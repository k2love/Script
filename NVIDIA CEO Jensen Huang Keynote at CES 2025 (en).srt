1
00:00:05,630 --> 00:00:08,690
This is how intelligence is made.

2
00:00:11,310 --> 00:00:12,990
A new kind of factory.

3
00:00:14,850 --> 00:00:15,950
Generator of tokens.

4
00:00:17,830 --> 00:00:19,590
The building blocks of AI.

5
00:00:21,810 --> 00:00:23,690
Tokens have opened a new frontier.

6
00:00:24,410 --> 00:00:26,530
The first step into an extraordinary world.

7
00:00:26,850 --> 00:00:29,130
Where endless possibilities are born.

8
00:00:34,410 --> 00:00:36,890
Tokens transform words into knowledge.

9
00:00:37,290 --> 00:00:39,150
And breathe life into images.

10
00:00:42,270 --> 00:00:44,250
They turn ideas into videos.

11
00:00:46,930 --> 00:00:49,450
And help us safely navigate any environment.

12
00:00:52,170 --> 00:00:54,990
Tokens teach robots to move like the masters.

13
00:01:00,070 --> 00:01:01,970
Inspire new ways to celebrate.

14
00:01:02,130 --> 00:01:03,210
To celebrate our victories.

15
00:01:03,250 --> 00:01:04,450
A Martini, please.

16
00:01:04,750 --> 00:01:05,750
Pulling right up.

17
00:01:07,110 --> 00:01:08,110
Thank you, Adam.

18
00:01:09,930 --> 00:01:12,690
And give us peace of mind when we need it most.

19
00:01:13,490 --> 00:01:14,490
Hi, Maruka.

20
00:01:14,930 --> 00:01:15,710
Hi, Anna.

21
00:01:15,930 --> 00:01:17,430
It's good to see you again.

22
00:01:18,190 --> 00:01:18,810
Hi, Emma.

23
00:01:18,950 --> 00:01:20,910
We're going to take your blood sample today, okay?

24
00:01:21,150 --> 00:01:21,810
Don't worry.

25
00:01:22,070 --> 00:01:23,790
I'm going to be here the whole time.

26
00:01:26,730 --> 00:01:28,330
They bring meaning to numbers.

27
00:01:30,370 --> 00:01:32,030
To help us better understand.

28
00:01:32,130 --> 00:01:33,130
The world around us.

29
00:01:41,280 --> 00:01:43,480
Predict the dangers that surround us.

30
00:01:51,640 --> 00:01:54,260
And find cures for the threats within us.

31
00:02:01,600 --> 00:02:03,620
Tokens can bring our visions to life.

32
00:02:10,570 --> 00:02:12,290
And restore what we've lost.

33
00:02:16,590 --> 00:02:17,590
Zachary.

34
00:02:17,770 --> 00:02:19,670
I got my voice back, buddy.

35
00:02:23,010 --> 00:02:24,710
They help us move forward.

36
00:02:26,650 --> 00:02:28,670
One small step at a time.

37
00:02:35,220 --> 00:02:36,500
And one giant leap.

38
00:02:38,480 --> 00:02:39,480
Together.

39
00:02:53,550 --> 00:02:54,550
And here.

40
00:02:57,070 --> 00:02:58,630
Is where it all begins.

41
00:03:06,580 --> 00:03:07,920
Welcome to the stage.

42
00:03:08,140 --> 00:03:10,920
NVIDIA founder and CEO, Jensen Wong.

43
00:03:20,640 --> 00:03:22,120
Welcome to CES.

44
00:03:24,740 --> 00:03:26,820
Are you excited to be in Las Vegas?

45
00:03:27,920 --> 00:03:29,800
Do you like my jacket?

46
00:03:32,180 --> 00:03:35,640
I thought I'd go the other way from Gary Shapiro.

47
00:03:37,600 --> 00:03:39,300
I'm in Las Vegas after all.

48
00:03:39,420 --> 00:03:46,500
If this doesn't work out, if all of you object, well, just get used to it.

49
00:03:46,501 --> 00:03:49,600
I really think you have to let this sink in.

50
00:03:51,040 --> 00:03:53,780
In another hour or so, you're going to feel good about it.

51
00:03:58,170 --> 00:04:01,470
Well, welcome to NVIDIA.

52
00:04:01,610 --> 00:04:04,250
In fact, you're inside NVIDIA's digital twin.

53
00:04:05,550 --> 00:04:08,630
And we're going to take you to NVIDIA.

54
00:04:09,210 --> 00:04:10,810
Ladies and gentlemen, welcome to NVIDIA.

55
00:04:14,450 --> 00:04:17,410
You're inside our digital twin.

56
00:04:20,700 --> 00:04:23,280
Everything here is generated by AI.

57
00:04:26,450 --> 00:04:29,630
It has been an extraordinary journey, extraordinary year.

58
00:04:30,610 --> 00:04:33,830
And it started in 1993.

59
00:04:34,330 --> 00:04:34,550
Ready?

60
00:04:34,630 --> 00:04:35,630
Go!

61
00:04:35,970 --> 00:04:40,354
With NV1, we wanted to build computers that

62
00:04:40,355 --> 00:04:43,810
can do things that normal computers couldn't.

63
00:04:44,390 --> 00:04:49,070
And NV1 made it possible to have a game console in your PC.

64
00:04:50,150 --> 00:04:53,550
Our programming architecture was called UDA.

65
00:04:54,210 --> 00:04:57,230
Missing the letter C until a little while later.

66
00:04:57,390 --> 00:05:00,470
But UDA, Unified Device Architecture.

67
00:05:00,930 --> 00:05:05,267
And the first developer for UDA and the first application

68
00:05:05,268 --> 00:05:10,110
that ever worked on UDA was Sega's Virtual Fighter.

69
00:05:11,150 --> 00:05:17,550
Six years later, we invented, in 1999, the programmable GPU.

70
00:05:18,390 --> 00:05:24,667
And it started 20 years, 20 plus years of incredible

71
00:05:24,668 --> 00:05:28,610
advance in this incredible processor called the GPU.

72
00:05:29,090 --> 00:05:32,110
It made modern computer graphics possible.

73
00:05:33,470 --> 00:05:40,130
And now, 30 years later, Sega's Virtual Fighter is completely cinematic.

74
00:05:42,230 --> 00:05:45,810
This is the new Virtual Fighter project that's coming.

75
00:05:45,950 --> 00:05:46,950
I just can't wait.

76
00:05:47,690 --> 00:05:48,790
Absolutely incredible.

77
00:05:49,670 --> 00:05:55,770
Six years after that, six years after 1999, we invented CUDA.

78
00:05:56,330 --> 00:06:02,870
So that we could explain or express the programmability of our

79
00:06:02,871 --> 00:06:05,991
GPUs to a rich set of algorithms that could benefit from it.

80
00:06:06,390 --> 00:06:10,110
CUDA initially was difficult to explain.

81
00:06:10,510 --> 00:06:12,210
And it took years, in fact.

82
00:06:12,470 --> 00:06:15,170
It took approximately six years.

83
00:06:15,930 --> 00:06:16,610
Somehow.

84
00:06:16,611 --> 00:06:18,050
Six years later.

85
00:06:18,730 --> 00:06:20,470
Six years later or so.

86
00:06:22,830 --> 00:06:23,830
2012.

87
00:06:25,730 --> 00:06:31,190
Alex Krzyzewski, Ilya Suskovor, and Jeff Hinton discovered CUDA.

88
00:06:31,530 --> 00:06:35,030
Used it to process AlexNet.

89
00:06:35,190 --> 00:06:37,490
And the rest of it is history.

90
00:06:37,930 --> 00:06:41,310
AI has been advancing at an incredible pace since.

91
00:06:41,630 --> 00:06:43,810
Started with perception AI.

92
00:06:43,811 --> 00:06:47,350
We now can understand images and words and sounds.

93
00:06:48,310 --> 00:06:49,550
To generative AI.

94
00:06:49,950 --> 00:06:52,550
We can generate images and texts and sounds.

95
00:06:53,390 --> 00:06:56,230
And now, agentic AI.

96
00:06:56,990 --> 00:07:01,530
AIs that can perceive, reason, plan, and act.

97
00:07:02,170 --> 00:07:06,370
And then the next phase, some of which we'll talk about tonight, physical AI.

98
00:07:07,050 --> 00:07:08,050
2012.

99
00:07:08,130 --> 00:07:11,610
Now magically, 2018.

100
00:07:11,611 --> 00:07:14,870
Something happened that was pretty incredible.

101
00:07:16,570 --> 00:07:20,010
Google's transformer was released as Bert.

102
00:07:20,290 --> 00:07:24,870
And the world of AI really took off.

103
00:07:25,930 --> 00:07:28,634
Transformers, as you know, completely changed

104
00:07:28,635 --> 00:07:30,830
the landscape for artificial intelligence.

105
00:07:31,210 --> 00:07:35,310
In fact, it completely changed the landscape for computing altogether.

106
00:07:35,970 --> 00:07:41,410
We recognized properly that AI was not just a new application.

107
00:07:41,411 --> 00:07:44,430
With a new business opportunity.

108
00:07:44,670 --> 00:07:50,030
But AI, more importantly, machine learning, enabled by transformers,

109
00:07:50,110 --> 00:07:53,690
was going to fundamentally change how computing works.

110
00:07:54,330 --> 00:08:01,150
And today, computing has revolutionized in every single layer.

111
00:08:01,450 --> 00:08:04,877
From hand coding, instructions that run on

112
00:08:04,878 --> 00:08:08,550
CPUs to create software tools that humans use.

113
00:08:08,870 --> 00:08:10,830
We now have machine learning.

114
00:08:10,831 --> 00:08:14,050
That creates and optimizes neural networks.

115
00:08:14,270 --> 00:08:16,650
That processes on GPUs.

116
00:08:16,770 --> 00:08:18,530
And creates artificial intelligence.

117
00:08:19,250 --> 00:08:24,270
Every single layer of the technology stack has been completely changed.

118
00:08:24,790 --> 00:08:28,870
An incredible transformation in just 12 years.

119
00:08:29,570 --> 00:08:35,570
Well, we can now understand information of just about any modality.

120
00:08:35,830 --> 00:08:39,890
Surely you've seen text and images and sounds and things like that.

121
00:08:39,891 --> 00:08:44,510
But not only can we understand those, we can understand amino acids.

122
00:08:44,690 --> 00:08:45,730
We can understand physics.

123
00:08:46,150 --> 00:08:47,510
We understand them.

124
00:08:47,590 --> 00:08:50,210
We can translate them and generate them.

125
00:08:50,530 --> 00:08:53,450
The applications are just completely endless.

126
00:08:53,810 --> 00:08:57,945
In fact, almost any AI application that you see out

127
00:08:57,946 --> 00:09:00,851
there, what modality is the input that it learned from?

128
00:09:01,510 --> 00:09:04,350
What modality of information did it translate to?

129
00:09:04,610 --> 00:09:07,290
And what modality of information is it generating?

130
00:09:07,291 --> 00:09:09,769
If you ask these three fundamental questions, just

131
00:09:09,770 --> 00:09:13,570
about every single application could be inferred.

132
00:09:13,690 --> 00:09:18,190
And so when you see application after application that are AI-driven,

133
00:09:18,410 --> 00:09:23,510
AI-native, at the core of it, this fundamental concept is there.

134
00:09:23,710 --> 00:09:28,290
Machine learning has changed how every application is going to be built,

135
00:09:28,410 --> 00:09:32,050
how computing will be done, and the possibilities beyond.

136
00:09:32,590 --> 00:09:35,650
Well, GPUs...

137
00:09:36,970 --> 00:09:43,690
GeForce, in a lot of ways, all of this with AI is the house that GeForce built.

138
00:09:44,550 --> 00:09:47,750
GeForce enabled AI to reach the masses.

139
00:09:48,150 --> 00:09:51,750
And now, AI is coming home to GeForce.

140
00:09:52,530 --> 00:09:56,530
There are so many things that you can't do without AI.

141
00:09:56,710 --> 00:09:59,910
Let me show you some of it now.

142
00:11:34,480 --> 00:11:37,720
That was real-time computer graphics.

143
00:11:44,660 --> 00:11:50,360
No computer graphics researcher, no computer scientist would have told you

144
00:11:50,361 --> 00:11:55,660
that it is possible for us to ray-trace every single pixel at this point.

145
00:11:56,340 --> 00:11:58,520
Ray-tracing is a simulation of light.

146
00:11:58,700 --> 00:12:01,820
The amount of geometry that you saw was absolutely insane.

147
00:12:02,140 --> 00:12:05,360
It would have been impossible without artificial intelligence.

148
00:12:05,920 --> 00:12:08,080
There are two fundamental things that we did.

149
00:12:08,860 --> 00:12:13,400
We used, of course, programmable shading and ray-traced acceleration.

150
00:12:13,401 --> 00:12:16,156
We used ray-tracing acceleration to produce incredibly beautiful pixels.

151
00:12:16,180 --> 00:12:23,460
But then we have artificial intelligence be conditioned, be controlled by that

152
00:12:23,461 --> 00:12:26,940
pixel to generate a whole bunch of other pixels.

153
00:12:27,200 --> 00:12:30,839
Not only is it able to generate other pixels spatially,

154
00:12:30,840 --> 00:12:33,600
because it's aware of what the colors should be.

155
00:12:33,980 --> 00:12:37,460
It has been trained on a supercomputer back in NVIDIA.

156
00:12:37,580 --> 00:12:40,760
And so the neural network that's running on the GPU...

157
00:12:40,761 --> 00:12:45,380
can infer and predict the pixels that we did not render.

158
00:12:46,020 --> 00:12:49,240
Not only can we do that, it's called DLSS.

159
00:12:49,580 --> 00:12:54,220
The latest generation of DLSS also generates beyond frames.

160
00:12:54,560 --> 00:12:56,160
It can predict the future.

161
00:12:56,820 --> 00:13:00,640
Generating three additional frames for every frame that we calculate.

162
00:13:01,260 --> 00:13:05,240
What you saw, if we just said four frames of what you saw...

163
00:13:05,700 --> 00:13:08,100
because we're going to render one frame and generate three.

164
00:13:08,101 --> 00:13:14,600
If I said four frames at full HD, 4K, that's 33 million pixels or so.

165
00:13:14,960 --> 00:13:21,740
Out of that 33 million pixels, we computed only two.

166
00:13:23,960 --> 00:13:28,543
It is an absolute miracle that we can computationally,

167
00:13:28,544 --> 00:13:33,140
using programmable shaders and our ray-tracing engine...

168
00:13:33,141 --> 00:13:38,080
to compute two million pixels and have AI predict all of the other frames.

169
00:13:38,100 --> 00:13:39,100
33.

170
00:13:39,600 --> 00:13:44,420
And as a result, we're able to render at incredibly high performance.

171
00:13:44,800 --> 00:13:47,260
Because AI does a lot less computation.

172
00:13:48,100 --> 00:13:51,880
It takes, of course, an enormous amount of training to produce that.

173
00:13:52,140 --> 00:13:56,060
But once you train it, the generation is extremely efficient.

174
00:13:56,720 --> 00:14:00,320
So this is one of the incredible capabilities of artificial intelligence.

175
00:14:00,600 --> 00:14:04,020
And that's why there's so many amazing things that are happening.

176
00:14:04,260 --> 00:14:08,080
We used GeForce to enable artificial intelligence...

177
00:14:08,081 --> 00:14:11,500
and now artificial intelligence is revolutionizing GeForce.

178
00:14:12,060 --> 00:14:16,040
Everyone, today we're announcing our next generation.

179
00:14:16,740 --> 00:14:19,600
The RTX Blackwell family.

180
00:14:19,980 --> 00:14:20,980
Let's take a look.

181
00:15:18,950 --> 00:15:19,950
Here it is.

182
00:15:20,770 --> 00:15:28,750
Our brand new GeForce RTX 50 series Blackwell architecture.

183
00:15:29,290 --> 00:15:31,670
The GPU is just a beast.

184
00:15:32,490 --> 00:15:34,630
92 billion transistors.

185
00:15:35,910 --> 00:15:37,710
4,000 tops.

186
00:15:38,210 --> 00:15:40,590
Four petaflops of AI.

187
00:15:41,050 --> 00:15:44,070
Three times higher than the last generation Ada.

188
00:15:44,250 --> 00:15:47,270
And we need all of it to generate those pixels that I showed you.

189
00:15:48,670 --> 00:15:51,510
380 ray-tracing teraflops.

190
00:15:51,830 --> 00:15:54,610
So that we could, for the pixels that we have to compute...

191
00:15:54,611 --> 00:15:57,330
compute the most beautiful image you possibly can.

192
00:15:58,000 --> 00:16:01,310
And, of course, 125 shader teraflops.

193
00:16:01,311 --> 00:16:04,210
There is actually a concurrent shader teraflops...

194
00:16:04,211 --> 00:16:07,150
as well as an integer unit of equal performance.

195
00:16:07,270 --> 00:16:09,390
So two dual shaders.

196
00:16:09,590 --> 00:16:11,130
One is for floating point.

197
00:16:11,290 --> 00:16:12,290
One is for integer.

198
00:16:12,910 --> 00:16:15,510
G7 memory from Micron.

199
00:16:15,650 --> 00:16:18,090
1.8 terabytes per second.

200
00:16:18,170 --> 00:16:20,010
Twice the performance of our last generation.

201
00:16:20,330 --> 00:16:24,570
And we now have the ability to intermix AI workloads...

202
00:16:24,571 --> 00:16:26,470
with computer graphics workloads.

203
00:16:26,850 --> 00:16:29,310
And one of the amazing things about this generation...

204
00:16:29,311 --> 00:16:35,190
is the programmable shader is also able... to now process neural networks.

205
00:16:35,450 --> 00:16:38,730
So the shader is able to carry these neural networks.

206
00:16:38,930 --> 00:16:43,010
And as a result, we invented neural texture compression...

207
00:16:43,011 --> 00:16:45,330
and neural material shading.

208
00:16:45,610 --> 00:16:49,230
As a result of that, you get these amazingly beautiful images...

209
00:16:49,231 --> 00:16:52,170
that are only possible because we use AIs...

210
00:16:52,171 --> 00:16:55,790
to learn the texture, learn the compression algorithm...

211
00:16:55,791 --> 00:16:57,730
and as a result, get extraordinary results.

212
00:16:57,731 --> 00:17:02,270
Okay, so this is the brand new...

213
00:17:05,490 --> 00:17:07,430
RTX Blackwell 59.

214
00:17:11,970 --> 00:17:16,170
Now, even the mechanical design is a miracle.

215
00:17:16,510 --> 00:17:18,010
Look at this, it's got two fans.

216
00:17:19,030 --> 00:17:22,130
This whole graphics card is just one giant fan.

217
00:17:22,910 --> 00:17:25,190
You know, so the question is, where's the graphics card?

218
00:17:25,290 --> 00:17:26,290
Is it literally this big?

219
00:17:27,570 --> 00:17:30,410
The voltage regulator design... is state-of-the-art.

220
00:17:31,530 --> 00:17:32,530
Incredible design.

221
00:17:32,750 --> 00:17:34,570
The engineering team did a great job.

222
00:17:34,950 --> 00:17:35,850
So here it is.

223
00:17:35,970 --> 00:17:36,970
Thank you.

224
00:17:42,560 --> 00:17:44,800
Okay, so those are the speeds and feeds.

225
00:17:44,940 --> 00:17:45,940
So how does it compare?

226
00:17:48,720 --> 00:17:52,000
Well, this is RTX 4090.

227
00:17:53,700 --> 00:17:55,940
I know, I know many of you have one.

228
00:17:58,260 --> 00:17:59,260
I know it.

229
00:17:59,520 --> 00:18:01,500
Look, it's $1,599.

230
00:18:01,501 --> 00:18:05,200
It is one of the best investments you could possibly make.

231
00:18:07,480 --> 00:18:17,160
For $1,599, you bring it home to your $10,000 PC Entertainment Command Center.

232
00:18:17,400 --> 00:18:18,400
Isn't that right?

233
00:18:19,120 --> 00:18:20,720
Don't tell me that's not true.

234
00:18:20,980 --> 00:18:21,980
Don't be ashamed.

235
00:18:23,640 --> 00:18:25,020
It's liquid-cooled.

236
00:18:26,380 --> 00:18:27,980
Fancy lights all over it.

237
00:18:29,580 --> 00:18:31,000
You lock it when you leave.

238
00:18:33,480 --> 00:18:35,600
It's the modern home theater.

239
00:18:35,800 --> 00:18:37,000
It makes perfect sense.

240
00:18:37,440 --> 00:18:41,297
And now for $1,599, you get to upgrade that

241
00:18:41,298 --> 00:18:44,460
and turbocharge the living daylights out of it.

242
00:18:44,540 --> 00:18:47,980
Well, now with the Blackwell family, RTX 5070.

243
00:18:49,020 --> 00:18:52,560
4090 performance at $549.

244
00:19:01,500 --> 00:19:03,800
Impossible without artificial intelligence.

245
00:19:04,180 --> 00:19:07,320
Impossible without the four tops.

246
00:19:07,321 --> 00:19:11,320
Four TeraOps of AI Tensor cores.

247
00:19:11,560 --> 00:19:13,920
Impossible without the G7 memories.

248
00:19:14,560 --> 00:19:18,740
Okay, so 5070, 4090 performance, $549.

249
00:19:19,220 --> 00:19:20,340
And here's the whole family.

250
00:19:20,440 --> 00:19:23,660
Starting from 5070 all the way up to 5090.

251
00:19:24,040 --> 00:19:26,760
5090, twice the performance of a 4090.

252
00:19:29,880 --> 00:19:30,880
Starting...

253
00:19:31,320 --> 00:19:35,660
Of course, we're producing at very large scale availability starting January.

254
00:19:35,661 --> 00:19:41,394
Well, it is incredible, but we managed to put

255
00:19:41,395 --> 00:19:46,120
these gigantic performance GPUs into a laptop.

256
00:19:46,420 --> 00:19:48,840
This is a 5070 laptop.

257
00:19:49,480 --> 00:19:55,500
For $1,299, this 5070 laptop has a 4090 performance.

258
00:19:55,920 --> 00:19:57,700
I think there's one here somewhere.

259
00:19:59,640 --> 00:20:01,020
Let me show you this.

260
00:20:02,740 --> 00:20:05,460
This is a... Look at this thing.

261
00:20:05,920 --> 00:20:07,821
Here, let me... Here.

262
00:20:08,580 --> 00:20:09,780
There's only so many pockets.

263
00:20:11,620 --> 00:20:13,320
Ladies and gentlemen, Janine Paul.

264
00:20:17,630 --> 00:20:18,690
So can you imagine?

265
00:20:18,850 --> 00:20:21,510
You get this incredible graphics card here, Blackwell.

266
00:20:21,650 --> 00:20:23,670
We're going to shrink it and put it in there.

267
00:20:23,890 --> 00:20:25,150
Does that make any sense?

268
00:20:27,150 --> 00:20:29,930
Well, you can't do that without artificial intelligence.

269
00:20:30,090 --> 00:20:33,402
And the reason for that is because we're generating

270
00:20:33,403 --> 00:20:35,490
most of the pixels using our Tensor cores.

271
00:20:35,491 --> 00:20:40,490
So we ray trace only the pixels we need, and we generate using artificial

272
00:20:40,491 --> 00:20:42,510
intelligence all of the other pixels we have.

273
00:20:42,810 --> 00:20:46,450
As a result, the amount of the energy efficiency is just off the charts.

274
00:20:47,130 --> 00:20:50,853
The future of computer graphics is neural rendering, the

275
00:20:50,854 --> 00:20:53,411
fusion of artificial intelligence and computer graphics.

276
00:20:53,810 --> 00:20:59,150
And what's really amazing is... Oh, here we go.

277
00:20:59,370 --> 00:21:00,370
Thank you.

278
00:21:01,210 --> 00:21:03,590
This is a surprisingly kinetic keynote.

279
00:21:05,410 --> 00:21:09,110
And what's really amazing is the family of GPUs we're going to put in here.

280
00:21:09,450 --> 00:21:15,470
And so the 5090 will fit into a laptop, a thin laptop.

281
00:21:15,630 --> 00:21:18,650
That last laptop was 14.9 millimeters.

282
00:21:18,990 --> 00:21:22,010
You've got a 5080, 5070 Ti, and 5070.

283
00:21:22,670 --> 00:21:23,230
Okay?

284
00:21:23,290 --> 00:21:28,430
So, ladies and gentlemen, the RTX Blackwell family.

285
00:21:37,540 --> 00:21:38,540
Well, GeForce...

286
00:21:38,800 --> 00:21:41,700
Brought AI to the world.

287
00:21:42,320 --> 00:21:43,320
Democratized AI.

288
00:21:43,780 --> 00:21:47,880
Now AI has come back and revolutionized GeForce.

289
00:21:48,140 --> 00:21:50,700
Let's talk about artificial intelligence.

290
00:21:51,020 --> 00:21:52,800
Let's go to somewhere else at NVIDIA.

291
00:21:57,860 --> 00:21:59,580
This is literally our office.

292
00:21:59,740 --> 00:22:01,340
This is literally NVIDIA's headquarters.

293
00:22:03,880 --> 00:22:06,320
Okay, so let's talk about AI.

294
00:22:06,820 --> 00:22:14,780
The industry is chasing and racing... to scale artificial intelligence.

295
00:22:16,840 --> 00:22:20,660
And the scaling law is a powerful model.

296
00:22:20,720 --> 00:22:23,940
It's an empirical law that has been observed...

297
00:22:23,941 --> 00:22:28,560
and demonstrated by researchers and industry over several generations.

298
00:22:29,300 --> 00:22:35,240
And the scaling laws says that the more data you have...

299
00:22:35,241 --> 00:22:38,820
the training data that you have, the larger model that you have...

300
00:22:38,821 --> 00:22:41,800
and the more compute that you apply to it, therefore...

301
00:22:41,801 --> 00:22:47,280
the more effective or the more capable your model will become.

302
00:22:47,920 --> 00:22:50,260
And so the scaling law continues.

303
00:22:51,040 --> 00:22:53,800
What's really amazing is that now we're moving towards...

304
00:22:54,540 --> 00:22:59,060
of course, and the Internet is producing about twice the amount of data...

305
00:22:59,061 --> 00:23:00,920
every single year as it did last year.

306
00:23:01,120 --> 00:23:03,740
I think in the next couple of years we'll produce...

307
00:23:03,741 --> 00:23:08,420
humanity will produce more data than all of humanity has ever produced...

308
00:23:08,421 --> 00:23:09,680
since the beginning.

309
00:23:09,880 --> 00:23:13,680
And so we're still producing... a gigantic amount of data.

310
00:23:13,860 --> 00:23:15,960
And it's becoming multimodal.

311
00:23:15,980 --> 00:23:18,140
Video and images and sound.

312
00:23:18,320 --> 00:23:22,820
All of that data could be used to train the fundamental knowledge...

313
00:23:23,180 --> 00:23:25,040
the foundational knowledge of an AI.

314
00:23:25,320 --> 00:23:30,960
But there are, in fact, two other scaling laws... that has now emerged.

315
00:23:31,200 --> 00:23:32,920
And it's somewhat intuitive.

316
00:23:33,360 --> 00:23:37,440
The second scaling law is post-training scaling law.

317
00:23:37,640 --> 00:23:41,060
Post-training scaling law uses technology techniques...

318
00:23:41,061 --> 00:23:42,800
like reinforcement learning, human feedback.

319
00:23:43,940 --> 00:23:50,680
Basically, the AI produces and generates answers... based on a human query.

320
00:23:50,960 --> 00:23:53,200
The human then, of course, gives the feedback.

321
00:23:53,840 --> 00:23:55,620
It's much more complicated than that.

322
00:23:55,680 --> 00:23:57,320
But that reinforcement learning system...

323
00:23:57,760 --> 00:24:00,840
with a fair number of very high quality prompts...

324
00:24:00,841 --> 00:24:04,760
causes the AI to refine its skills.

325
00:24:05,220 --> 00:24:08,360
It could fine-tune its skills for particular domains.

326
00:24:08,720 --> 00:24:10,440
It could be better at solving math problems.

327
00:24:11,060 --> 00:24:11,860
Better at reasoning.

328
00:24:12,020 --> 00:24:13,020
So on and so forth.

329
00:24:13,080 --> 00:24:16,980
And so it's essentially like having a mentor...

330
00:24:16,981 --> 00:24:21,440
or having a coach give you feedback... after you're done going to school.

331
00:24:21,900 --> 00:24:23,340
And so you get tests.

332
00:24:23,560 --> 00:24:24,140
You get feedback.

333
00:24:24,280 --> 00:24:25,280
You improve yourself.

334
00:24:25,460 --> 00:24:28,240
We also have reinforcement learning AI feedback.

335
00:24:28,700 --> 00:24:30,780
And we have synthetic data generation.

336
00:24:31,840 --> 00:24:33,720
These techniques are rather...

337
00:24:35,720 --> 00:24:38,600
akin to, if you will, self-practice.

338
00:24:38,960 --> 00:24:41,780
You know... you know the answer to a particular problem.

339
00:24:42,200 --> 00:24:44,920
And you continue to try it until you get it right.

340
00:24:45,280 --> 00:24:47,080
And so an AI could be presented...

341
00:24:47,440 --> 00:24:53,120
with a very complicated and a difficult problem... that is verifiable functionally.

342
00:24:53,220 --> 00:24:55,540
And it has an answer that we understand.

343
00:24:55,780 --> 00:24:56,780
Maybe proving a theorem.

344
00:24:56,940 --> 00:25:00,120
Maybe solving a geometry problem.

345
00:25:00,460 --> 00:25:04,840
And so these problems... would cause the AI to produce answers.

346
00:25:05,040 --> 00:25:08,960
And using reinforcement learning... you would learn how to improve itself.

347
00:25:08,961 --> 00:25:11,300
That's called post-training.

348
00:25:11,460 --> 00:25:13,900
Post-training requires an enormous amount of computation.

349
00:25:14,220 --> 00:25:17,240
But the end result produces incredible models.

350
00:25:17,720 --> 00:25:20,300
We now have a third scaling law.

351
00:25:20,520 --> 00:25:25,480
And this third scaling law... has to do with what's called test-time scaling.

352
00:25:25,840 --> 00:25:29,140
Test-time scaling is basically when you're being used.

353
00:25:29,360 --> 00:25:34,040
When you're using the AI... the AI has the ability...

354
00:25:34,041 --> 00:25:37,040
to now apply a different resource allocation.

355
00:25:37,360 --> 00:25:41,140
Instead of improving its parameters... now it's focused on...

356
00:25:41,141 --> 00:25:46,120
deciding how much computation to use... to produce the answers...

357
00:25:46,121 --> 00:25:47,280
it wants to produce.

358
00:25:48,600 --> 00:25:50,360
Reasoning is a way of thinking about this.

359
00:25:50,640 --> 00:25:52,640
Long thinking is a way to think about this.

360
00:25:52,820 --> 00:25:58,320
Instead of a direct inference... or one-shot answer... you might reason about it.

361
00:25:58,440 --> 00:26:00,620
You might break down the problem into multiple steps.

362
00:26:01,000 --> 00:26:04,420
You might generate multiple ideas... and evaluate.

363
00:26:04,800 --> 00:26:08,900
Your AI system would evaluate... which one of the ideas that you generated...

364
00:26:08,960 --> 00:26:09,960
was the best one.

365
00:26:10,240 --> 00:26:12,300
Maybe it solves the problem step-by-step.

366
00:26:12,460 --> 00:26:13,460
So on and so forth.

367
00:26:13,560 --> 00:26:18,020
And so now test-time scaling... has proven to be incredibly effective.

368
00:26:18,660 --> 00:26:21,880
You're watching this sequence of technology...

369
00:26:21,881 --> 00:26:27,380
and all of these scaling laws emerge... as we see incredible achievements...

370
00:26:27,381 --> 00:26:32,980
from ChatGPT to 01 to 03... and now Gemini Pro.

371
00:26:33,180 --> 00:26:37,820
All of these systems are going through this journey... step-by-step-by-step...

372
00:26:37,821 --> 00:26:41,820
of pre-training to post-training... to test-time scaling.

373
00:26:42,280 --> 00:26:45,800
Well, the amount of computation that we need... of course, is incredible.

374
00:26:46,280 --> 00:26:49,600
And we would like, in fact... we would like, in fact...

375
00:26:49,601 --> 00:26:52,980
that society has the ability to scale... the amount of computation...

376
00:26:52,981 --> 00:26:56,720
to produce more and more novel... and better intelligence.

377
00:26:57,360 --> 00:26:59,800
Intelligence, of course, is the most valuable asset...

378
00:26:59,801 --> 00:27:03,241
that we have, and it can be applied... to solve a lot of very challenging problems.

379
00:27:03,700 --> 00:27:05,680
And so, scaling law.

380
00:27:06,040 --> 00:27:07,700
It's driving enormous...

381
00:27:07,820 --> 00:27:09,120
demand for NVIDIA computing.

382
00:27:09,340 --> 00:27:14,581
It's driving enormous demand... for this incredible chip we call... Blackwell.

383
00:27:15,160 --> 00:27:16,560
Let's take a look at Blackwell.

384
00:27:17,240 --> 00:27:19,640
Well, Blackwell is in full production.

385
00:27:22,300 --> 00:27:24,501
It is incredible... what it looks like.

386
00:27:24,800 --> 00:27:27,220
So, first of all, there's some...

387
00:27:27,580 --> 00:27:31,061
every single cloud service provider... now have systems up and running.

388
00:27:31,380 --> 00:27:33,200
We have systems here from about...

389
00:27:33,820 --> 00:27:34,820
15...

390
00:27:36,120 --> 00:27:37,120
15...

391
00:27:37,820 --> 00:27:39,320
15 computer makers.

392
00:27:39,620 --> 00:27:43,120
It's being made... about 200 different SKUs.

393
00:27:43,400 --> 00:27:44,780
200 different configurations.

394
00:27:45,060 --> 00:27:49,320
They're liquid-cooled, air-cooled, x86... NVIDIA Grey CPU versions.

395
00:27:49,740 --> 00:27:51,860
NVLink 36x2.

396
00:27:52,000 --> 00:27:54,220
NVLink 72x1.

397
00:27:54,420 --> 00:27:57,740
Whole bunch of different types of systems... so that we can accommodate...

398
00:27:57,741 --> 00:27:59,720
just about every single data center in the world.

399
00:28:00,480 --> 00:28:03,369
Well, this... these systems are being...

400
00:28:03,370 --> 00:28:06,280
currently manufactured in some 45... factories.

401
00:28:06,500 --> 00:28:07,700
It tells you...

402
00:28:07,820 --> 00:28:11,980
how pervasive artificial intelligence is... and how much the industry...

403
00:28:11,981 --> 00:28:15,740
is jumping onto artificial intelligence... in this new computing model.

404
00:28:16,940 --> 00:28:21,800
Well... the reason why we're driving... it so hard, is because we need...

405
00:28:21,801 --> 00:28:22,801
a lot more computation.

406
00:28:22,860 --> 00:28:27,061
And it's very clear... it's very clear that... that...

407
00:28:30,480 --> 00:28:31,480
Janine?

408
00:28:38,050 --> 00:28:39,050
You know, I...

409
00:28:40,830 --> 00:28:45,250
it's hard... to tell... you don't ever want to reach your hands...

410
00:28:45,550 --> 00:28:46,550
into a dark place.

411
00:28:47,790 --> 00:28:49,551
Hang on a second... is this a good idea?

412
00:28:51,470 --> 00:28:52,470
Alright.

413
00:29:08,540 --> 00:29:09,540
Wait for it.

414
00:29:11,920 --> 00:29:12,920
Wait for it.

415
00:29:17,440 --> 00:29:18,640
I thought I was worthy.

416
00:29:23,920 --> 00:29:25,720
Apparently... Yoner didn't think I was worthy.

417
00:29:27,380 --> 00:29:28,380
Alright.

418
00:29:29,260 --> 00:29:30,660
This is my show and tell.

419
00:29:31,020 --> 00:29:32,060
This is a show and tell.

420
00:29:32,660 --> 00:29:33,660
So...

421
00:29:34,560 --> 00:29:34,840
MVLink system.

422
00:29:35,260 --> 00:29:36,480
This right here.

423
00:29:36,540 --> 00:29:37,600
This MVLink system.

424
00:29:37,900 --> 00:29:40,160
This is GB200.

425
00:29:40,500 --> 00:29:41,500
MVLink 72.

426
00:29:42,160 --> 00:29:43,900
It is one and a half tons.

427
00:29:44,980 --> 00:29:46,560
600,000 parts.

428
00:29:48,420 --> 00:29:50,180
Approximately equal to 20 cars.

429
00:29:54,060 --> 00:29:55,420
120 kilowatts.

430
00:29:58,450 --> 00:29:59,590
It has...

431
00:30:00,310 --> 00:30:03,651
a spine behind it... that connects all of these GPU together.

432
00:30:04,670 --> 00:30:06,050
Two miles of...

433
00:30:06,310 --> 00:30:07,310
copper cable.

434
00:30:09,730 --> 00:30:10,770
5000 cables.

435
00:30:12,250 --> 00:30:15,450
This is being manufactured... in 45 factories around the world.

436
00:30:16,170 --> 00:30:17,210
We build them.

437
00:30:17,710 --> 00:30:19,170
We liquid cool them.

438
00:30:19,310 --> 00:30:20,310
We test them.

439
00:30:20,390 --> 00:30:21,690
We disassemble them.

440
00:30:21,770 --> 00:30:26,150
Ship them in parts... to the data centers... because it's one and a half tons.

441
00:30:26,810 --> 00:30:29,930
We reassemble it outside the data centers... and install them.

442
00:30:30,330 --> 00:30:31,870
The manufacturing is insane.

443
00:30:31,871 --> 00:30:35,890
But the goal of all of this... is because the scaling laws...

444
00:30:35,891 --> 00:30:39,890
are driving computing so hard... that this level of computation...

445
00:30:39,891 --> 00:30:44,770
Blackwell over our last generation... improves the performance per watt...

446
00:30:44,771 --> 00:30:46,170
by a factor of 4.

447
00:30:47,250 --> 00:30:49,170
Performance per watt... by a factor of 4.

448
00:30:49,290 --> 00:30:52,250
Performance per dollar... by a factor of 3.

449
00:30:52,570 --> 00:30:56,250
That basically says... that in one generation...

450
00:30:56,251 --> 00:31:01,131
we reduce the cost of training these models... by a factor of 3.

451
00:31:01,870 --> 00:31:04,065
Or if you want to increase the size of your model

452
00:31:04,125 --> 00:31:06,050
by a factor of three, it's about the same cost.

453
00:31:06,450 --> 00:31:08,030
But the important thing is this.

454
00:31:08,650 --> 00:31:14,570
These are generating tokens that are being used by all of us when we use ChatGPT or

455
00:31:14,571 --> 00:31:16,670
when we use Gemini and use our phones in the future.

456
00:31:16,890 --> 00:31:20,630
Just about all of these applications are going to be consuming these AI tokens.

457
00:31:20,970 --> 00:31:23,730
And these AI tokens are being generated by these systems.

458
00:31:24,730 --> 00:31:27,710
And every single data center is limited by power.

459
00:31:27,711 --> 00:31:35,350
And so if the per watt of Blackwell is four times our last generation,

460
00:31:35,690 --> 00:31:40,310
then the revenue that could be generated, the amount of business that could be

461
00:31:40,311 --> 00:31:42,751
generated in the data center is increased by a factor of four.

462
00:31:42,970 --> 00:31:47,030
And so these AI factory systems really are factories today.

463
00:31:47,330 --> 00:31:52,130
Now the goal of all of this is so that we can create one giant chip.

464
00:31:52,470 --> 00:31:55,310
The amount of computation we need is really quite incredible.

465
00:31:55,610 --> 00:31:57,690
And this is basically one giant chip.

466
00:31:57,691 --> 00:32:05,110
If we would have had to build a chip, one, here we go, sorry guys, you see that?

467
00:32:05,250 --> 00:32:06,250
That's cool.

468
00:32:06,910 --> 00:32:08,670
Look at that, disco lights in here.

469
00:32:12,170 --> 00:32:16,450
If we had to build this as one chip, obviously this would be the size of the wafer.

470
00:32:16,590 --> 00:32:18,950
But this doesn't include the impact of yield.

471
00:32:19,150 --> 00:32:21,530
It would have to be probably three or four times the size.

472
00:32:21,830 --> 00:32:27,170
But what we basically have here is 72 Blackwell GPUs or 144 dies.

473
00:32:27,670 --> 00:32:29,170
This one chip.

474
00:32:29,250 --> 00:32:31,250
This chip here is 1.4 Exaflops.

475
00:32:31,450 --> 00:32:35,550
The world's largest supercomputer, fastest supercomputer only recently,

476
00:32:35,870 --> 00:32:40,730
this entire room supercomputer only recently achieved an Exaflop plus.

477
00:32:41,090 --> 00:32:45,010
This is 1.4 Exaflops of AI floating point performance.

478
00:32:45,470 --> 00:32:48,790
It has 14 Terabytes of memory, but here's the amazing thing.

479
00:32:48,970 --> 00:32:52,650
The memory bandwidth is 1.2 Petabytes per second.

480
00:32:52,870 --> 00:32:59,230
That's basically, basically, the entire Internet traffic that's happening.

481
00:32:59,231 --> 00:33:00,631
This is what's happening right now.

482
00:33:01,490 --> 00:33:07,130
The entire world's Internet traffic is being processed across these chips.

483
00:33:07,790 --> 00:33:14,813
And we have 130 trillion transistors in total,

484
00:33:14,814 --> 00:33:19,270
2,592 CPU cores, a whole bunch of networking.

485
00:33:19,930 --> 00:33:22,330
And so these... I wish I could do this.

486
00:33:22,450 --> 00:33:23,130
I don't think I will.

487
00:33:23,131 --> 00:33:24,650
So these are the Blackwells.

488
00:33:26,350 --> 00:33:30,930
These are our ConnectX networking chips.

489
00:33:31,470 --> 00:33:36,850
These are the NVLink, and we're trying to pretend about the NVLink spine,

490
00:33:37,130 --> 00:33:38,450
but that's not possible.

491
00:33:38,990 --> 00:33:45,250
And these are all of the HBM memories, 14 terabytes of HBM memory.

492
00:33:45,730 --> 00:33:50,550
This is what we're trying to do, and this is the miracle of the Blackwell system.

493
00:33:50,910 --> 00:33:52,690
The Blackwell dies right here.

494
00:33:53,330 --> 00:33:55,670
It is the largest single chip the world's ever made.

495
00:33:56,090 --> 00:34:00,150
But yet, the miracle is really in addition to that.

496
00:34:00,790 --> 00:34:02,570
This is the Grace Blackwell system.

497
00:34:03,110 --> 00:34:06,950
Well, the goal of all of this, of course, is so that we can... Thank you.

498
00:34:07,010 --> 00:34:08,010
Thanks.

499
00:34:11,240 --> 00:34:13,340
Boy, is there a chair I could sit down for a second?

500
00:34:26,140 --> 00:34:28,040
Can I have a Michelob Ultra?

501
00:34:39,870 --> 00:34:44,830
How is it possible that we're in the Michelob Ultra stadium?

502
00:34:47,630 --> 00:34:50,250
It's like coming to NVIDIA and we don't have a GPU for you.

503
00:34:55,410 --> 00:34:58,108
So we need an enormous amount of computation

504
00:34:58,109 --> 00:35:00,411
because we want to train larger and larger models.

505
00:35:00,990 --> 00:35:05,524
And these inferences used to be one inference, but in

506
00:35:05,525 --> 00:35:08,026
the future, the AI is going to be talking to itself.

507
00:35:08,050 --> 00:35:09,090
It's going to be thinking.

508
00:35:09,370 --> 00:35:11,490
It's going to be internally reflecting, processing.

509
00:35:11,790 --> 00:35:16,930
So today, when the tokens are being generated at you, so long as it's coming

510
00:35:16,931 --> 00:35:22,250
out at 20 or 30 tokens per second, it's basically as fast as anybody can read.

511
00:35:22,390 --> 00:35:30,730
However, in the future, and right now with GPT-01, with the new Gemini Pro and the

512
00:35:30,731 --> 00:35:34,390
new 0103 models, they're talking to themselves.

513
00:35:34,510 --> 00:35:35,150
They're reflecting.

514
00:35:35,410 --> 00:35:36,410
They're thinking.

515
00:35:36,530 --> 00:35:39,190
And so, as you can imagine, the rate at which

516
00:35:39,191 --> 00:35:42,230
the tokens could be ingested is incredibly high.

517
00:35:42,570 --> 00:35:46,690
And so we need the token rates, the token generation rates, to go way up.

518
00:35:46,830 --> 00:35:52,090
And we also have to drive the costs way down simultaneously so that the quality of

519
00:35:52,091 --> 00:35:56,150
service can be extraordinary, the cost to customers can continue to be low,

520
00:35:56,330 --> 00:35:58,410
and AI will continue to scale.

521
00:35:58,670 --> 00:36:02,130
And so that's the fundamental purpose, the reason why we created MVLink.

522
00:36:02,370 --> 00:36:04,412
Well, one of the most important things that's

523
00:36:04,413 --> 00:36:07,490
happening in the world of enterprise is agentic AI.

524
00:36:08,090 --> 00:36:11,830
Agentic AI, basically, is a perfect example of test time scaling.

525
00:36:12,710 --> 00:36:14,810
AI is a system of models.

526
00:36:15,490 --> 00:36:17,390
Some of it is understanding, interacting

527
00:36:17,391 --> 00:36:19,450
with the customer, interacting with the user.

528
00:36:19,610 --> 00:36:22,670
Some of it is maybe retrieving information, retrieving

529
00:36:22,671 --> 00:36:26,990
information from storage, a semantic AI system like a RAG.

530
00:36:27,330 --> 00:36:29,530
Maybe it's going on to the Internet.

531
00:36:29,810 --> 00:36:32,530
Maybe it's studying a PDF file.

532
00:36:32,730 --> 00:36:34,350
And so it might be using tools.

533
00:36:34,410 --> 00:36:35,650
It might be using a calculator.

534
00:36:35,790 --> 00:36:40,170
And it might be using a generative AI to generate charts and such.

535
00:36:40,410 --> 00:36:44,690
And it's taking the problem you gave it, breaking it down step by step,

536
00:36:45,490 --> 00:36:46,966
integrating through all these different models.

537
00:36:46,990 --> 00:36:51,190
Well, in order to respond to a customer in the future, in order for AI to respond,

538
00:36:51,410 --> 00:36:55,010
it used to be ask a question, answer starts spewing out.

539
00:36:55,130 --> 00:36:57,312
In the future, you ask a question, a whole bunch of

540
00:36:57,313 --> 00:36:59,291
models are going to be working in the background.

541
00:36:59,350 --> 00:37:04,970
And so test time scaling, the amount of computation used for inferencing,

542
00:37:05,110 --> 00:37:06,750
is going to go through the roof.

543
00:37:07,170 --> 00:37:10,046
It's going to go through the roof because we want better and better answers.

544
00:37:10,070 --> 00:37:14,283
Well, to help the industry build agentic AI, our

545
00:37:14,284 --> 00:37:17,030
go-to-market is not direct to enterprise customers.

546
00:37:17,270 --> 00:37:22,750
Our go-to-market is we work with software developers in the IT ecosystem to

547
00:37:22,751 --> 00:37:25,521
integrate our technology to make possible new

548
00:37:25,522 --> 00:37:28,711
capabilities, just like we did with CUDA libraries.

549
00:37:28,750 --> 00:37:32,230
We now want to do that with AI libraries.

550
00:37:32,790 --> 00:37:38,570
And just as the computing model of the past has APIs that are doing computer

551
00:37:38,571 --> 00:37:42,970
graphics or doing linear algebra or doing fluid dynamics, in the future,

552
00:37:42,971 --> 00:37:46,244
on top of those acceleration libraries, CUDA

553
00:37:46,245 --> 00:37:49,270
acceleration libraries, we'll have AI libraries.

554
00:37:49,630 --> 00:37:54,110
We've created three things for helping the ecosystem build agentic AI.

555
00:37:54,490 --> 00:38:00,110
NVIDIA NIMS, which are essentially AI microservices all packaged up.

556
00:38:00,230 --> 00:38:05,910
It takes all of this really complicated CUDA software, CUDA DNN, Cutlass,

557
00:38:05,950 --> 00:38:12,190
or Tensor RTLM, or Triton, or all of these different really complicated software,

558
00:38:12,191 --> 00:38:16,530
and the model itself, we package it up, we optimize it, we put it into a

559
00:38:16,531 --> 00:38:18,670
container, and you can take it wherever you like.

560
00:38:18,870 --> 00:38:23,210
And so we have models for vision, for understanding languages, for speech,

561
00:38:23,410 --> 00:38:26,867
for animation, for digital biology, and we have

562
00:38:26,868 --> 00:38:29,630
some new exciting models coming for physical AI.

563
00:38:29,870 --> 00:38:33,710
And these AI models run in every single cloud, because

564
00:38:33,711 --> 00:38:36,271
NVIDIA's GPUs are now available in every single cloud.

565
00:38:36,370 --> 00:38:37,930
It's available in every single OEM.

566
00:38:38,070 --> 00:38:42,170
So you could literally take these models, integrate it into your software package,

567
00:38:42,190 --> 00:38:48,970
create AI agents that run on Cadence, or they might be ServiceNow agents,

568
00:38:49,150 --> 00:38:53,870
or they might be SAP agents, and they could deploy it to their customers and run

569
00:38:53,871 --> 00:38:55,871
it wherever the customers want to run the software.

570
00:38:56,010 --> 00:38:58,430
The next layer is what we call NVIDIA Nemo.

571
00:38:58,910 --> 00:39:09,390
Nemo is essentially a digital employee onboarding and training evaluation system.

572
00:39:10,470 --> 00:39:16,190
In the future, these AI agents are essentially digital workforce that are

573
00:39:16,191 --> 00:39:20,990
working alongside your employees, doing things for you on your behalf.

574
00:39:21,290 --> 00:39:27,170
And so the way that you would bring these specialized agents, these special agents,

575
00:39:27,290 --> 00:39:31,590
into your company is to onboard them, just like you onboard an employee.

576
00:39:32,170 --> 00:39:37,670
And so we have different libraries that help these AI agents be trained for the

577
00:39:37,671 --> 00:39:42,790
type of language in your company, maybe the vocabulary is unique to your

578
00:39:42,791 --> 00:39:46,010
company, the business process is different, the way you work is different.

579
00:39:46,150 --> 00:39:49,730
So you would give them examples of what the work product should look like,

580
00:39:49,790 --> 00:39:52,350
and they would try to generate it, and you would give a feedback.

581
00:39:52,530 --> 00:39:55,230
And then you would evaluate them, so on and so forth.

582
00:39:55,450 --> 00:39:57,910
And you would guardrail them.

583
00:39:58,010 --> 00:39:59,826
You say, these are the things that you're not allowed to do.

584
00:39:59,850 --> 00:40:01,690
These are the things you're not allowed to say.

585
00:40:01,870 --> 00:40:04,790
And we even give them access to certain information.

586
00:40:05,610 --> 00:40:11,350
So that entire pipeline, digital employee pipeline, The last line is called Nemo.

587
00:40:11,530 --> 00:40:15,834
In a lot of ways, the IT department of every company is

588
00:40:15,835 --> 00:40:19,310
going to be the HR department of AI agents in the future.

589
00:40:20,310 --> 00:40:25,830
Today, they manage and maintain a bunch of software from the IT industry.

590
00:40:26,050 --> 00:40:31,690
In the future, they will maintain, nurture, onboard, and improve a whole

591
00:40:31,691 --> 00:40:34,990
bunch of digital agents and provision them to the companies to use.

592
00:40:34,991 --> 00:40:40,270
And so your IT department is going to become kind of like AI agent HR.

593
00:40:41,090 --> 00:40:44,137
And on top of that, we provide a whole bunch of

594
00:40:44,138 --> 00:40:48,070
blueprints that our ecosystem could take advantage of.

595
00:40:48,170 --> 00:40:51,128
All of this is completely open source, and so

596
00:40:51,129 --> 00:40:53,470
you could take it and modify the blueprints.

597
00:40:53,530 --> 00:40:55,970
We have blueprints for all kinds of different types of agents.

598
00:40:56,370 --> 00:40:58,873
Well today, we're also announcing that we're doing

599
00:40:58,874 --> 00:41:01,231
something that's really cool and I think really clever.

600
00:41:01,730 --> 00:41:04,570
We're announcing a whole family of models.

601
00:41:04,990 --> 00:41:06,790
That are based off of LAMA.

602
00:41:06,930 --> 00:41:11,410
The NVIDIA LAMA NEMOTRON language foundation models.

603
00:41:11,930 --> 00:41:15,790
LAMA 3.1 is a complete phenomenon.

604
00:41:16,850 --> 00:41:22,370
The download of LAMA 3.1 from Meta, 650,000 times.

605
00:41:22,710 --> 00:41:23,870
Something like that.

606
00:41:24,190 --> 00:41:29,410
It has been derived and turned into other models.

607
00:41:29,650 --> 00:41:32,330
About 60,000 other different models.

608
00:41:32,550 --> 00:41:34,910
It is singularly the reason.

609
00:41:34,990 --> 00:41:37,467
Why just about every single enterprise and every single

610
00:41:37,468 --> 00:41:39,710
industry has been activated to start working on AI.

611
00:41:40,050 --> 00:41:43,643
Well the thing that we did was we realized that the LAMA

612
00:41:43,644 --> 00:41:47,370
models really could be better fine tuned for enterprise use.

613
00:41:47,790 --> 00:41:51,190
And so we fine tuned them using our expertise and our capabilities.

614
00:41:51,550 --> 00:41:56,470
And we turned them into the LAMA NEMOTRON suite of open models.

615
00:41:57,070 --> 00:42:02,170
There are small ones that interact in very fast response time.

616
00:42:02,730 --> 00:42:03,370
Extremely small.

617
00:42:03,371 --> 00:42:06,330
They are what we call super.

618
00:42:06,910 --> 00:42:08,210
LAMA NEMOTRON supers.

619
00:42:08,630 --> 00:42:11,450
They are basically your mainstream versions of your models.

620
00:42:11,570 --> 00:42:13,150
Or your ultra model.

621
00:42:13,330 --> 00:42:16,218
The ultra model could be used to be a teacher

622
00:42:16,219 --> 00:42:18,530
model for a whole bunch of other models.

623
00:42:18,710 --> 00:42:20,270
It could be a reward model.

624
00:42:20,610 --> 00:42:21,150
Evaluator.

625
00:42:21,550 --> 00:42:24,337
A judge for other models to create answers

626
00:42:24,338 --> 00:42:27,150
and decide whether it is a good answer or not.

627
00:42:27,530 --> 00:42:29,530
Basically give feedback to other models.

628
00:42:29,750 --> 00:42:31,486
It could be distilled in a lot of different ways.

629
00:42:31,510 --> 00:42:32,890
Basically a teacher model.

630
00:42:32,891 --> 00:42:35,910
A knowledge distillation model.

631
00:42:36,270 --> 00:42:37,250
Very large.

632
00:42:37,290 --> 00:42:37,870
Very capable.

633
00:42:38,110 --> 00:42:40,650
And so all of this is now available online.

634
00:42:41,070 --> 00:42:44,570
Well, these models are incredible.

635
00:42:44,970 --> 00:42:47,730
It is number one in leader boards for chat.

636
00:42:48,070 --> 00:42:50,290
Leader board for instruction.

637
00:42:51,230 --> 00:42:53,370
Leader board for retrieval.

638
00:42:53,870 --> 00:42:57,069
So the different types of functionalities necessary

639
00:42:57,070 --> 00:42:59,190
that are used in AI agents around the world.

640
00:42:59,370 --> 00:43:01,450
These are going to be incredible models for you.

641
00:43:02,650 --> 00:43:04,950
We are also working with the ecosystem.

642
00:43:05,730 --> 00:43:11,390
All of our NVIDIA AI technologies are integrated into the IT industry.

643
00:43:11,990 --> 00:43:15,590
We have great partners and really great work being done at ServiceNow,

644
00:43:15,710 --> 00:43:19,290
at SAP, at Siemens for industrial AI.

645
00:43:20,310 --> 00:43:21,730
Cadence is doing great work.

646
00:43:21,850 --> 00:43:23,010
Synopsys is doing great work.

647
00:43:23,070 --> 00:43:25,690
I am really proud of the work that we do with Perplexity.

648
00:43:25,730 --> 00:43:27,430
As you know, they revolutionize search.

649
00:43:27,770 --> 00:43:29,470
Really fantastic stuff.

650
00:43:29,890 --> 00:43:30,430
Codium.

651
00:43:30,431 --> 00:43:33,190
Every software engineer in the world.

652
00:43:33,250 --> 00:43:36,870
This is going to be the next giant AI application.

653
00:43:37,310 --> 00:43:41,990
Next giant AI service period is software coding.

654
00:43:42,370 --> 00:43:44,730
30 million software engineers around the world.

655
00:43:45,070 --> 00:43:48,990
Everybody is going to have a software assistant helping them code.

656
00:43:49,470 --> 00:43:52,628
If not, obviously you are going to be way

657
00:43:52,629 --> 00:43:55,810
less productive and create lesser good code.

658
00:43:55,990 --> 00:43:57,730
And so this is 30 million.

659
00:43:57,731 --> 00:44:00,850
There is a billion knowledge workers in the world.

660
00:44:00,990 --> 00:44:02,230
It is very, very clear.

661
00:44:02,550 --> 00:44:06,327
AI agents is probably the next robotics industry and

662
00:44:06,328 --> 00:44:09,291
likely to be a multi-trillion dollar opportunity.

663
00:44:09,510 --> 00:44:14,950
Well, let me show you some of the blueprints that we created and some of the

664
00:44:14,951 --> 00:44:17,750
work that we have done with our partners with these AI agents.

665
00:44:22,530 --> 00:44:25,390
AI agents are the new digital workforce.

666
00:44:25,391 --> 00:44:27,870
Working for and with us.

667
00:44:28,610 --> 00:44:34,690
AI agents are a system of models that reason about a mission, break it down into

668
00:44:34,691 --> 00:44:39,590
tasks, and retrieve data or use tools to generate a quality response.

669
00:44:40,790 --> 00:44:46,410
NVIDIA's agentic AI building blocks, NIM pre-trained models, and Nemo framework

670
00:44:46,411 --> 00:44:51,270
let organizations easily develop AI agents and deploy them anywhere.

671
00:44:51,670 --> 00:44:55,190
We will onboard and train our agentic workforces.

672
00:44:55,191 --> 00:44:56,510
On our company's methods.

673
00:44:56,750 --> 00:44:58,150
Like we do for employees.

674
00:44:58,870 --> 00:45:02,750
AI agents are domain-specific task experts.

675
00:45:03,190 --> 00:45:04,730
Let me show you four examples.

676
00:45:05,370 --> 00:45:10,330
For the billions of knowledge workers and students, AI research assistant agents

677
00:45:10,331 --> 00:45:15,049
ingest complex documents like lectures, journals, financial

678
00:45:15,050 --> 00:45:19,210
results, and generate interactive podcasts for easy learning.

679
00:45:19,450 --> 00:45:24,650
By combining a UNET regression model with a diffusion model, CoreDiff can downscale

680
00:45:24,651 --> 00:45:27,970
global weather forecasts down from 25 km to 2 km.

681
00:45:29,650 --> 00:45:34,670
Developers, like at NVIDIA, manage software security AI agents that

682
00:45:34,671 --> 00:45:37,130
continuously scan software for vulnerabilities.

683
00:45:37,670 --> 00:45:40,630
Alerting developers to what action is needed.

684
00:45:42,550 --> 00:45:48,710
Virtual lab AI agents help researchers design and screen billions of compounds to

685
00:45:48,711 --> 00:45:51,170
find promising drug candidates faster than ever.

686
00:45:52,750 --> 00:45:58,270
NVIDIA Analytics AI Agents, built on an NVIDIA Metropolis Blueprint including

687
00:45:58,271 --> 00:46:02,190
NVIDIA Cosmos Nematron Vision Language Models,

688
00:46:02,191 --> 00:46:05,651
LAMA Nematron LLMs, and Nemo Retriever.

689
00:46:05,970 --> 00:46:10,717
Metropolis Agents analyze content from the billions of

690
00:46:10,718 --> 00:46:14,010
cameras generating 100,000 petabytes of video per day.

691
00:46:14,450 --> 00:46:19,510
They enable interactive search, summarization, and automated reporting.

692
00:46:19,511 --> 00:46:25,670
And help monitor traffic flows, flagging congestion or danger.

693
00:46:27,550 --> 00:46:31,154
In industrial facilities, they monitor processes

694
00:46:31,155 --> 00:46:34,531
and generate recommendations or improvement.

695
00:46:35,550 --> 00:46:39,677
Metropolis Agents centralize data from hundreds of cameras

696
00:46:39,678 --> 00:46:43,410
and can reroute workers or robots when incidents occur.

697
00:46:44,110 --> 00:46:46,610
The age of agentic AI is here.

698
00:46:47,030 --> 00:46:48,770
For every organization.

699
00:46:52,730 --> 00:46:53,730
Okay.

700
00:46:57,100 --> 00:47:00,340
That was the first pitch at a baseball game.

701
00:47:00,420 --> 00:47:01,460
That was not generated.

702
00:47:01,900 --> 00:47:04,020
I just felt that none of you were impressed.

703
00:47:05,740 --> 00:47:11,740
Okay, so AI was created in the cloud and for the cloud.

704
00:47:12,060 --> 00:47:13,880
AI was created in the cloud and for the cloud.

705
00:47:14,020 --> 00:47:18,440
And for enjoying AI on phones, of course, it's perfect.

706
00:47:19,140 --> 00:47:20,220
Very, very soon.

707
00:47:20,900 --> 00:47:23,740
We're going to have a continuous AI that's going to be with you.

708
00:47:23,900 --> 00:47:28,580
And when you use those meta glasses, you could, of course, point at something,

709
00:47:28,680 --> 00:47:31,780
look at something, and ask it, you know, whatever information you want.

710
00:47:32,040 --> 00:47:35,000
And so AI is perfect in the cloud.

711
00:47:35,060 --> 00:47:36,876
What's created in the cloud is perfect in the cloud.

712
00:47:36,900 --> 00:47:40,400
However, we would love to be able to take that AI everywhere.

713
00:47:40,600 --> 00:47:43,341
I've mentioned already that you could take NVIDIA AI to

714
00:47:43,342 --> 00:47:45,840
any cloud, but you could also put it inside your company.

715
00:47:46,040 --> 00:47:49,300
But the thing that we want to do more than anything is put it on our PC as well.

716
00:47:49,301 --> 00:47:54,640
And so, as you know, Windows 95 revolutionized the computer industry.

717
00:47:54,920 --> 00:47:58,350
It made possible this new suite of multimedia services and

718
00:47:58,351 --> 00:48:01,140
it changed the way that applications was created forever.

719
00:48:02,100 --> 00:48:08,100
Windows 95, this model of computing, of course, is not perfect for AI.

720
00:48:08,400 --> 00:48:13,240
And so the thing that we would like to do is we would like to have, in the future,

721
00:48:13,400 --> 00:48:15,760
your AI basically become your AI assistant.

722
00:48:16,060 --> 00:48:19,280
And instead of just the 3D model.

723
00:48:19,281 --> 00:48:23,880
The 3D APIs and the sound APIs and the video APIs, you would have generative APIs.

724
00:48:24,260 --> 00:48:27,239
Generative APIs for 3D and generative APIs for language

725
00:48:27,240 --> 00:48:29,280
and generative AI for sound and so on and so forth.

726
00:48:29,520 --> 00:48:34,093
And we need a system that makes that possible while

727
00:48:34,094 --> 00:48:37,460
leveraging the massive investment that's in the cloud.

728
00:48:37,840 --> 00:48:39,986
There's no way that we could, the world can

729
00:48:39,987 --> 00:48:43,161
create yet another way of programming AI models.

730
00:48:43,380 --> 00:48:44,620
It's just not going to happen.

731
00:48:44,820 --> 00:48:50,448
And so if we could figure out a way to make Windows, a Windows

732
00:48:50,449 --> 00:48:54,900
PC, a world-class AI PC, it would be completely awesome.

733
00:48:55,100 --> 00:48:57,080
And it turns out the answer is Windows.

734
00:48:57,500 --> 00:48:59,980
It's Windows WSL2.

735
00:49:00,200 --> 00:49:02,420
Windows WSL2.

736
00:49:02,500 --> 00:49:06,840
Windows WSL2 basically is two operating systems within one.

737
00:49:07,040 --> 00:49:08,280
It works perfectly.

738
00:49:09,000 --> 00:49:12,005
It's developed for developers and it's developed

739
00:49:12,006 --> 00:49:15,041
so that you can have access to bare metal.

740
00:49:15,200 --> 00:49:17,340
WSL2 has been optimized.

741
00:49:18,620 --> 00:49:19,260
Optimized.

742
00:49:19,280 --> 00:49:21,240
It's been optimized for cloud-native applications.

743
00:49:21,460 --> 00:49:25,840
It is optimized for, and very importantly, it's been optimized for CUDA.

744
00:49:26,160 --> 00:49:30,180
And so WSL2 supports CUDA perfectly out of the box.

745
00:49:30,280 --> 00:49:39,460
As a result, everything that I showed you with NVIDIA NIMS, NVIDIA Nemo,

746
00:49:40,040 --> 00:49:45,174
the blueprints that we developed that are going to be up in AI.nvidia.

747
00:49:45,294 --> 00:49:50,460
com, so long as the computer fits it, so long as you can fit that model,

748
00:49:50,600 --> 00:49:54,400
and we're going to have many models that fit, whether it's vision models or

749
00:49:54,401 --> 00:49:59,220
language models or speech models or these animation digital human models,

750
00:49:59,380 --> 00:50:03,680
all kinds of different types of models are going to be perfect for your PC.

751
00:50:03,980 --> 00:50:07,660
And you download it and it should just run.

752
00:50:07,860 --> 00:50:14,037
And so our focus is to turn Windows WSL2, Windows PC,

753
00:50:14,038 --> 00:50:18,120
into a target first-class platform that we will support.

754
00:50:18,121 --> 00:50:20,500
And maintain for as long as we shall live.

755
00:50:20,640 --> 00:50:24,780
And so this is an incredible thing for engineers and developers everywhere.

756
00:50:25,060 --> 00:50:27,140
Let me show you something that we can do with that.

757
00:50:27,280 --> 00:50:29,800
This is one of the examples of a blueprint we just made for you.

758
00:50:32,640 --> 00:50:37,140
Generative AI synthesizes amazing images from simple text prompts.

759
00:50:37,540 --> 00:50:41,500
Yet image composition can be challenging to control using only words.

760
00:50:41,960 --> 00:50:45,929
With NVIDIA NIMS Microservices, creators can use

761
00:50:45,930 --> 00:50:48,940
simple 3D objects to guide AI image generation.

762
00:50:49,360 --> 00:50:54,400
Let's see how a concept artist can use this technology to develop the look of a scene.

763
00:50:55,160 --> 00:51:00,300
They start by laying out 3D assets, created by hand or generated with AI.

764
00:51:00,620 --> 00:51:04,318
Then use an image generation NIM, such as Flux,

765
00:51:04,319 --> 00:51:07,500
to create a visual that adheres to the 3D scene.

766
00:51:08,340 --> 00:51:11,300
Add or move objects to refine the composition.

767
00:51:13,560 --> 00:51:16,920
Change camera angles to frame the perfect shot.

768
00:51:18,120 --> 00:51:20,860
Or re-imagine the whole scene with a new prompt.

769
00:51:24,960 --> 00:51:30,741
Assisted by Generative AI and NVIDIA NIM, an artist can quickly realize their vision.

770
00:51:33,870 --> 00:51:35,510
NVIDIA AI for your PCs.

771
00:51:38,050 --> 00:51:40,684
Hundreds of millions of PCs in the world with

772
00:51:40,685 --> 00:51:43,930
Windows, and so we could get them ready for AI.

773
00:51:44,810 --> 00:51:47,351
OEMs, all the PC OEMs we work with, just basically all of the

774
00:51:47,352 --> 00:51:50,550
world's leading PC OEMs, are going to get their PCs ready.

775
00:51:50,551 --> 00:51:51,551
Ready for this stack.

776
00:51:51,830 --> 00:51:55,050
And so AI PCs are coming to a home near you.

777
00:52:01,640 --> 00:52:02,660
Linux is good.

778
00:52:08,480 --> 00:52:10,340
Okay, let's talk about physical AI.

779
00:52:12,800 --> 00:52:15,140
Speaking of Linux, let's talk about physical AI.

780
00:52:17,020 --> 00:52:18,580
So, physical AI.

781
00:52:20,380 --> 00:52:21,580
Imagine, imagine.

782
00:52:23,000 --> 00:52:28,900
Whereas your large language model, you give it your context, your prompt,

783
00:52:30,600 --> 00:52:37,540
on the left, and it generates tokens one at a time to produce the output.

784
00:52:38,560 --> 00:52:39,900
That's basically how it works.

785
00:52:40,080 --> 00:52:42,568
The amazing thing is, this model in the middle

786
00:52:42,569 --> 00:52:45,461
is quite large, has billions of parameters.

787
00:52:45,720 --> 00:52:51,020
The context length is incredibly large, because you might decide to load in a PDF.

788
00:52:51,260 --> 00:52:55,120
In my case, I might load in several PDFs before I ask it a question.

789
00:52:55,900 --> 00:52:57,100
Those PDFs are capable of doing that.

790
00:52:57,101 --> 00:53:00,020
So, if I want to turn into tokens, the attention, the basic attention

791
00:53:00,021 --> 00:53:03,873
characteristic of a transformer has every single token find

792
00:53:03,874 --> 00:53:07,140
its relationship and relevance against every other token.

793
00:53:07,900 --> 00:53:13,580
So, you could have hundreds of thousands of tokens, and the computational load

794
00:53:13,581 --> 00:53:19,300
increases quadratically, and it does this, that all of the parameters, all of the

795
00:53:19,301 --> 00:53:22,500
input sequence, process it through every single layer of the transformer,

796
00:53:22,680 --> 00:53:24,260
and it produces one token.

797
00:53:24,600 --> 00:53:26,420
That's the reason why we needed Blackwell.

798
00:53:26,421 --> 00:53:29,280
And then the next token is produced.

799
00:53:29,440 --> 00:53:33,940
When the current token is done, it puts the current token into the input

800
00:53:33,941 --> 00:53:37,540
sequence and takes that whole thing and generates the next token.

801
00:53:37,600 --> 00:53:38,600
It does it one at a time.

802
00:53:39,180 --> 00:53:41,460
This is the transformer model.

803
00:53:41,620 --> 00:53:46,300
It's the reason why it is so incredibly effective, computationally demanding.

804
00:53:46,940 --> 00:53:50,920
What if instead of PDFs, it's your surrounding?

805
00:53:50,960 --> 00:53:54,940
And what if instead of the prompt, a question, it's a request?

806
00:53:54,941 --> 00:53:58,700
Go over there and pick up that, you know, that box and bring it back.

807
00:53:59,000 --> 00:54:04,860
And instead of what is produced in tokens as text, it produces action tokens.

808
00:54:05,740 --> 00:54:11,260
Well, that, I just described, is a very sensible thing for the future of robotics.

809
00:54:12,060 --> 00:54:14,240
And the technology is right around the corner.

810
00:54:14,440 --> 00:54:18,760
But what we need to do is we need to create the effective, effectively,

811
00:54:18,940 --> 00:54:25,600
the world model of, you know, as opposed to GPT, which is a language model.

812
00:54:25,820 --> 00:54:29,220
And this world model has to understand the language of the world.

813
00:54:29,300 --> 00:54:31,320
It has to understand physical dynamics.

814
00:54:32,160 --> 00:54:35,340
Things like gravity and friction and inertia.

815
00:54:35,760 --> 00:54:38,960
It has to understand geometric and spatial relationships.

816
00:54:39,440 --> 00:54:41,080
It has to understand cause and effect.

817
00:54:41,320 --> 00:54:43,184
If you drop something and it falls to the ground,

818
00:54:43,185 --> 00:54:45,661
if you, you know, poke at it and it tips over.

819
00:54:46,020 --> 00:54:48,240
It has to understand object permanence.

820
00:54:49,020 --> 00:54:51,307
If you roll a ball over the kitchen counter when

821
00:54:51,347 --> 00:54:53,820
it goes off the other side, the ball didn't leave.

822
00:54:53,821 --> 00:54:56,840
We're going to move into another quantum universe that's still there.

823
00:54:57,080 --> 00:55:01,140
And so all of these types of understanding, intuitive understanding

824
00:55:01,141 --> 00:55:05,260
that we know, that most models today have a very hard time with.

825
00:55:05,480 --> 00:55:09,720
And so we would like to create a world, we need a world foundation model.

826
00:55:09,900 --> 00:55:12,240
Today we're announcing a very big thing.

827
00:55:12,640 --> 00:55:19,140
We're announcing NVIDIA Cosmos, a world foundation model that is designed,

828
00:55:19,360 --> 00:55:22,480
that was created to understand the physical world.

829
00:55:22,481 --> 00:55:25,780
And the only way for you to really understand this is to see it.

830
00:55:25,820 --> 00:55:26,820
Let's play it.

831
00:55:33,040 --> 00:55:36,300
The next frontier of AI is physical AI.

832
00:55:36,780 --> 00:55:40,640
Model performance is directly related to data availability.

833
00:55:41,160 --> 00:55:45,760
But physical world data is costly to capture, curate, and label.

834
00:55:47,160 --> 00:55:53,326
NVIDIA Cosmos is a world foundation model development platform to advance physical world data.

835
00:55:53,953 --> 00:55:58,440
It includes auto-regressive world foundation models, diffusion-based world

836
00:55:58,441 --> 00:56:02,172
foundation models, advanced tokenizers, and an

837
00:56:02,173 --> 00:56:06,161
NVIDIA CUDA, an AI-accelerated data pipeline.

838
00:56:08,060 --> 00:56:11,755
Cosmos models ingest text, image, or video prompts,

839
00:56:11,756 --> 00:56:14,460
and generate virtual world states as videos.

840
00:56:15,480 --> 00:56:20,880
Cosmos generations prioritize the unique requirements of AV and robotics use cases,

841
00:56:21,060 --> 00:56:22,460
like real-world data.

842
00:56:22,480 --> 00:56:25,760
They build environments, lighting, and object permanence.

843
00:56:26,800 --> 00:56:32,180
Developers use NVIDIA Omniverse to build physics-based, geospatially accurate

844
00:56:32,181 --> 00:56:38,100
scenarios, then output Omniverse renders into Cosmos, which generates photoreal,

845
00:56:38,220 --> 00:56:40,340
physically-based synthetic data.

846
00:56:51,400 --> 00:56:57,494
Whether diverse objects, or environments, conditions

847
00:56:57,495 --> 00:57:02,980
like weather, or time of day, or edge case scenarios.

848
00:57:05,340 --> 00:57:11,120
Developers use Cosmos to generate worlds for reinforcement learning AI feedback to

849
00:57:11,121 --> 00:57:16,160
improve policy models, or to test and validate model performance.

850
00:57:17,700 --> 00:57:19,840
Even across multi-sensor views.

851
00:57:22,500 --> 00:57:26,061
Cosmos can generate tokens in real-time, bringing the

852
00:57:26,062 --> 00:57:30,160
power of foresight and multiverse simulation to AI models.

853
00:57:30,740 --> 00:57:34,940
Generating every possible future, to help the model select the right path.

854
00:57:36,700 --> 00:57:40,165
Working with the world's developer ecosystem, NVIDIA

855
00:57:40,166 --> 00:57:43,420
is helping advance the next wave of physical AI.

856
00:57:49,050 --> 00:57:50,430
NVIDIA Cosmos.

857
00:57:52,310 --> 00:57:53,710
NVIDIA Cosmos.

858
00:57:54,550 --> 00:57:55,810
NVIDIA Cosmos.

859
00:57:55,970 --> 00:57:59,230
The world's first, world foundation model.

860
00:57:59,690 --> 00:58:04,250
It is trained on 20 million hours of video.

861
00:58:04,770 --> 00:58:09,990
The 20 million hours of video focuses on physical, dynamic things.

862
00:58:10,190 --> 00:58:20,211
So, dynamic nature, nature themes, humans walking, hands moving, manipulating things.

863
00:58:20,350 --> 00:58:23,630
You know, things that are fast camera movements.

864
00:58:23,790 --> 00:58:28,150
It's really about teaching the AI, not about generating creative content,

865
00:58:28,390 --> 00:58:31,350
but teaching the AI to understand the physical world.

866
00:58:31,351 --> 00:58:34,821
And from this, with this physical AI, there are

867
00:58:34,822 --> 00:58:39,070
many downstream things that we could do as a result.

868
00:58:39,190 --> 00:58:42,550
We could do synthetic data generation to train models.

869
00:58:42,850 --> 00:58:46,028
We could distill it and turn it into, effectively,

870
00:58:46,029 --> 00:58:48,290
the seed, the beginnings of a robotics model.

871
00:58:48,550 --> 00:58:54,050
You could have it generate multiple physically based, physically plausible.

872
00:58:55,050 --> 00:58:56,370
scenarios of the future.

873
00:58:56,490 --> 00:58:57,770
Basically do a Doctor Strange.

874
00:58:58,530 --> 00:59:02,430
You could, because, because this model understands the physical world,

875
00:59:02,530 --> 00:59:05,830
of course you saw a whole bunch of images generated, this model understanding the

876
00:59:05,831 --> 00:59:09,790
physical world, it also could do, of course, captioning.

877
00:59:09,850 --> 00:59:15,910
And so it could take videos, caption it incredibly well, and that captioning and

878
00:59:15,911 --> 00:59:20,430
the video could be used to train large language models.

879
00:59:21,370 --> 00:59:23,250
Multi-modality, large language models.

880
00:59:23,730 --> 00:59:28,350
And so you could use this technology to use this foundation model to train

881
00:59:28,351 --> 00:59:33,430
robotics, robots, And so this is the NVIDIA Cosmos.

882
00:59:33,610 --> 00:59:38,530
The platform has an autoregressive model for real-time applications, has diffusion

883
00:59:38,531 --> 00:59:43,310
model for a very high quality image generation, it's incredible tokenizer,

884
00:59:43,430 --> 00:59:49,530
basically learning the vocabulary of real world, and a data pipeline so that if you

885
00:59:49,531 --> 00:59:53,530
would like to take all of this and then train it on your own data, this data

886
00:59:53,531 --> 00:59:55,745
pipeline, because there's so much data involved,

887
00:59:55,746 --> 00:59:58,010
we've accelerated everything end-to-end for you.

888
00:59:58,011 --> 01:00:01,559
And so this is the world's first data processing pipeline

889
01:00:01,560 --> 01:00:04,110
that's CUDA accelerated as well as AI accelerated.

890
01:00:04,410 --> 01:00:07,030
All of this is part of the Cosmos platform.

891
01:00:07,290 --> 01:00:11,030
And today we're announcing that Cosmos is open licensed.

892
01:00:11,330 --> 01:00:13,030
It's open available on GitHub.

893
01:00:20,420 --> 01:00:28,020
We hope that this moment, and there's a small, medium, large for very fast models,

894
01:00:28,260 --> 01:00:31,460
you know, mainstream models, and also teacher models, basically.

895
01:00:31,680 --> 01:00:33,200
Not knowledge transfer models.

896
01:00:33,480 --> 01:00:40,500
Cosmos World Foundation model being open, we really hope will do for the world of

897
01:00:40,501 --> 01:00:44,760
robotics and industrial AI what LAMA3 has done for enterprise AI.

898
01:00:45,360 --> 01:00:50,720
The magic happens when you connect Cosmos to Omniverse.

899
01:00:50,940 --> 01:00:52,620
And the reason fundamentally is this.

900
01:00:53,580 --> 01:00:57,620
Omniverse is a physics grounded.

901
01:00:57,740 --> 01:01:00,800
Not physically grounded, but physics grounded.

902
01:01:00,801 --> 01:01:05,720
It's algorithmic physics, principled physics simulation grounded system.

903
01:01:06,060 --> 01:01:07,060
It's a simulator.

904
01:01:07,460 --> 01:01:13,760
When you connect that to Cosmos, it provides the grounding, the ground

905
01:01:13,761 --> 01:01:18,200
truth that can control and to condition the Osmos generation.

906
01:01:18,800 --> 01:01:21,820
As a result, what comes out of Osmos is grounded on truth.

907
01:01:22,080 --> 01:01:26,860
This is exactly the same idea as connecting a large language model to a

908
01:01:26,861 --> 01:01:29,920
RAG, to a retrieval augmented generation system.

909
01:01:29,921 --> 01:01:33,840
You want to ground the AI generation on ground truth.

910
01:01:34,040 --> 01:01:38,466
And so the combination of the two gives you a physically

911
01:01:38,467 --> 01:01:43,720
simulated, a physically grounded multiverse generator.

912
01:01:44,460 --> 01:01:47,740
And the application, the use cases are really quite exciting.

913
01:01:48,060 --> 01:01:53,920
And of course, for robotics, for industrial applications, it is very, very clear.

914
01:01:54,260 --> 01:01:59,380
This Cosmos plus Omniverse plus Cosmos.

915
01:01:59,381 --> 01:02:03,800
represents the third computer that's necessary for building robotic systems.

916
01:02:04,680 --> 01:02:08,480
Every robotics company will ultimately have to build three computers.

917
01:02:08,720 --> 01:02:12,560
The robotics system could be a factory, the robotics system could be a car,

918
01:02:12,700 --> 01:02:13,380
it could be a robot.

919
01:02:13,600 --> 01:02:15,840
You need three fundamental computers.

920
01:02:16,080 --> 01:02:18,220
One computer, of course, to train the AI.

921
01:02:18,600 --> 01:02:21,660
We call it the DGX computer to train the AI.

922
01:02:21,960 --> 01:02:25,720
Another, of course, when you're done, to deploy the AI.

923
01:02:25,860 --> 01:02:27,420
We call that AGX.

924
01:02:27,421 --> 01:02:33,000
That's inside the car, in the robot, or in an AMR, or in a stadium,

925
01:02:33,140 --> 01:02:34,000
or whatever it is.

926
01:02:34,120 --> 01:02:37,660
These computers are at the edge and they're autonomous.

927
01:02:38,200 --> 01:02:40,980
But to connect the two, you need a digital twin.

928
01:02:41,280 --> 01:02:43,420
And this is all the simulations that you were seeing.

929
01:02:43,640 --> 01:02:49,160
The digital twin is where the AI that has been trained goes to practice.

930
01:02:49,460 --> 01:02:50,600
To be refined.

931
01:02:50,920 --> 01:02:52,840
To do its synthetic data generation.

932
01:02:53,520 --> 01:02:55,120
Reinforcement learning AI feedback.

933
01:02:55,380 --> 01:02:56,080
Such and such.

934
01:02:56,081 --> 01:02:58,500
And so it's the digital twin of the AI.

935
01:02:58,840 --> 01:03:01,600
These three computers are going to be working interactively.

936
01:03:01,860 --> 01:03:06,440
NVIDIA's strategy for the industrial world, and we've been talking about this

937
01:03:06,441 --> 01:03:09,020
for some time, is this three-computer system.

938
01:03:10,020 --> 01:03:14,100
You know, instead of a three-body problem, we have a three-computer solution.

939
01:03:14,740 --> 01:03:17,160
And so, it's the NVIDIA of robotics.

940
01:03:23,560 --> 01:03:25,400
So let me give you three examples.

941
01:03:25,940 --> 01:03:28,360
Alright, so the first example is...

942
01:03:29,560 --> 01:03:34,400
how we apply all of this to industrial digitalization.

943
01:03:34,800 --> 01:03:39,080
There are millions of factories, hundreds of thousands of warehouses.

944
01:03:39,160 --> 01:03:44,540
That basically is the backbone of a $50 trillion manufacturing industry.

945
01:03:44,940 --> 01:03:47,080
All of that has to become software defined.

946
01:03:47,420 --> 01:03:50,820
All of it has to have automation in the future.

947
01:03:51,000 --> 01:03:53,100
And all of it will be infused with robotics.

948
01:03:53,580 --> 01:03:58,520
Well, we're partnering with Kion, the world's leading warehouse,

949
01:03:59,560 --> 01:04:02,857
automation solutions provider, and Accenture, the

950
01:04:02,858 --> 01:04:05,460
world's largest professional services provider.

951
01:04:05,740 --> 01:04:08,980
And they have a big focus in digital manufacturing.

952
01:04:09,360 --> 01:04:13,300
And we're working together to create something that's really special.

953
01:04:13,420 --> 01:04:14,616
And I'll show you that in a second.

954
01:04:14,640 --> 01:04:19,080
But our go-to-market is essentially the same as all of the other software

955
01:04:19,081 --> 01:04:21,900
platforms and all the technology platforms that we have.

956
01:04:22,020 --> 01:04:30,700
Through the developers and ecosystem partners, we have just a growing number of

957
01:04:30,701 --> 01:04:33,080
ecosystem partners connecting to Omniverse.

958
01:04:33,320 --> 01:04:34,880
And the reason for that is very clear.

959
01:04:35,080 --> 01:04:37,840
Everybody wants to digitalize the future of industries.

960
01:04:38,180 --> 01:04:41,543
There's so much waste, so much opportunity for

961
01:04:41,544 --> 01:04:44,620
automation in that $50 trillion of the world's GDP.

962
01:04:45,060 --> 01:04:50,060
So let's take a look at this one example that we're doing with Kion and Accenture.

963
01:04:52,980 --> 01:04:53,580
Kion.

964
01:04:53,581 --> 01:04:55,920
The supply chain solution company.

965
01:04:56,380 --> 01:04:57,260
Accenture.

966
01:04:57,380 --> 01:04:59,660
A global leader in professional services.

967
01:04:59,980 --> 01:05:00,980
And Nvidia.

968
01:05:01,120 --> 01:05:07,901
Are bringing physical AI to the $1 trillion warehouse and distribution center market.

969
01:05:08,100 --> 01:05:12,980
Managing high-performance warehouse logistics involves navigating a complex

970
01:05:12,981 --> 01:05:16,760
web of decisions influenced by constantly shifting variables.

971
01:05:17,140 --> 01:05:22,680
These include daily and seasonal demand changes, space constraints, workforce

972
01:05:22,681 --> 01:05:27,800
availability, and the integration of diverse robotic and automated systems.

973
01:05:28,060 --> 01:05:34,440
And predicting operational KPIs of a physical warehouse is nearly impossible today.

974
01:05:34,860 --> 01:05:40,260
To tackle these challenges, Kion is adopting Mega, an Nvidia Omniverse

975
01:05:40,261 --> 01:05:45,780
blueprint for building industrial digital twins to test and optimize robotic fleets.

976
01:05:46,080 --> 01:05:51,620
First, Kion's warehouse management solution assigns tasks to the industrial

977
01:05:51,621 --> 01:05:55,075
AI brains in the digital twin, such as moving a load

978
01:05:55,076 --> 01:05:58,080
from a buffer location to a shuttle storage solution.

979
01:05:58,820 --> 01:06:04,320
The robots' brains are in a simulation of a physical warehouse, digitalized into

980
01:06:04,321 --> 01:06:10,880
Omniverse using OpenUSD connectors to aggregate CAD, video and image to 3D,

981
01:06:11,120 --> 01:06:15,060
LIDAR to point cloud, and AI-generated data.

982
01:06:15,280 --> 01:06:20,960
The fleet of robots execute tasks by perceiving and reasoning about their

983
01:06:20,961 --> 01:06:25,360
Omniverse digital twin environment, planning their next motion and acting.

984
01:06:25,980 --> 01:06:29,429
The robot brains can see the resulting state through

985
01:06:29,430 --> 01:06:32,060
sensor simulations and decide their next action.

986
01:06:32,300 --> 01:06:35,838
The loop continues while Mega precisely tracks

987
01:06:35,839 --> 01:06:38,540
the state of everything in the digital twin.

988
01:06:38,920 --> 01:06:45,820
Now, Kion can simulate infinite scenarios at scale while measuring operational KPIs,

989
01:06:46,000 --> 01:06:50,096
such as throughput, efficiency, and utilization, all

990
01:06:50,097 --> 01:06:52,820
before deploying changes to the physical warehouse.

991
01:06:53,860 --> 01:06:59,480
Together with NVIDIA, Kion and Accenture are reinventing industrial autonomy.

992
01:07:02,460 --> 01:07:03,480
That's incredible.

993
01:07:03,660 --> 01:07:04,780
Everything is in simulation.

994
01:07:05,640 --> 01:07:11,980
In the future, in the future, every factory will have a digital twin.

995
01:07:12,160 --> 01:07:15,680
And that digital twin operates exactly like the real factory.

996
01:07:15,880 --> 01:07:19,448
And in fact, you could use Omniverse with Cosmos

997
01:07:19,449 --> 01:07:22,420
to generate a whole bunch of future scenarios.

998
01:07:22,660 --> 01:07:25,370
And you pick, then an AI decides which one of the

999
01:07:25,371 --> 01:07:28,460
scenarios are the most optimal for whatever KPIs.

1000
01:07:28,620 --> 01:07:32,440
And that becomes the programming, constrains the program, if you will,

1001
01:07:32,560 --> 01:07:35,620
the AIs that will be deployed into the real factories.

1002
01:07:35,820 --> 01:07:37,660
The next example, autonomous vehicles.

1003
01:07:37,960 --> 01:07:40,260
The AV revolution has arrived.

1004
01:07:40,920 --> 01:07:46,460
After so many years, with Waymo's success and Tesla's success, it is very,

1005
01:07:46,520 --> 01:07:49,460
very clear, autonomous vehicles has finally arrived.

1006
01:07:49,820 --> 01:07:53,600
Well, our offering to this industry is the three computers.

1007
01:07:53,780 --> 01:07:59,060
The training systems, to train the AIs, the simulation systems, and the synthetic

1008
01:07:59,061 --> 01:08:02,150
data generation systems, Omniverse and now Cosmos,

1009
01:08:02,151 --> 01:08:04,921
and also the computer that's inside the car.

1010
01:08:05,420 --> 01:08:08,394
Each car company might work with us in a different

1011
01:08:08,395 --> 01:08:10,400
way, use one or two or three of the computers.

1012
01:08:10,600 --> 01:08:14,340
We're working with just about every major car company around the world.

1013
01:08:14,500 --> 01:08:17,940
Waymo and Zoom, Zooks and Tesla, of course, and their data center.

1014
01:08:18,200 --> 01:08:21,100
BYD, the largest EV company in the world.

1015
01:08:21,200 --> 01:08:23,080
JLR has got a really cool car coming.

1016
01:08:23,260 --> 01:08:26,031
Mercedes has got a fleet of cars coming, with

1017
01:08:26,032 --> 01:08:28,280
NVIDIA starting this year going to production.

1018
01:08:28,540 --> 01:08:34,640
And I'm super, super pleased to announce that today, Toyota and NVIDIA are going to

1019
01:08:34,641 --> 01:08:37,160
partner together to create their next generation AVs.

1020
01:08:44,470 --> 01:08:46,670
Just so many, so many cool companies.

1021
01:08:47,210 --> 01:08:53,030
Lucid and Rivian and Xiaomi, and of course, Volvo, just so many different companies.

1022
01:08:53,230 --> 01:08:55,710
Wabi is building self-driving trucks.

1023
01:08:55,990 --> 01:08:58,668
Aurora, we announced this week also that Aurora is

1024
01:08:58,669 --> 01:09:01,151
going to use NVIDIA to build self-driving trucks.

1025
01:09:02,030 --> 01:09:08,250
Autonomous, 100 million cars built each year, a billion cars, vehicles on the road

1026
01:09:08,251 --> 01:09:11,930
all over the world, a trillion miles that are driven around the world each year.

1027
01:09:12,970 --> 01:09:16,001
That's all going to be either highly autonomous

1028
01:09:16,002 --> 01:09:18,630
or, you know, fully autonomous coming up.

1029
01:09:18,770 --> 01:09:21,230
And so this is going to be a very large, very large industry.

1030
01:09:21,410 --> 01:09:26,890
I predict that this will likely be the first multi-trillion dollar robotics industry.

1031
01:09:27,150 --> 01:09:34,550
This business for us, notice in just a few of these cars that are starting to ramp

1032
01:09:34,551 --> 01:09:38,650
into the world, our business is already four billion dollars, and this year,

1033
01:09:38,770 --> 01:09:40,830
probably on a run rate about five billion dollars.

1034
01:09:40,990 --> 01:09:42,730
So really significant business already.

1035
01:09:42,870 --> 01:09:43,966
This is going to be very large.

1036
01:09:43,990 --> 01:09:48,550
Well, today we're announcing that our next generation processor for the car,

1037
01:09:48,551 --> 01:09:51,690
our next generation computer for the car, is called Thor.

1038
01:09:51,950 --> 01:09:53,030
I have one right here.

1039
01:09:53,110 --> 01:09:54,110
Hang on a second.

1040
01:09:56,620 --> 01:09:57,800
Okay, this is Thor.

1041
01:09:59,060 --> 01:10:00,060
This is Thor.

1042
01:10:01,580 --> 01:10:05,120
This is, this is a robotics computer.

1043
01:10:06,300 --> 01:10:07,900
This is a robotics computer.

1044
01:10:08,040 --> 01:10:14,180
It takes sensors, just a madness amount of sensor information, processes it,

1045
01:10:16,340 --> 01:10:22,620
umpteen cameras, high resolution, radars, lidars, they're all coming into this chip.

1046
01:10:22,740 --> 01:10:26,760
And this chip has to process all that sensor, turn them into tokens,

1047
01:10:27,000 --> 01:10:30,820
put them into a transformer, and predict the next path.

1048
01:10:31,320 --> 01:10:35,240
And this AV computer is now in full production.

1049
01:10:35,540 --> 01:10:41,840
Thor is 20 times the processing capability of our last generation Orin, which is

1050
01:10:41,841 --> 01:10:44,220
really the standard of autonomous vehicles today.

1051
01:10:44,480 --> 01:10:47,240
And so this is just really quite, quite incredible.

1052
01:10:47,440 --> 01:10:48,680
Thor is in full production.

1053
01:10:48,681 --> 01:10:52,220
This robotics processor, by the way, also goes into a full robot.

1054
01:10:52,420 --> 01:10:57,200
And so it could be an AMR, it could be a human or robot, it could be the brain,

1055
01:10:57,340 --> 01:10:58,840
it could be the manipulator.

1056
01:10:59,120 --> 01:11:03,640
This processor basically is a universal robotics computer.

1057
01:11:05,080 --> 01:11:08,024
The second part of our Drive system that I'm

1058
01:11:08,025 --> 01:11:11,701
incredibly proud of is the dedication to safety.

1059
01:11:12,340 --> 01:11:18,120
Drive OS, I'm pleased to announce, is now the first software-defined.

1060
01:11:18,820 --> 01:11:25,320
programmable AI computer that has been certified up to ASIL-D, which is the

1061
01:11:25,321 --> 01:11:29,860
highest standard of functional safety for automobiles.

1062
01:11:30,100 --> 01:11:31,820
The only and the highest.

1063
01:11:32,080 --> 01:11:33,900
And so I'm really, really proud of this.

1064
01:11:34,060 --> 01:11:36,540
ASIL-D, ISO 26262.

1065
01:11:36,920 --> 01:11:41,260
It is the work of some 15,000 engineering years.

1066
01:11:41,880 --> 01:11:43,860
This is just extraordinary work.

1067
01:11:44,020 --> 01:11:48,700
And as a result of that, CUDA is now a functional, safe computer.

1068
01:11:49,820 --> 01:11:52,900
And so if you're building a robot, NVIDIA CUDA, yup.

1069
01:11:57,850 --> 01:12:02,510
Okay, so now I wanted to, I told you I was going to show you what would we use

1070
01:12:02,511 --> 01:12:08,350
Omniverse and Cosmos to do in the context of self-driving cars.

1071
01:12:09,030 --> 01:12:14,170
And, you know, today, instead of showing you a whole bunch of videos of cars

1072
01:12:14,171 --> 01:12:16,610
driving on the road, I'll show you some of that too.

1073
01:12:17,230 --> 01:12:23,370
But I want to show you how we use the cars to reconstruct digital twins automatically

1074
01:12:23,371 --> 01:12:29,370
using AI and use that capability to train future AI models.

1075
01:12:29,610 --> 01:12:30,610
Okay, let's play it.

1076
01:12:34,180 --> 01:12:37,180
The autonomous vehicle revolution is here.

1077
01:12:37,760 --> 01:12:43,400
Building autonomous vehicles, like all robots, requires three computers.

1078
01:12:43,780 --> 01:12:46,700
NVIDIA DGX to train AI models.

1079
01:12:47,020 --> 01:12:50,320
Omniverse to test drive and generate synthetic data.

1080
01:12:50,460 --> 01:12:54,400
And Drive AGX, a supercomputer in the car.

1081
01:12:55,080 --> 01:12:59,320
Building safe autonomous vehicles means addressing edge scenarios.

1082
01:13:00,070 --> 01:13:06,341
But real-world data is limited, so synthetic data is essential for training.

1083
01:13:07,090 --> 01:13:12,480
The autonomous vehicle data factory, powered by NVIDIA Omniverse, AI models,

1084
01:13:12,680 --> 01:13:16,681
and Cosmos, generates synthetic driving scenarios

1085
01:13:16,682 --> 01:13:19,680
that enhance training data by orders of magnitude.

1086
01:13:19,681 --> 01:13:28,981
First, Omnimap fuses map and geospatial data to construct drivable 3D environments.

1087
01:13:31,530 --> 01:13:35,287
Driving scenario variations can be generated

1088
01:13:35,288 --> 01:13:38,411
from replay drive logs or AI traffic generators.

1089
01:13:39,490 --> 01:13:44,530
Next, a neural reconstruction engine uses autonomous vehicle

1090
01:13:44,531 --> 01:13:49,490
sensor logs to create high-fidelity 4D simulation environments.

1091
01:13:49,491 --> 01:13:53,690
It replays previous drives in 3D and generates

1092
01:13:53,691 --> 01:13:57,291
scenario variations to amplify training data.

1093
01:13:58,150 --> 01:14:05,510
Finally, Edify 3DS automatically searches through existing asset libraries or

1094
01:14:05,511 --> 01:14:09,070
generates new assets to create sim-ready scenes.

1095
01:14:12,190 --> 01:14:17,570
The Omniverse scenarios are used to condition Cosmos to generate massive

1096
01:14:17,571 --> 01:14:23,810
amounts of photorealistic data, reducing the sim-to-real gap, and with

1097
01:14:23,811 --> 01:14:29,090
text prompts, generate near-infinite variations of the driving scenario.

1098
01:14:30,530 --> 01:14:36,310
With Cosmos Nemotron Video Search, the massively scaled synthetic dataset,

1099
01:14:36,590 --> 01:14:41,130
combined with recorded drives, can be curated to train models.

1100
01:14:43,890 --> 01:14:49,470
NVIDIA's AI Data Factory scales hundreds of drives into billions of effects.

1101
01:14:49,490 --> 01:14:51,586
The data is then used to track the most effective miles,

1102
01:14:51,587 --> 01:14:54,790
setting the standard for safe and advanced autonomous driving.

1103
01:14:58,900 --> 01:14:59,900
Isn't that incredible?

1104
01:15:00,540 --> 01:15:01,540
We...

1105
01:15:04,000 --> 01:15:05,000
take...

1106
01:15:05,300 --> 01:15:10,080
take thousands of drives and turn them into billions of miles.

1107
01:15:10,360 --> 01:15:15,180
We are going to have mountains of training data for autonomous vehicles.

1108
01:15:15,420 --> 01:15:18,140
Of course, we still need actual cars on the road.

1109
01:15:18,280 --> 01:15:24,220
Of course, we will continuously collect data However, synthetic data generation

1110
01:15:24,221 --> 01:15:29,940
using this multiverse, physically based, physically grounded capability,

1111
01:15:30,180 --> 01:15:35,840
so that we generate data for training AIs that are physically grounded and accurate,

1112
01:15:35,980 --> 01:15:39,900
or plausible, so that we could have an enormous amount of data to train with.

1113
01:15:40,100 --> 01:15:41,620
The AV industry is here.

1114
01:15:41,920 --> 01:15:44,340
This is an incredibly exciting time.

1115
01:15:44,500 --> 01:15:48,060
Super, super, super excited about the next several years.

1116
01:15:48,180 --> 01:15:51,870
I think you are going to see, just as computer graphics was revolutionized at

1117
01:15:51,871 --> 01:15:55,515
such an incredible pace, you are going to see the pace of AV

1118
01:15:55,516 --> 01:15:58,530
development increasing tremendously over the next several years.

1119
01:16:09,210 --> 01:16:11,411
I think... I think...

1120
01:16:13,430 --> 01:16:17,131
I think the next part is... is robotics.

1121
01:16:18,430 --> 01:16:19,430
So...

1122
01:16:26,540 --> 01:16:27,540
Humanoid robots.

1123
01:16:31,440 --> 01:16:32,440
My friends.

1124
01:16:38,570 --> 01:16:43,450
The chat GPT moment for general robotics is just around the corner.

1125
01:16:43,470 --> 01:16:47,350
And in fact, all of the enabling technologies that I have been talking

1126
01:16:47,351 --> 01:16:54,150
about is going to make it possible for us in the next several years to see very

1127
01:16:54,151 --> 01:16:57,350
rapid breakthroughs, surprising breakthroughs in general robotics.

1128
01:16:57,650 --> 01:17:02,550
Now the reason why general robotics is so important is whereas robots with tracks

1129
01:17:02,551 --> 01:17:08,570
and wheels require special environments to accommodate them, there are three robots,

1130
01:17:09,670 --> 01:17:13,450
three robots in the world that we can make that require robots.

1131
01:17:13,451 --> 01:17:14,630
There are no green fields.

1132
01:17:16,110 --> 01:17:18,030
Brownfield adaptation is perfect.

1133
01:17:18,510 --> 01:17:23,850
If we could possibly build these amazing robots, we could deploy them in exactly

1134
01:17:23,851 --> 01:17:25,531
the world that we have built for ourselves.

1135
01:17:25,890 --> 01:17:32,270
These three robots are, one, agentic robots and agentic AI because,

1136
01:17:32,450 --> 01:17:36,050
you know, they are information workers so long as they could accommodate the

1137
01:17:36,051 --> 01:17:38,531
computers that we have in our offices, it is going to be great.

1138
01:17:38,830 --> 01:17:41,270
Number two, self-driving cars.

1139
01:17:41,510 --> 01:17:45,690
And the reason for that is we spent 100 plus years building roads and cities.

1140
01:17:46,030 --> 01:17:48,350
And then number three, human or robots.

1141
01:17:48,630 --> 01:17:52,566
If we have the technology to solve these three, this will

1142
01:17:52,567 --> 01:17:55,910
be the largest technology industry the world has ever seen.

1143
01:17:56,590 --> 01:18:01,870
And so we think that the robotics era is just around the corner.

1144
01:18:02,070 --> 01:18:05,890
The critical capability is how to train these robots.

1145
01:18:06,410 --> 01:18:12,990
In the case of human or robots, the imitation information is rather hard to collect.

1146
01:18:13,350 --> 01:18:16,870
And the reason for that is in the case of cars, you just drive it.

1147
01:18:16,930 --> 01:18:18,186
We are driving cars all the time.

1148
01:18:18,210 --> 01:18:21,630
In the case of these human or robots, the imitation

1149
01:18:21,631 --> 01:18:25,170
information, the human demonstration is rather laborious to do.

1150
01:18:25,410 --> 01:18:30,490
And so we need to come up with a clever way to take hundreds of demonstrations,

1151
01:18:30,870 --> 01:18:36,010
thousands of human demonstrations, and somehow use artificial intelligence

1152
01:18:36,011 --> 01:18:48,070
and omniverse to synthetically generate millions of synthetically generated motions.

1153
01:18:48,410 --> 01:18:53,270
And from those motions, the AI can learn how to perform a task.

1154
01:18:53,490 --> 01:18:54,790
Let me show you how that's done.

1155
01:19:06,360 --> 01:19:09,063
Developers around the world are building the next

1156
01:19:09,064 --> 01:19:12,620
wave of physical, AI-embodied robots, humanoids.

1157
01:19:13,880 --> 01:19:18,520
Developing general-purpose robot models requires massive amounts of real-world

1158
01:19:18,521 --> 01:19:21,580
data, which is costly to capture and curate.

1159
01:19:22,460 --> 01:19:25,792
NVIDIA Isaac Groot helps tackle these challenges,

1160
01:19:25,793 --> 01:19:28,900
providing humanoid robot developers with four things.

1161
01:19:29,140 --> 01:19:35,079
Robot foundation models, data pipelines, simulation

1162
01:19:35,080 --> 01:19:39,661
frameworks, and a Thor robotics computer.

1163
01:19:40,920 --> 01:19:45,960
The NVIDIA Isaac Groot Blueprint for synthetic motion generation is a

1164
01:19:45,961 --> 01:19:50,760
simulation workflow for imitation learning, enabling developers to generate

1165
01:19:50,761 --> 01:19:55,160
exponentially large data sets from a small number of human demonstrations.

1166
01:19:56,020 --> 01:20:01,180
First, Groot Teleop enables skilled human workers to portal

1167
01:20:01,181 --> 01:20:04,900
into a digital twin of their robot using the Apple Vision Pro.

1168
01:20:06,060 --> 01:20:11,000
This means operators can capture data even without a physical robot, and they can

1169
01:20:11,001 --> 01:20:14,397
operate the robot in a risk-free environment, eliminating

1170
01:20:14,398 --> 01:20:16,780
the chance of physical damage or wear and tear.

1171
01:20:18,660 --> 01:20:23,140
To teach a robot a single task, operators capture motion trajectories

1172
01:20:23,680 --> 01:20:25,800
through a handful of teleoperated demonstrations.

1173
01:20:26,440 --> 01:20:32,160
Then use Groot Mimic to multiply these trajectories into a much larger data set.

1174
01:20:33,920 --> 01:20:38,960
Next, they use Groot Gen, built on Omniverse and Cosmos, for domain

1175
01:20:38,961 --> 01:20:43,092
randomization and 3D to real upscaling, generating

1176
01:20:43,093 --> 01:20:46,520
an extra and exponentially larger data set.

1177
01:20:48,760 --> 01:20:52,847
The Omniverse and Cosmos Multiverse simulation engine provides

1178
01:20:52,848 --> 01:20:56,560
a massively scaled data set to train the robot policy.

1179
01:20:57,780 --> 01:21:03,460
Once the policy is trained, developers can perform software-in-the-loop testing and

1180
01:21:03,461 --> 01:21:07,300
validation in Isaac Sim before deploying to the real robot.

1181
01:21:08,980 --> 01:21:11,580
The age of general robotics is arriving.

1182
01:21:12,000 --> 01:21:13,940
Powered by NVIDIA Isaac Groot.

1183
01:21:18,540 --> 01:21:21,600
We're going to have mountains of data to train robots with.

1184
01:21:24,580 --> 01:21:26,260
NVIDIA Isaac Groot.

1185
01:21:26,600 --> 01:21:27,920
NVIDIA Isaac Groot.

1186
01:21:28,020 --> 01:21:34,200
This is our platform to provide technology elements to the robotics industry to

1187
01:21:34,201 --> 01:21:36,120
accelerate the development of general robotics.

1188
01:21:36,780 --> 01:21:40,720
And, well, I have one more thing that I want to show you.

1189
01:21:41,100 --> 01:21:44,990
None of this would be possible if not for this

1190
01:21:44,991 --> 01:21:49,640
incredible project that we started about a decade ago.

1191
01:21:49,920 --> 01:21:53,440
Inside the company was called Project Digits.

1192
01:21:53,840 --> 01:21:58,760
Deep learning GPU intelligence training system.

1193
01:21:59,760 --> 01:22:00,760
Digits.

1194
01:22:01,620 --> 01:22:06,380
Well, before we launched it, I shrunk it to DGX.

1195
01:22:07,120 --> 01:22:11,680
And to harmonize it with RTX, AGX, OVX, and all

1196
01:22:11,681 --> 01:22:15,201
of the other Xs that we have in the company.

1197
01:22:15,380 --> 01:22:20,220
And... And it really revolutionized...

1198
01:22:20,900 --> 01:22:24,080
DGX1 really revolutionized... Where is DGX1?

1199
01:22:26,060 --> 01:22:28,360
DGX1 revolutionized artificial intelligence.

1200
01:22:28,660 --> 01:22:34,280
The reason why we built it was because we wanted to make it possible for researchers

1201
01:22:34,281 --> 01:22:37,300
and startups to have an out-of-the-box AI supercomputer.

1202
01:22:37,900 --> 01:22:40,060
Imagine the way supercomputers were built in the past.

1203
01:22:40,320 --> 01:22:43,001
You really have to build your own facility and

1204
01:22:43,002 --> 01:22:44,720
you have to go build your own infrastructure.

1205
01:22:44,721 --> 01:22:47,280
And really engineer it into existence.

1206
01:22:47,600 --> 01:22:51,284
And so we created a supercomputer for AI development for

1207
01:22:51,285 --> 01:22:55,060
researchers and startups that comes literally one out of the box.

1208
01:22:55,220 --> 01:22:59,720
I delivered the first one to a startup company in 2016 called OpenAI.

1209
01:23:00,060 --> 01:23:01,300
And Elon was there.

1210
01:23:01,400 --> 01:23:02,980
And Ilya Suskovor was there.

1211
01:23:03,080 --> 01:23:05,140
And many of the NVIDIA engineers were there.

1212
01:23:05,300 --> 01:23:08,940
And we celebrated the arrival of DGX1.

1213
01:23:09,060 --> 01:23:14,700
And obviously it revolutionized artificial intelligence and computing.

1214
01:23:15,480 --> 01:23:17,900
But now artificial intelligence is everywhere.

1215
01:23:18,100 --> 01:23:20,840
It's not just in researchers and startup labs.

1216
01:23:21,440 --> 01:23:24,560
We want artificial intelligence, as I mentioned in the beginning of our talk.

1217
01:23:24,820 --> 01:23:27,220
This is now the new way of doing computing.

1218
01:23:27,360 --> 01:23:28,880
This is the new way of doing software.

1219
01:23:28,920 --> 01:23:34,360
Every software engineer, every engineer, every creative artist, everybody who uses

1220
01:23:34,361 --> 01:23:39,120
computers today as a tool will need an AI supercomputer.

1221
01:23:39,900 --> 01:23:44,820
And so I just wish that DGX1 was smaller.

1222
01:23:45,320 --> 01:23:56,390
And, you know, so imagine, ladies and gentlemen,

1223
01:24:05,230 --> 01:24:08,910
this is NVIDIA's latest AI supercomputer.

1224
01:24:13,430 --> 01:24:18,150
And it's finally called Project Digits right now.

1225
01:24:18,530 --> 01:24:21,210
And if you have a good name for it, reach out to us.

1226
01:24:23,870 --> 01:24:25,290
This, here's the amazing thing.

1227
01:24:25,310 --> 01:24:26,430
This is an AI supercomputer.

1228
01:24:26,730 --> 01:24:29,670
It runs the entire NVIDIA AI stack.

1229
01:24:31,110 --> 01:24:33,150
All of NVIDIA's software runs on this.

1230
01:24:33,770 --> 01:24:35,550
DGX Cloud runs on this.

1231
01:24:36,810 --> 01:24:40,194
This sits, well, somewhere, and it's wireless

1232
01:24:40,195 --> 01:24:42,630
or, you know, connected to your computer.

1233
01:24:42,810 --> 01:24:44,670
It's even a workstation if you like it to be.

1234
01:24:44,870 --> 01:24:46,930
And you could access it.

1235
01:24:47,030 --> 01:24:50,870
You could reach it like a cloud supercomputer.

1236
01:24:51,270 --> 01:24:53,350
And NVIDIA's AI works on it.

1237
01:24:53,351 --> 01:24:59,750
And it's based on a super secret chip that we've been working on called GB110,

1238
01:25:00,130 --> 01:25:03,170
the smallest Grace Blackwell that we make.

1239
01:25:03,730 --> 01:25:05,630
And I have, well, you know what?

1240
01:25:05,670 --> 01:25:06,910
Let's show everybody inside.

1241
01:25:34,180 --> 01:25:37,340
Isn't this just, isn't this just, this is so cute.

1242
01:25:37,560 --> 01:25:39,080
And this is the chip that's inside.

1243
01:25:40,920 --> 01:25:42,560
It is in production.

1244
01:25:43,740 --> 01:25:48,660
This top secret chip, we did in collaboration with the CPU, the Grace CPU,

1245
01:25:48,940 --> 01:25:54,120
was a, is built for NVIDIA in collaboration with MediaTek.

1246
01:25:54,700 --> 01:25:56,840
They're the world's leading SOC company.

1247
01:25:57,080 --> 01:26:01,170
And they worked with us to build this CPU, this CPU SOC, and

1248
01:26:01,171 --> 01:26:05,340
connect it with chip-to-chip NVLink to the Blackwell GPU.

1249
01:26:05,940 --> 01:26:10,460
And this little, this little thing here is in full production.

1250
01:26:10,900 --> 01:26:16,360
We're expecting this computer to be available around May timeframe.

1251
01:26:16,361 --> 01:26:18,640
And so it's coming at you.

1252
01:26:19,020 --> 01:26:20,960
It's just incredible what we could do.

1253
01:26:21,100 --> 01:26:26,390
And it's just, I think it's, you really, I was trying

1254
01:26:26,391 --> 01:26:29,841
to figure out, do I need more hands or more pockets?

1255
01:26:30,920 --> 01:26:34,660
All right, so, so, imagine this is what it looks like.

1256
01:26:36,120 --> 01:26:37,840
You know, who doesn't want one of those?

1257
01:26:38,880 --> 01:26:44,140
And if you, if you use PC, Mac, you know, anything.

1258
01:26:45,140 --> 01:26:48,200
Because, because, you know, it's a cloud platform.

1259
01:26:48,360 --> 01:26:50,520
It's a cloud computing platform that sits on your desk.

1260
01:26:50,620 --> 01:26:53,440
You could also use it as a Linux workstation if you like.

1261
01:26:53,920 --> 01:26:59,480
If you would like to have double digits, this is what it looks like, you know.

1262
01:26:59,580 --> 01:27:05,920
And you connect it, you connect it together with ConnectX, and it has Nickel,

1263
01:27:07,340 --> 01:27:10,700
GPU Direct, all of that out of the box.

1264
01:27:10,840 --> 01:27:11,880
It's like a supercomputer.

1265
01:27:12,020 --> 01:27:14,680
Our entire supercomputing stack is available.

1266
01:27:15,240 --> 01:27:18,500
And so, NVIDIA Project Digits.

1267
01:27:27,190 --> 01:27:28,190
Okay.

1268
01:27:28,790 --> 01:27:31,610
Well, let me, let me, let me tell you what I told you.

1269
01:27:31,810 --> 01:27:38,210
I told you that we are in production with three new Blackwells.

1270
01:27:38,370 --> 01:27:43,290
Not only is the Grace Blackwell supercomputers, NVLink 72s, in production

1271
01:27:43,291 --> 01:27:48,350
all over the world, we now have three new Blackwell systems in production.

1272
01:27:48,770 --> 01:27:53,497
One amazing AI foundational, world foundation model,

1273
01:27:53,498 --> 01:27:56,810
the world's first physical AI foundation model.

1274
01:27:56,970 --> 01:28:02,010
It's open, available to activate the world's industries of robotics and such.

1275
01:28:02,210 --> 01:28:09,250
And three, and three robotics, three robots working on agentic AI,

1276
01:28:10,250 --> 01:28:12,170
humanoid robots, and self-driving cars.

1277
01:28:13,830 --> 01:28:15,370
It's been an incredible year.

1278
01:28:15,550 --> 01:28:17,430
I want to thank all of you for your partnership.

1279
01:28:17,590 --> 01:28:18,930
Thank all of you for coming.

1280
01:28:19,090 --> 01:28:21,390
I made you a short video to reflect on last year.

1281
01:28:21,391 --> 01:28:22,870
And look forward to the next year.

1282
01:28:22,950 --> 01:28:23,950
Play, please.

1283
01:31:14,340 --> 01:31:16,200
Have a great CES, everybody!

1284
01:31:17,960 --> 01:31:18,980
Happy New Year!

1285
01:31:20,120 --> 01:31:21,120
Thank you!

