1
00:00:00,000 --> 00:00:06,800
자동으로 수집된 글에 체크만 한번 눌러주면 AI가 각 플랫폼에 맞는 글을 이렇게 완성해줍니다.

2
00:00:06,860 --> 00:00:09,200
거기다 포스팅까지 알아서 해줍니다.

3
00:00:09,420 --> 00:00:11,900
SNS 글쓰기가 진짜 쉬워지겠죠?

4
00:00:12,140 --> 00:00:17,520
여러분 요새 SNS 마케팅이 더 이상 선택이 아닌 필수라는 얘기 많이 들어보셨죠?

5
00:00:17,680 --> 00:00:25,740
실제로 요즘은 평범한 직장인들도 퇴근 후 SNS 활동만으로 본업 연봉만큼 수익을 올리는 사례들이 상당히 많은데요.

6
00:00:25,741 --> 00:00:31,680
그만큼 셀프 브랜딩을 하거나 향후 부업으로 활용하기에 정말 SNS는 최고의 수단인 것 같습니다.

7
00:00:31,940 --> 00:00:36,900
하지만 SNS 운영이 결코 쉽지 않다는 걸 경험해보신 분들은 잘 아실 거예요.

8
00:00:37,280 --> 00:00:43,900
매일같이 새로운 아이디어를 떠올리고 각 플랫폼의 특성에 맞춰 포스팅하는 게 여간 부담스러운 일이 아니죠.

9
00:00:44,350 --> 00:00:55,300
그런데 여러분 해외 마케터들은 이미 AI 자동화 시스템을 활용해서 손 하나 까딱하지 않고 SNS를 운영하면서 큰 성과를 내고 있다는 사실 알고 계신가요?

10
00:00:55,420 --> 00:00:55,720
네.

11
00:00:55,740 --> 00:01:00,960
1일 1포스팅은 물론 그 이상의 콘텐츠 발행도 거뜬히 해내고 있는 분들이 많습니다.

12
00:01:01,120 --> 00:01:09,680
그래서 오늘은 단 한 번만 설정해두면 SNS 게시글이 자동으로 포스팅되도록 하는 시스템을 만드는 방법을 알려드릴까 하는데요.

13
00:01:10,020 --> 00:01:18,920
이 AI 자동화 시스템을 활용하면 최신 뉴스 수집부터 게시글 작성 그리고 포스팅까지 이 모든 과정을 자동으로 처리할 수 있습니다.

14
00:01:19,340 --> 00:01:24,960
매일 뭘 써야 할까 고민하던 때에서 벗어나 꿈꾸던 1일 1포스팅을 실현할 수 있는 것이죠.

15
00:01:24,961 --> 00:01:30,895
영상을 끝까지 시청하시면 이 자동화 시스템을 그대로 적용할 수 있도록 템플릿과 상세한

16
00:01:30,896 --> 00:01:36,620
프롬프트 예시 그리고 제가 어떻게 실무에 적용하고 있는지까지 모두 알려드리고 있으니까요.

17
00:01:36,640 --> 00:01:38,500
끝까지 시청해주시기 바랍니다.

18
00:01:38,960 --> 00:01:47,740
참고로 이 영상은 링크드인과 트위터를 기준으로 말씀드리지만 인스타그램이나 다른 SNS 채널에도 충분히 응용해서 적용이 가능합니다.

19
00:01:49,740 --> 00:01:56,235
그럼 이 자동화 시스템이 어떻게 작동하는지 최종 결과물을 함께 보면서 설명해 드리겠습니다

20
00:01:56,582 --> 00:01:59,052
이 자동화 시스템은 크게 3단계로 작동하는데요.

21
00:01:59,433 --> 00:02:02,273
첫번째로 먼저 구글 알리미라는 걸 사용해서

22
00:02:02,511 --> 00:02:06,620
여러 뉴스 사이트로부터 여러분이 원하는 주제의 최신 뉴스를

23
00:02:06,791 --> 00:02:08,658
구글 시트에 자동으로 저장합니다.

24
00:02:09,138 --> 00:02:14,308
그리고 이 수집된 뉴스들 중에 여러분이 SNS에 포스팅하고 싶은 뉴스를 선택해서

25
00:02:14,561 --> 00:02:19,060
체크박스를 누르면 ChatGPT가 이걸 알아서 SNS 글로 바꿔줄 거고요.

26
00:02:19,380 --> 00:02:24,406
마지막으로 ChatGPT가 작성한 글이 마음에 들면 옆에 발행 버튼을 눌러서

27
00:02:24,645 --> 00:02:27,593
실제 SNS에 자동으로 포스팅까지 할 수 있습니다.

28
00:02:27,813 --> 00:02:33,468
물론 이 모든 과정을 체크박스를 누를 필요도 없이 완전 자동으로 진행되도록 설정할 수도 있는데요.

29
00:02:33,755 --> 00:02:36,361
이 부분은 나중에 자세히 설명 드릴 예정입니다.

30
00:02:36,827 --> 00:02:41,776
완전 자동화하는 방법도 있지만 먼저 이 체크박스를 쓰는 방식을 추천하는 이유는

31
00:02:41,981 --> 00:02:44,656
좀 더 자연스러운 글 작성이 가능하기 때문입니다.

32
00:02:44,963 --> 00:02:50,312
프롬프트가 어느 정도 다듬어질 때까지는 이렇게 체크박스로 확인하는 단계를 거침으로써

33
00:02:50,690 --> 00:02:53,150
사람이 쓴 것 같은 글로 완성할 수 있을 거예요.

34
00:02:53,363 --> 00:02:57,866
우리는 이 자동화 시스템을 make.com이라는 사이트를 활용해서 만들 예정인데요.

35
00:02:58,206 --> 00:03:05,186
make.com을 처음 써보시는 분들은 설명란 또는 고정 댓글을 통해서 make.com에 가입하실 수 있으니까 참고해주세요.

36
00:03:05,326 --> 00:03:11,206
그럼 이제 SNS 자동화의 첫 단계인 구글 알리미 설정부터 시작하도록 하겠습니다.

37
00:03:11,625 --> 00:03:16,412
이 구글 알리미를 통해서 RSS로 매일 뉴스 기사들을 수집할 수가 있는데요.

38
00:03:16,739 --> 00:03:20,334
RSS라는 개념이 좀 생소하신 분들도 있으실 것 같아요.

39
00:03:20,787 --> 00:03:24,242
RSS는 사용자가 웹사이트에 들어가서 매일 경제에 직접 방문하지 않고도

40
00:03:24,501 --> 00:03:27,601
새로운 콘텐츠를 받아볼 수 있게 해주는 기술입니다.

41
00:03:28,067 --> 00:03:32,767
많은 뉴스 사이트나 블로그들이 자체적으로 RSS 피드를 제공하고 있는데요.

42
00:03:33,107 --> 00:03:35,962
예를 들어서 매일 경제에 RSS를 구독하면

43
00:03:36,227 --> 00:03:40,860
이 매일 경제 사이트에 방문하지 않고도 최신 뉴스 알림을 받아볼 수 있는 거죠.

44
00:03:41,207 --> 00:03:44,568
각각의 뉴스 사이트에서 RSS를 따올 수도 있지만

45
00:03:44,839 --> 00:03:48,213
구글 알리미는 이러한 각각의 사이트에 들어갈 필요 없이

46
00:03:48,466 --> 00:03:55,226
여기 키워드만 설정하면 내가 관심 있는 주제에 대한 뉴스들을 다 수집을 해주기 때문에 굉장히 유용합니다.

47
00:03:55,512 --> 00:04:00,453
여기 구글 알리미 사이트에 들어가서 여러분이 원하는 키워드를 검색을 해주면

48
00:04:00,698 --> 00:04:03,585
해당 키워드와 관련된 최신 뉴스들이 나타납니다.

49
00:04:03,978 --> 00:04:06,572
저는 AI로 한번 검색을 해볼게요.

50
00:04:07,225 --> 00:04:10,691
이렇게 검색을 하면 AI 관련 뉴스들이 쭉 뜨게 되고요.

51
00:04:11,017 --> 00:04:15,584
이 뉴스들을 수집하고 싶다면 상단에 알림 만들기를 눌러주시면 됩니다.

52
00:04:15,937 --> 00:04:18,390
그리고 여기 연필 부분을 눌러서

53
00:04:18,477 --> 00:04:23,488
수신 위치를 RSS 피드로 바꿔주시고 알림 업데이트를 눌러줍니다.

54
00:04:24,135 --> 00:04:28,308
그러면 이 AI라는 키워드 옆에 이 전파 아이콘이 생기는데요.

55
00:04:28,682 --> 00:04:34,215
이 전파 아이콘을 누르면 XML로 구성된 RSS 뉴스 피드 주소로 이동합니다.

56
00:04:34,745 --> 00:04:39,381
이 주소창의 주소를 전체 선택 후 Ctrl C를 눌러서 복사를 해주세요.

57
00:04:39,708 --> 00:04:43,961
이제 본격적으로 make.com을 활용한 자동화 시스템을 구축을 해볼게요.

58
00:04:44,681 --> 00:04:48,161
먼저 make.com에 로그인하면 저 같은 화면이 뜨실 텐데요.

59
00:04:48,215 --> 00:04:51,109
왼쪽에 시나리오 버튼을 눌러주시고

60
00:04:51,439 --> 00:04:56,388
여기 오른쪽 위에 Create New Scenario를 눌러서 새로운 시나리오를 생성해주세요.

61
00:04:57,941 --> 00:05:00,561
일단 뉴스를 수집하는 시나리오를 만들 건데요.

62
00:05:00,775 --> 00:05:04,861
제 유튜브 설명란에 미리 JSON 파일을 어느 정도 만들어 뒀거든요.

63
00:05:05,088 --> 00:05:06,935
그걸 바탕으로 시작을 해보겠습니다.

64
00:05:07,288 --> 00:05:11,010
제 유튜브 설명란에 있는 JSON 파일을 먼저 다운받아 주시고요.

65
00:05:11,317 --> 00:05:15,172
다운받으신 분들은 여기 시나리오 하단에 ...을 눌러서

66
00:05:15,617 --> 00:05:17,828
Import Blueprint를 눌러주시고

67
00:05:18,393 --> 00:05:22,153
다운받으신 파일을 업로드해주시고 세이브를 눌러주시면

68
00:05:22,200 --> 00:05:24,166
저처럼 이런 화면이 뜨실 겁니다.

69
00:05:24,573 --> 00:05:28,266
여기서 RSS 뉴스 수집 이 부분을 클릭을 해주시고요.

70
00:05:28,546 --> 00:05:36,287
저 같은 옵션 창이 보이실 건데 이 URL 부분에 아까 만든 피드 주소를 Ctrl V로 붙여넣어 주시고요.

71
00:05:36,367 --> 00:05:39,027
이렇게 하면 AI 뉴스들이 수집이 될 겁니다.

72
00:05:39,427 --> 00:05:45,111
Date From과 Date To는 언제부터 언제까지의 뉴스를 가져올 건지 입력하는 칸인데요.

73
00:05:45,533 --> 00:05:53,464
지금 같은 경우는 Now 그리고 마이너스 6으로 되어 있으니까 현재부터 6일 전까지의 뉴스를 가져오겠다고 되어 있는 겁니다.

74
00:05:53,884 --> 00:06:00,805
여기서 저는 6을 1로 바꿔서 오늘부터 어제까지의 뉴스만 가져와 보도록 할게요.

75
00:06:01,551 --> 00:06:05,771
그리고 밑에 보면 Maximum Number of Returned Items라고 적혀있는데

76
00:06:05,884 --> 00:06:09,684
 이건 한 번에 몇 개의 뉴스를 가져올 거냐를 설정하는 부분입니다.

77
00:06:10,090 --> 00:06:13,817
지금은 뉴스를 5개까지만 가져오는 걸로 설정이 된 거고요.

78
00:06:14,257 --> 00:06:17,764
이렇게 설정을 두고 OK를 눌러주시면 저장됩니다.

79
00:06:18,564 --> 00:06:23,717
하단에 Run Once 버튼을 누르면 이 시나리오가 실행되거든요. 한 번 눌러보겠습니다.

80
00:06:24,317 --> 00:06:26,542
Run Anyway를 눌러주시면 되고요.

81
00:06:27,569 --> 00:06:32,529
누르고 잠시 기다리시면 저처럼 여기 위쪽에 흰색 동그라미가 뜰 텐데요.

82
00:06:33,055 --> 00:06:36,590
이 RSS 뉴스 수집 위에 흰색 동그라미를 클릭을 해보면

83
00:06:36,649 --> 00:06:40,185
실제로 어떤 뉴스가 수집되어 있는지 볼 수가 있습니다.

84
00:06:40,738 --> 00:06:47,758
보면은 Bundle 1부터 Bundle 2, Bundle 3 해서 총 5개의 뉴스가 가져와진 걸 볼 수 있고요.

85
00:06:48,198 --> 00:06:52,682
각 번들 안에 보면은 뉴스의 제목, 그리고 뉴스의 개요,

86
00:06:53,311 --> 00:06:55,938
URL도 가져와진 거를 볼 수가 있습니다.

87
00:06:56,078 --> 00:07:01,817
여기서 중요한 게 저희가 지금 뉴스 제목이랑 URL만 있고 뉴스 본문이 없어요.

88
00:07:02,136 --> 00:07:06,952
본문을 가져오려면 이 URL로 접속을 해서 실제 기사 내용을 가져와야 되는데

89
00:07:07,263 --> 00:07:11,817
문제는 이 URL이 진짜 기사 URL이 아니라는 겁니다.

90
00:07:12,443 --> 00:07:14,069
복사해서 한 번 보여드릴게요.

91
00:07:14,202 --> 00:07:19,157
이걸 복사해서 인터넷 창에 붙여 넣어서 실제로 가는 주소를 확인해보면

92
00:07:19,629 --> 00:07:22,209
실제 주소는 이 주소인 걸 확인할 수 있거든요.

93
00:07:22,309 --> 00:07:26,430
그래서 이 주소를 이렇게 깔끔한 주소로 정리를 해주기 위해서

94
00:07:26,541 --> 00:07:30,495
이 make .com에 제가 3개의 모듈을 미리 추가를 해뒀는데요.

95
00:07:30,829 --> 00:07:37,031
각각의 모듈이 거름망처럼 작동해서 복잡한 URL을 단계적으로 깔끔하게 정리를 해줄 겁니다.

96
00:07:37,644 --> 00:07:41,384
첫 번째 모듈 같은 경우는 이러한 패턴이 들어가 있는데요.

97
00:07:41,551 --> 00:07:44,317
이게 정규식이라는 일종의 규칙입니다.

98
00:07:44,397 --> 00:07:47,838
이 정규식 규칙은 지금 이러한 URL에서

99
00:07:48,310 --> 00:07:54,437
이 URL "=" 다음 부분부터 &CT 사이에 이 URL만 뽑아낸다는 뜻이거든요.

100
00:07:54,563 --> 00:07:59,623
그리고 두 번째 모듈은 이 %3D를 "="로 바꿔준다는 뜻입니다.

101
00:07:59,957 --> 00:08:07,376
그리고 세 번째 모듈은 이 URL에서 %3F라는 부분이 있으면 그걸 물음표로 바꿔준다는 뜻이고요.

102
00:08:08,042 --> 00:08:10,311
이렇게 세 번의 정제 작업을 거치면은

103
00:08:10,628 --> 00:08:14,931
이렇게 아까 보여드린 것처럼 깔끔한 기사 URL로 바뀌게 됩니다.

104
00:08:15,497 --> 00:08:18,939
실제로 이 URL 정제 3번에 흰색 모듈을 눌러서

105
00:08:19,277 --> 00:08:23,024
이 오퍼레이션 부분을 눌러서 아웃풋 부분을 확인을 해보면요.

106
00:08:23,531 --> 00:08:27,535
이렇게 깔끔하게 진짜 기사 URL이 뽑혀서 나온 것을 볼 수가 있어요.

107
00:08:27,875 --> 00:08:31,535
자 이제 이 깔끔해진 URL로 실제 뉴스 본문을 가져와 볼 겁니다.

108
00:08:31,908 --> 00:08:35,895
옆에 플러스를 눌러서 http를 검색해 주시고요.

109
00:08:36,127 --> 00:08:38,944
여기서 Make a request를 눌러서 추가를 해주세요.

110
00:08:39,024 --> 00:08:44,431
이 URL 부분에 클릭을 하면은 여기에 이전 모듈들이 만들어낸 결과물들이 쭉 뜹니다.

111
00:08:44,531 --> 00:08:48,869
여기 이 색깔로 표시된 이 박스들이 하나의 바구니라고 생각을 하시면 돼요.

112
00:08:49,176 --> 00:08:53,109
각각의 이 바구니 안에 우리가 필요한 정보들이 담겨져 있는 거거든요.

113
00:08:53,269 --> 00:08:55,377
지금 우리가 여기에 넣어야 될 정보는

114
00:08:55,451 --> 00:08:59,815
URL 정제 3번의 모듈을 통해서 깔끔하게 걸러진 URL이잖아요.

115
00:09:00,269 --> 00:09:02,924
그래서 이렇게 URL 정제 3번 밑을 보면은

116
00:09:03,329 --> 00:09:07,589
이 바구니 안에 뭐가 담겨져 있는지 이렇게 미리보기로 보여지게 됩니다.

117
00:09:07,862 --> 00:09:10,203
여기 이렇게 깔끔한 URL이 담겨져 있으니까

118
00:09:10,281 --> 00:09:14,648
이 URL 정제 3번의 텍스트 바구니를 눌러서 이렇게 추가를 해주면 되겠죠.

119
00:09:14,734 --> 00:09:20,693
메소드는 현재 상태 그대로 get으로 두면은 뉴스를 get, 즉 가져온다는 뜻이고요.

120
00:09:21,440 --> 00:09:23,947
여기서 고수들만 아는 꿀팁 하나를 드릴게요.

121
00:09:24,413 --> 00:09:28,582
대부분의 사이트들은 자기네 사이트에서
정보를 스크랩하는 걸 막기 위해서

122
00:09:28,899 --> 00:09:32,905
이 헤더를 검사를 해서 로봇이
긁어가는 것 같으면 막아버리거든요.

123
00:09:33,219 --> 00:09:38,422
그래서 우리는 이 사이트가 진짜 사람처럼 착각하도록 가짜 헤더를 만들어줄 겁니다.

124
00:09:38,695 --> 00:09:41,190
헤더 부분에 이렇게 add header를 눌러서

125
00:09:42,742 --> 00:09:45,634
name 부분에 cookie를 추가를 해주시고요.

126
00:09:45,994 --> 00:09:47,116
또 한 번 눌러서

127
00:09:48,661 --> 00:09:50,634
accept라고 입력을 해주세요.

128
00:09:50,943 --> 00:09:54,203
그리고 한 번 더 눌러서 이번에는 accept

129
00:09:56,221 --> 00:09:59,382
-Encoding이라고 입력을 해주시고

130
00:09:59,683 --> 00:10:05,539
한 번 더 추가를 해서 User-Agent라고 추가를 해줍니다.

131
00:10:05,739 --> 00:10:09,390
이렇게 하면 웹사이트 URL에서 뉴스를 긁어올 수 있게 될 거예요.

132
00:10:09,737 --> 00:10:12,943
실제로 잘 긁어와지는지 테스트를 해보겠습니다.

133
00:10:13,597 --> 00:10:14,770
ok를 눌러주시고요.

134
00:10:15,090 --> 00:10:17,530
밑에 run once를 눌러서 테스트해보겠습니다.

135
00:10:18,337 --> 00:10:22,238
그러면 이렇게 http 모듈 위에 이렇게 흰색 원이 뜨고

136
00:10:22,569 --> 00:10:28,022
눌러보면 5개의 뉴스, 5개의 결과가 실행되었다고 이렇게 뜨는 걸 볼 수가 있고요.

137
00:10:28,422 --> 00:10:31,124
이 중에서 아무 operation이나 이렇게 눌러보면

138
00:10:31,449 --> 00:10:38,799
input으로 이러한 값들이 들어왔고 이러한 값들이 나왔다 이렇게 출력이 되는 걸 볼 수가 있어요.

139
00:10:39,152 --> 00:10:44,106
여기서 output 아래에 있는 bundle 밑에 있는 데이터를 이렇게 누르면

140
00:10:45,464 --> 00:10:52,681
이렇게 그 해당 웹페이지에 뉴스, 기사를 포함한
html 전체가 이렇게 긁어진 거를 볼 수가 있습니다.

141
00:10:53,041 --> 00:10:58,741
그런데 우리한테 진짜 필요한 거는 이 html 코드 전체가 아니라 뉴스 내용이잖아요.

142
00:10:58,821 --> 00:11:02,634
그래서 이 html 코드에서 실제 텍스트만 뽑아내야 됩니다.

143
00:11:02,967 --> 00:11:05,427
이걸 위해서 새로운 모듈을 추가할 건데요.

144
00:11:05,907 --> 00:11:09,787
플러스를 누르시고 Text parser를 검색을 해주세요.

145
00:11:10,107 --> 00:11:15,647
이 Text parser를 누르고 보면 html to text라는 모듈이 있습니다.

146
00:11:16,560 --> 00:11:23,999
이걸 눌러주시고 이 html 란에다가 바꿀 html을 넣으면 그걸 텍스트 형태로 바꿔주게 됩니다.

147
00:11:24,086 --> 00:11:29,342
여기 빈 칸에 마우스를 클릭을 하면 아까처럼 이렇게 이전 모듈의 결과 값이 쭉 뜨는데요.

148
00:11:29,747 --> 00:11:36,022
여기서 우리가 필요한 건 이 http 모듈에서의 결과 값인 이 데이터 값을 넣으면 되겠죠

149
00:11:36,323 --> 00:11:39,574
데이터를 클릭을 해서 넣어주시고 ok를 눌러줍니다.

150
00:11:39,940 --> 00:11:41,247
한번 실행해 보겠습니다.

151
00:11:41,834 --> 00:11:43,458
run anyway를 눌러주시고요.

152
00:11:44,964 --> 00:11:50,832
좀 기다리면 이렇게 http 모듈이 실행되면서 이 Text parser에 5개의 결과가 생기고

153
00:11:51,231 --> 00:11:55,246
눌러보면 이 아웃풋 안에 텍스트란 안에 보면

154
00:11:55,510 --> 00:12:00,911
html이 제거된 텍스트 영역만 쫙쫙 남게 되는 것을 볼 수가 있습니다.

155
00:12:01,011 --> 00:12:03,534
그런데 추출된 뉴스를 자세히 보면은

156
00:12:03,864 --> 00:12:08,174
저희가 여기서 원하는 거는 이 실제 본문인데 본문뿐만 아니라

157
00:12:08,513 --> 00:12:15,930
이렇게 공유라든지 웹사이트의 메뉴 부분이라든지 이런
부분들도 다 한꺼번에 포함되어 있는 걸 볼 수가 있어요.

158
00:12:16,350 --> 00:12:22,566
여기서 우리가 원하는 거는 이 텍스트 본문 부분만이기 때문에 이것만 깔끔하게 추출을 해 볼 건데요.

159
00:12:23,092 --> 00:12:27,793
그 전에 이 추가한 모듈 이름도 좀 더 알아보기 쉽게 바꿔주겠습니다.

160
00:12:27,933 --> 00:12:31,118
이 http 모듈에서 마우스 오른쪽을 클릭해서

161
00:12:31,630 --> 00:12:35,530
rename을 눌러서 뉴스 데이터 추출이라고 바꿔줄게요.

162
00:12:35,816 --> 00:12:39,373
그리고 Text parser도 rename을 눌러서 이것은

163
00:12:39,713 --> 00:12:45,799
html을 텍스트로 변환이라고 바꿔주겠습니다.

164
00:12:46,299 --> 00:12:50,820
그 다음에 이 모듈 옆에 플러스를 눌러서 새로운 모듈을 추가할 건데요.

165
00:12:51,293 --> 00:12:55,666
Open AI를 누르고 여기서 create a compilation을 눌러주세요.

166
00:12:57,131 --> 00:13:03,325
처음 접속하신 분들은 저처럼 이렇게 연결이 된 게 아니라 여기에 버튼 형태로 뜨실 건데요.

167
00:13:03,560 --> 00:13:07,439
연결하는 방법은 어렵지 않으니까 설명란에 자세히 남겨둘게요.

168
00:13:07,852 --> 00:13:11,349
그걸로 연결을 진행을 해주시면 저랑 똑같은 창이 뜰 겁니다.

169
00:13:12,409 --> 00:13:16,216
자 이제 뉴스 본문을 깔끔하게 뽑아주기 위한 설정을 해 볼게요.

170
00:13:17,230 --> 00:13:23,544
옵션 부분의 모델에서 GPT-3.5를 선택을 하겠습니다.

171
00:13:24,825 --> 00:13:28,585
3.5 터보 0125를 선택을 할게요.

172
00:13:32,434 --> 00:13:36,420
모델을 GPT-4o로 하면은 정확도가 올라가긴 하는데

173
00:13:36,492 --> 00:13:42,072
지금 여기 안에 들어있는 텍스트 양이 아까 보셨다시피 굉장히 많잖아요.

174
00:13:42,631 --> 00:13:46,408
그래서 GPT-4o로 하면은 비용이 너무 높아지기 때문에

175
00:13:46,747 --> 00:13:49,953
여기서는 저렴한 GPT-3.5로 쓰겠습니다.

176
00:13:50,300 --> 00:13:56,034
그리고 메세지 아래에 add message를 추가를 한 다음에 row를 user로 설정을 해 주시고요.

177
00:13:56,534 --> 00:13:59,010
텍스트 콘텐트에 이렇게 적어주세요.

178
00:13:59,396 --> 00:14:06,176
"이 문서에서 이 뉴스와 관련되지 않은 부분을 모두 제거해줘."

179
00:14:06,482 --> 00:14:11,324
"뉴스 제목과 뉴스 본문만 남겨야 해."

180
00:14:11,591 --> 00:14:12,191
#문서

181
00:14:13,744 --> 00:14:19,345
이렇게 해 주시고 이 ChatGPT가 이 뉴스의 주제가 뭔지 알 수 있게 여기다가 추가를 해 줄게요.

182
00:14:19,825 --> 00:14:22,094
뉴스 옆에다가 괄호를 친 다음에

183
00:14:22,490 --> 00:14:27,354
이 안에다가 뉴스의 제목이 담겨있는 이 rss 수집 모듈 하위에

184
00:14:27,890 --> 00:14:30,703
타이틀 부분을 클릭을 해서 추가를 해 주겠습니다.

185
00:14:31,003 --> 00:14:34,753
그리고 문서 옆에도 저희가 추출할 뉴스 내용이 들어 있는

186
00:14:34,977 --> 00:14:40,485
이 html 텍스트로 변환 모듈 안에 있는 텍스트를 눌러서 추가를 할게요.

187
00:14:40,851 --> 00:14:44,926
그리고 여기 아래에 show
advanced settings를 켜서

188
00:14:45,566 --> 00:14:50,980
고급 메뉴를 키신 다음에 여기
temperature를 0.2 정도로 줄여 주겠습니다.

189
00:14:51,289 --> 00:14:56,108
이 temperature 값이 1에 가까우면
가까울수록 창의적인 답변이 나오고

190
00:14:56,600 --> 00:15:03,130
지금은 그렇게 창의적인 답변이 필요한 건
아니니까 0에 가까운 0. 2 정도로 설정을 하는 거고요.

191
00:15:03,670 --> 00:15:08,218
그리고 Max completion token은 답변 길이를 설정하는 건데

192
00:15:08,640 --> 00:15:13,027
여기서는 답변 길이에 제한을 두지 않기 위해서 0을 입력하겠습니다.

193
00:15:15,350 --> 00:15:19,907
ok를 누른 다음에 다시 한번 run once를 눌러서 실행해 보겠습니다.

194
00:15:24,638 --> 00:15:29,113
비용이 많이 드니까 처음 첫 번째 것만 실행시키고 stop을 눌러줄게요.

195
00:15:32,675 --> 00:15:35,910
이렇게 실행이 된 다음에 Open AI 상단에 이

196
00:15:36,247 --> 00:15:39,421
흰색 풍선을 눌러서 결과 값을 확인해 보면

197
00:15:39,640 --> 00:15:44,120
이 Result 안에 실제 뉴스 본문이 이렇게 추출된 것을 볼 수가 있고요.

198
00:15:44,628 --> 00:15:49,196
참고로 지금은 3.5, 0125 가장 비용이 싼 걸로 해가지고

199
00:15:49,536 --> 00:15:53,061
지금 본문 추출이 아주 정확하게 이루어지진 않았는데요.

200
00:15:53,440 --> 00:15:58,081
조금 더 비싼 모델을 쓸수록 이 결과
값도 아주 정확하게 출력이 되니까

201
00:15:58,419 --> 00:16:02,460
그 부분은 가격 부분을 생각을
해서 설정을 해 주시면 되겠습니다.

202
00:16:02,633 --> 00:16:08,581
이렇게 뉴스 본문이 잘 출력이 됐으니까 이 본문을 구글 시트에 저장을 해 줄 겁니다.

203
00:16:08,908 --> 00:16:10,727
먼저 구글 시트를 만들어 줄게요.

204
00:16:10,879 --> 00:16:15,402
구글 스프레드 시트 사이트에 가서 빈 스프레드 시트를 눌러서 만든 다음에

205
00:16:16,302 --> 00:16:23,287
뉴스 스크랩으로 해주고 첫 번째 맨 위에 제목 원문 url

206
00:16:23,985 --> 00:16:27,133
작성일이라고 이렇게 헤더를 넣어줄게요.

207
00:16:27,593 --> 00:16:29,566
다시 make.com으로 돌아와서

208
00:16:30,024 --> 00:16:36,212
이 마지막 Open AI 모듈 오른쪽에 플러스를 눌러서 이 구글 시트를 눌러주시고요.

209
00:16:36,879 --> 00:16:38,933
add a row를 선택을 해 주세요.

210
00:16:40,021 --> 00:16:44,191
저 같은 경우는 이미 그 구글 시트와 연동이 되어 있어서 이렇게 뜨는데

211
00:16:44,482 --> 00:16:46,784
여러분 같은 경우는 버튼이 뜨실 거예요.

212
00:16:46,937 --> 00:16:49,721
그걸 눌러서 로그인해 주시면 연결이 됩니다.

213
00:16:50,215 --> 00:16:55,316
연결을 해 주신 다음에 이 스프레드 시트 아이디 밑에 있는 버튼을 누르셔 가지고

214
00:16:56,121 --> 00:17:00,107
아까 만들었던 뉴스 스크랩을 검색을 해 주시고 추가를 해 줍니다.

215
00:17:00,454 --> 00:17:04,774
그리고 시트 네임은 sheet1 그리고 아까 헤더를 만들었으니까

216
00:17:05,192 --> 00:17:07,771
헤더 포함 여부 예스로 주시면 되고요.

217
00:17:08,138 --> 00:17:13,383
그리고 이 values 이 부분이 구글 시트에 입력할 데이터를 넣어주면 되는 부분인데요.

218
00:17:13,756 --> 00:17:18,301
이 제목열에 뉴스 제목을 넣어야 될 거니까 이 팝업창에서

219
00:17:18,740 --> 00:17:24,116
이 rss 뉴스 수집 모듈 밑에 있는 title을 클릭을 해서 입력을 해 주시면 되고요.

220
00:17:24,710 --> 00:17:28,241
그다음에 원문 부분에는 뉴스 기사 원문을 넣어야 되니까

221
00:17:28,886 --> 00:17:35,407
이 팝업창에서 저희가 Open AI 모듈을 통해서 이 뉴스 원문을 추출을 해 줬잖아요.

222
00:17:35,561 --> 00:17:37,987
이 result 값을 넣어주시면 되겠습니다.

223
00:17:38,358 --> 00:17:39,746
그리고 url 란에는

224
00:17:39,824 --> 00:17:46,958
이 url 정제 3번 모듈을 통과해서 깔끔하게 정돈된 url 결과 값 텍스트를 입력을 해 주면 되겠죠.

225
00:17:47,351 --> 00:17:52,960
그리고 작성일 부분에는 이 rss 뉴스 수집 모듈 밑에 있는 date created

226
00:17:53,440 --> 00:17:56,514
작성된 날짜를 선택을 해서 입력을 해 주시면 됩니다.

227
00:17:56,934 --> 00:17:58,165
ok 를 눌러 주시고요.

228
00:17:58,725 --> 00:18:02,572
실제로 잘 동작하는지 run once를 눌러 보겠습니다.

229
00:18:05,140 --> 00:18:08,312
눌러서 실행될 때까지 좀 기다려 보도록 하고요.

230
00:18:08,372 --> 00:18:12,576
이렇게 실행되는 와중에 이렇게 오류가 뜰 때가 있는데요.

231
00:18:12,690 --> 00:18:18,718
지금 이 오류가 뜬 이유는 GPT 3.5의 그 최대 토큰 수를 넘어서 그런 거거든요.

232
00:18:19,032 --> 00:18:22,038
이럴 때는 여기 마우스 오른쪽을 누른 다음에.

233
00:18:22,345 --> 00:18:25,284
add error handler를 추가를 해 주시면 됩니다.

234
00:18:25,771 --> 00:18:29,504
이 에러가 발생했을 때 어떻게 처리하는지 적어 주시면 되거든요.

235
00:18:30,004 --> 00:18:34,123
여기 에러 핸들러 모듈 중에서 ignore를 선택을 해 주시면은

236
00:18:34,528 --> 00:18:37,515
해당 오류를 무시하고 계속 실행을 하게 됩니다.

237
00:18:37,730 --> 00:18:43,797
4개까지는 지금 결과 값이 다 실행이 되었다고 뜨는데 한번 뉴스 스크랩 구글 시트로 이동을 해 볼게요.

238
00:18:44,377 --> 00:18:48,238
그러면 이렇게 이렇게 4개의 뉴스가 잘 스크랩 된 것을 볼 수 있습니다.

239
00:18:48,344 --> 00:18:54,186
이제 에러 핸들러를 추가를 했으니까. 다시 한번 실행시켜서 잘 실행이 되는지 체크를 해 보겠습니다.

240
00:18:54,552 --> 00:18:57,699
run once를 눌러주면 이렇게 실행이 되고 있고요.

241
00:18:58,139 --> 00:19:01,340
첫 번째 실행이 되었고 두 번째 실행이 됐고요.

242
00:19:01,747 --> 00:19:04,217
세 번째 실행이 완료되었다고 하고요.

243
00:19:04,537 --> 00:19:06,910
네 번째 이렇게 잘 처리가 됐고

244
00:19:06,934 --> 00:19:14,686
에러가 발생한 한 건은 이렇게 무시를 했고 나머지 4개는 이 뉴스 스크랩에 잘 저장을 해 준 거를 볼 수가 있습니다.

245
00:19:17,250 --> 00:19:20,063
이렇게 뉴스를 수집해 주는 플로우를 만들었는데요.

246
00:19:20,436 --> 00:19:22,804
여기서 한 가지만 더 수정해 주면 완료입니다.

247
00:19:23,224 --> 00:19:25,477
바로 이 시나리오의 실행 간격인데요.

248
00:19:25,683 --> 00:19:29,273
여기 첫 번째 모듈의 왼쪽 시계 아이콘을 눌러주시고

249
00:19:29,718 --> 00:19:32,699
여기서 시나리오 실행 간격을 세팅을 할 수가 있습니다.

250
00:19:32,872 --> 00:19:35,678
기본 값은 보시다시피 15분으로 되어 있는데요.

251
00:19:36,072 --> 00:19:39,951
여기서 실행 간격을 여러분이 원하는 간격으로 바꿔주시면 됩니다.

252
00:19:40,171 --> 00:19:42,840
매일 아침마다 뉴스를 수집하기를 원하시면

253
00:19:43,506 --> 00:19:48,483
여기 런 시나리오 밑에를 눌러서 실행 간격을 에브리데이로 바꿔주시고

254
00:19:48,883 --> 00:19:53,336
시간을... 원하는 시간으로 바꾸신 다음에 OK를 눌러주시면 됩니다.

255
00:19:53,829 --> 00:19:57,408
그러면 이렇게 시나리오를 활성화할 거냐 이렇게 뜨는데요.

256
00:19:57,728 --> 00:20:00,580
활성화하겠다 액티베이트 시나리오를 눌러주시면

257
00:20:00,898 --> 00:20:07,777
이 부분이 켜지면서 매일 오후 4시 6분마다 실행되도록 하겠다 이렇게 설정이 완료됩니다.

258
00:20:08,758 --> 00:20:13,830
자 이제 이 수집한 뉴스들을 바탕으로 sns 자동 발행 시스템을 만들어 볼 건데요.

259
00:20:14,216 --> 00:20:18,755
먼저 구글 시트에 sns 글로 변환이라는 헤더를 추가를 할게요.

260
00:20:19,987 --> 00:20:22,718
그리고 그 밑에 체크박스를 추가를 해줍니다.

261
00:20:25,104 --> 00:20:29,478
그리고 이 옆에 링크드인 트위터 라고 이어서 적어줄게요.

262
00:20:33,066 --> 00:20:39,514
이 sns 글로 변환 체크박스가 체크되면 이 옆에 링크드인용 글과 트위터용 글이 생성되게 할 거예요.

263
00:20:40,034 --> 00:20:42,537
그리고 옆에는 발행이라고 적어주시고요.

264
00:20:43,303 --> 00:20:45,309
여기도 체크박스를 추가를 해줍니다.

265
00:20:47,577 --> 00:20:52,083
이 체크박스가 체크되면은 여기에 작성된 글들이 바로 발행되게끔 할 겁니다

266
00:20:52,496 --> 00:20:57,312
먼저 이 체크박스가 체크될 때 메이크에서 감지를 할 수 있도록 해줘야 되는데요.

267
00:20:57,739 --> 00:21:00,622
그 역할을 해주는 연결고리를 웹훅이라고 합니다.

268
00:21:01,062 --> 00:21:05,560
웹훅은 make.com의 구글 시트 확장 프로그램을 활용하면 세팅할 수 있는데요.

269
00:21:06,170 --> 00:21:10,054
확장 프로그램 메뉴에서 부가기능, 부가기능 설치하기를 눌러주시고요.

270
00:21:11,595 --> 00:21:13,738
여기서 메이크를 검색을 하시면

271
00:21:15,310 --> 00:21:16,942
이렇게 확장 프로그램이 뜹니다.

272
00:21:17,118 --> 00:21:19,668
저는 이미 설치가 되어 있어서 제거가 뜨는데

273
00:21:19,909 --> 00:21:23,382
여러분은 설치가 뜨실 거예요. 눌러서 설치를 진행을 해주시고요.

274
00:21:24,300 --> 00:21:30,401
그리고 make.com으로 돌아가서 다시 create a new 시나리오를 눌러서 새로운 시나리오를 생성을 해주세요.

275
00:21:32,320 --> 00:21:38,080
여기서 구글 시트, 워치 체인지스 모듈을 눌러서 이렇게 추가를 해주시고요.

276
00:21:38,220 --> 00:21:43,260
이 웹훅 부분이 뜨면 옆에 add를 눌러서 새로운 웹훅을 하나 만들어주세요.

277
00:21:45,069 --> 00:21:47,260
그러면 이렇게 웹훅 URL이 뜨는데요.

278
00:21:47,486 --> 00:21:52,335
이걸 copy address를 눌러서 복사를 해주신
다음에 다시 구글 시트로 돌아와서

279
00:21:52,799 --> 00:21:58,932
확장 프로그램, make for Google sheets, settings를
눌러서 옆에 사이드바를 띄워줍니다.

280
00:21:59,200 --> 00:22:01,780
그러면 여기 웹훅 URL을 적는 칸이 있는데요.

281
00:22:02,000 --> 00:22:07,000
이 부분에 ctrl v로 붙여넣고 save로 저장을 해주시면 연결이 됩니다.

282
00:22:09,240 --> 00:22:11,087
이렇게 세팅이 잘 되었다고 뜨고요.

283
00:22:11,220 --> 00:22:14,040
make 시나리오로 돌아와서 ok를 눌러주세요.

284
00:22:14,146 --> 00:22:17,312
테스트를 해보기 위해서 아래에 run once를 눌러줄게요.

285
00:22:17,412 --> 00:22:21,147
그러면 이렇게 원이 돌아가면서 구글 시트를 감지하고 있다고 뜨고요.

286
00:22:21,373 --> 00:22:24,881
이 상태에서 구글 시트에서 체크박스를 이렇게 체크를 하면

287
00:22:26,876 --> 00:22:29,824
이렇게 감지되었다고 하면서 결과값이 뜹니다.

288
00:22:29,924 --> 00:22:33,238
여기서 아웃풋 번들 안에 이 내용을 확인해보면

289
00:22:33,497 --> 00:22:37,228
old value는 false, 즉 체크박스가 체크가 안 되어 있었는데

290
00:22:37,252 --> 00:22:43,140
지금 value는 true로 체크박스의 변경 사항을 make에서 잘 감지한 것을 확인할 수가 있어요.

291
00:22:43,540 --> 00:22:46,013
그리고 range 부분을 눌러서 열어보면

292
00:22:46,500 --> 00:22:52,312
이 감지된 사항이 두 번째 행 그리고 다섯 번째 열에서 감지되었다고 이렇게 뜨는데요

293
00:22:52,585 --> 00:22:59,020
실제로 저희가 체크한 이 체크박스 위치를 보면 두 번째 행, 다섯 번째 열이 맞죠?

294
00:22:59,740 --> 00:23:02,260
이렇게 잘 감지를 한 걸 확인할 수가 있습니다.

295
00:23:02,706 --> 00:23:06,720
웹훅이 정상적으로 작동하는 걸 확인했으니까 이어서 만들어보겠습니다.

296
00:23:07,180 --> 00:23:12,700
모듈 옆에 플러스를 눌러서 flow control 안에 있는 Router를 추가해 주시고요.

297
00:23:13,154 --> 00:23:15,500
추가하면 이렇게 길이 두 개로 나눠지는데요.

298
00:23:15,940 --> 00:23:20,399
위쪽으로는 sns 글 변환 체크박스를 체크하면 글이 써지는 플로우,

299
00:23:20,525 --> 00:23:25,660
아래쪽으로는 발행 체크박스를 체크하면 글이 발행되는 플로우를 만들어볼게요.

300
00:23:26,131 --> 00:23:32,020
이 위쪽 선에서 마우스 오른쪽 버튼을 누른 다음에 Set up a filter를 눌러서 이 필터 창을 띄워주시고요.

301
00:23:32,240 --> 00:23:36,584
SNS 글 변환 체크박스를 눌렀을 때 여기가 실행되어야 하니까

302
00:23:36,815 --> 00:23:45,432
올드 밸류가 false이고 여기 밸류 값이 true이라는 규칙을 만들어주시면 되고요.

303
00:23:45,559 --> 00:23:50,328
그리고 end를 하나 더 추가한 다음에 Column start를 눌러주시고요.

304
00:23:50,421 --> 00:23:55,540
지금 저희가 설정하려는 이 체크박스 위치가 하나, 둘, 셋, 넷, 다섯 번째 열이죠?

305
00:23:55,680 --> 00:23:59,051
그러니까 여기 Column start 부분에 5를 넣어주시고

306
00:23:59,075 --> 00:24:04,200
end를 하나 더 추가해서 칼럼 end도 똑같이 5로 추가를 해줍니다.

307
00:24:04,580 --> 00:24:06,031
OK를 눌러주시고요.

308
00:24:06,131 --> 00:24:11,080
이렇게 하면 SNS 글 변환 체크박스를 체크할 때만 이 플로우가 실행되게 될 겁니다.

309
00:24:11,742 --> 00:24:17,602
그 다음에 이 뒤에 플러스를 눌러서 Open AI Creator Completion을 선택을 해주시고요.

310
00:24:17,695 --> 00:24:24,784
모델을 GPT-4o Mini로 선택을 하겠습니다.

311
00:24:24,977 --> 00:24:28,555
그리고 Add Message를 눌러서 롤은 User로 세팅을 하고요.

312
00:24:29,342 --> 00:24:34,660
이 Text content 부분에는 유튜브 설명란에 있는 프롬프트를 복사해서 붙여넣어주세요.

313
00:24:35,455 --> 00:24:42,140
이 프롬프트는 ChatGPT에게 마케터 역할을 맡겨서 링크드인 글과 트위터 글을 잘 써달라고 부탁하는 글인데요.

314
00:24:42,540 --> 00:24:47,307
ChatGPT에게 부탁할 때 SNS 글로 바꿔줄 기사 원문을 넣어줘야 되니까

315
00:24:47,965 --> 00:24:52,276
여기 읽고 분석하세요. 이 다음 부분에 기사 원문을 넣을 건데요.

316
00:24:52,589 --> 00:24:58,160
이 구글 시트에 기사 원문이 어디 있나 확인을 해보면 두 번째 열에 있는 걸 확인할 수 있습니다.

317
00:24:58,666 --> 00:25:04,920
그래서 여기 팝업창에서 Raw Value 안에 두 번째 열인 B열을 눌러서 추가를 해주시면 됩니다.

318
00:25:05,240 --> 00:25:10,079
그리고 출처도 함께 표기하기 위해서 URL도 이 원문 링크 옆부분에 넣어줄 건데요.

319
00:25:10,300 --> 00:25:15,857
다시 구글 시트에서 URL이 어디에 있나 확인을 해보면 세 번째 열에 있는 걸 확인할 수 있으니까

320
00:25:16,843 --> 00:25:22,161
여기 프롬프트 부분에 팝업창에서 세 번째 열인 C열을 입력을 해주시면 됩니다.

321
00:25:23,760 --> 00:25:28,758
그리고 밑으로 내려서 이 Max Tokens는 한 1000 정도로 설정을 하겠습니다.

322
00:25:28,938 --> 00:25:32,739
그리고 이 아래에 Show Advanced Settings를 켠 다음에

323
00:25:33,470 --> 00:25:36,724
이 Temperature는 0.32 정도로 세팅을 하겠습니다.

324
00:25:37,694 --> 00:25:41,015
나머지는 기본값 그대로 두고 OK를 눌러주시면 되고요.

325
00:25:41,128 --> 00:25:43,280
Run Once를 눌러서 테스트를 해볼게요.

326
00:25:43,547 --> 00:25:45,841
구글 시트로 이동을 한 다음에

327
00:25:46,406 --> 00:25:51,747
글로 쓰고 싶은 뉴스 옆에 체크박스를 체크를 해서 해 주고 다시 메이크 시나리오로 돌아와 보면

328
00:25:52,007 --> 00:25:58,940
이렇게 변화를 감지하고 ChatGPT로 인풋이 들어와서 이렇게 글을 써주는 것을 볼 수 있어요.

329
00:25:59,349 --> 00:26:00,954
결과값을 확인을 해 보면

330
00:26:01,326 --> 00:26:05,401
이 아웃풋 부분에 Result를 눌러보면 이렇게 링크드인 글과

331
00:26:05,840 --> 00:26:08,267
트위터 글이 잘 써진 거를 확인을 할 수 있습니다.

332
00:26:08,360 --> 00:26:11,769
여기서 링크드인 글 부분은 구글 시트 링크드인 열에

333
00:26:12,080 --> 00:26:16,307
그리고 트위터 부분은 여기 구글 시트 트위터 열 부분에 추가를 해 줄 건데요.

334
00:26:16,501 --> 00:26:22,480
지금은 두 글이 하나로 합쳐져 있기 때문에 분리해 주기 위해서 정규식이라는 도구를 사용을 할 겁니다.

335
00:26:22,892 --> 00:26:24,999
정규식은 아까 말씀드렸다시피

336
00:26:25,091 --> 00:26:29,812
텍스트에서 우리가 원하는 부분만 뽑아내는 일종의 수식이라고 생각하시면 되는데요.

337
00:26:30,006 --> 00:26:32,516
여기 Open AI 옆에 플러스를 눌러서

338
00:26:33,619 --> 00:26:38,226
Text parser 밑에 있는 매치 패턴을 선택을 해 주세요.

339
00:26:39,340 --> 00:26:45,820
그리고 여기에 제가 유튜브 고정 댓글에 올려둔 정규식 패턴을 복사 붙여넣기 해 주시면 되고요.

340
00:26:45,946 --> 00:26:48,818
그리고 글로벌 매치만 예스로 바꿔주시면은,

341
00:26:49,151 --> 00:26:53,747
텍스트를 처음부터 끝까지 검색해서 이 패턴과 겹치는 모든 값을 찾아 줄 겁니다.

342
00:26:54,066 --> 00:27:00,460
그리고 텍스트 부분에 방금 전에 ChatGPT가 만든 Result 결과 값을 입력을 해 줍니다.

343
00:27:00,689 --> 00:27:04,940
OK를 눌러 주고 다시 한번 테스트를 위해 Run Once를 눌러 줄게요.

344
00:27:05,360 --> 00:27:07,020
Run Anyway를 눌러 주시고요.

345
00:27:07,980 --> 00:27:14,220
그리고 구글 시트로 돌아가서 글로 쓰고 싶은 뉴스 옆 부분에 체크박스를 체크를 해 줍니다.

346
00:27:15,040 --> 00:27:18,268
그리고 이렇게 돌아오면은 Open AI가 글을 써 주고,

347
00:27:18,686 --> 00:27:21,827
이 글을 Text parser가 두 개로 나눠 가지고 이렇게

348
00:27:21,858 --> 00:27:26,007
링크드인 글과 트위터 글로 분리를 해 준 것을 확인을 할 수가 있습니다.

349
00:27:26,180 --> 00:27:28,784
이제 이 글들을 구글 시트에 저장해 줄게요.

350
00:27:29,674 --> 00:27:35,700
Text parser 옆에 플러스를 눌러서 Flow Control 를 선택을 해 주시고요.

351
00:27:36,108 --> 00:27:41,018
위쪽에는 링크드인 게시물 아래쪽에는 트위터 게시물이 저장되도록 필터를 걸어 주겠습니다.

352
00:27:41,580 --> 00:27:44,269
아까 이 Text parser의 결과물을 보면은

353
00:27:45,046 --> 00:27:51,880
첫 번째 링크드인 글 같은 경우는 i가 1이라고 나왔고, 두 번째 트위터 글은 i가 2라고 나왔거든요.

354
00:27:52,040 --> 00:27:54,240
이걸 기준으로 필터를 걸어 줄게요.

355
00:27:54,360 --> 00:28:00,900
여기 첫 번째 선을 눌러서 필터를 켜신 다음에 팝업에서 i를 누르고 1을 입력을 합니다.

356
00:28:01,080 --> 00:28:02,360
ok 를 눌러 주시고요.

357
00:28:02,460 --> 00:28:06,640
이렇게 하면 첫 번째 글인 링크드인 글만 이쪽으로 지나가게 될 겁니다.

358
00:28:06,772 --> 00:28:09,591
그리고 플러스를 누르시고 이번에는 구글 시트

359
00:28:10,249 --> 00:28:16,185
업데이트 어로우를 선택을 하시고 이 스프레드 시트 아이디에 아까 저희가 만들었던

360
00:28:18,125 --> 00:28:20,359
"뉴스 스크랩" 시트를 선택을 하시고

361
00:28:22,131 --> 00:28:28,283
시트네임: 시트1 그리고 로우 넘버는 여기 row end로 선택을 해주시면 되고요.

362
00:28:28,377 --> 00:28:33,846
그리고 values 부분에 지금 링크드인 글을 저장을 하는 거니까 이 링크드인 열에다가

363
00:28:34,253 --> 00:28:37,060
이 fallback match 이 부분을 입력을 해주시면 됩니다.

364
00:28:37,522 --> 00:28:38,960
OK를 눌러주시고요.

365
00:28:39,395 --> 00:28:46,740
두 번째 역시 필터를 i로 넣어주시고 그리고 값은 2로 넣어주신 다음에 OK를 눌러주세요.

366
00:28:47,640 --> 00:28:51,026
똑같이 구글 시트 update a row를 추가를 하고

367
00:28:51,910 --> 00:28:55,382
나머지 옵션은 위에 거랑 다 똑같이 설정을 해줍니다.

368
00:28:55,509 --> 00:29:01,120
그리고 values 부분만 링크드인 부분이 아닌 트위터 부분에다가 fallback match를 넣어주시면 됩니다.

369
00:29:02,180 --> 00:29:09,160
다시 한번 제대로 작동하는지 확인하기 위해서 Run Once를 누르고 구글 시트에서 체크박스를 체크를 해볼게요.

370
00:29:10,260 --> 00:29:16,880
그러면 이렇게 감지가 되고 있고 ChatGPT가 글을 써주고 구글 시트가 실행됐다고 뜨는데요.

371
00:29:17,120 --> 00:29:23,032
시트로 이동을 해보면 이렇게 링크드인 글과 트위터 글이 잘 생성된 거를 확인을 할 수가 있습니다.

372
00:29:23,152 --> 00:29:27,460
글 자동 생성 부분이 완성되었으니까 글 자동 발행 부분도 만들어 보겠습니다.

373
00:29:28,140 --> 00:29:31,647
이 첫 번째 Router 밑에 선 부분에 필터를 만들어줄 건데요.

374
00:29:31,860 --> 00:29:35,634
이번에는 발행 체크박스가 체크될 때 여기가 실행되어야 되니까

375
00:29:35,732 --> 00:29:41,085
Column start를 이 발행 체크박스가 있는 열인 8번째 열로 입력을 하고요.

376
00:29:41,992 --> 00:29:45,579
and rule 추가한 다음에 Column end도 여덟 번째

377
00:29:46,252 --> 00:29:55,786
그리고 Old value가 False이고 value값이 True일 때라고 설정을 합니다.

378
00:29:56,000 --> 00:30:00,555
그리고 여기 플러스를 눌러서 Flow control에 Router를 추가를 해주시고요.

379
00:30:00,695 --> 00:30:04,565
그리고 첫 번째 플러스를 눌러서 링크드인을 검색을 하고

380
00:30:04,993 --> 00:30:08,558
여기 Create a user text post를 눌러서 추가를 하겠습니다.

381
00:30:08,698 --> 00:30:14,900
저 같은 경우는 미리 연결을 해놔서 이렇게 뜨는데 여러분들은 여기 버튼을 눌러서 연결을 진행해 주시면 됩니다.

382
00:30:15,080 --> 00:30:19,060
그리고 컨텐츠 부분에 링크드인 포스트 글을 입력을 해주면 되겠죠.

383
00:30:19,490 --> 00:30:25,422
구글 시트에서 링크드인 포스트가 들어있는 열인 F열을 선택을 해주면 되니까

384
00:30:25,720 --> 00:30:28,900
이 row value 안에 F열을 입력을 해줍니다.

385
00:30:30,110 --> 00:30:32,720
그리고 OK를 눌러주면 세팅이 끝나고요.

386
00:30:33,055 --> 00:30:42,960
이 부분도 역시 X 트위터를 검색을 해서 이 X 안에 있는 Create post를 눌러주시면 됩니다.

387
00:30:43,102 --> 00:30:45,938
저 같은 경우는 미리 연결을 해놔서 이렇게 뜨는데

388
00:30:46,251 --> 00:30:52,712
트위터 같은 경우는 사전에 API 신청이 통과되야 메이크에서 이렇게 포스팅을 할 수가 있어요.

389
00:30:52,852 --> 00:30:59,197
귀찮긴 하지만 이 API 신청이 어렵지는 않으니까 제가 이 신청 방법을 링크로 남겨둘게요.

390
00:30:59,662 --> 00:31:04,664
그걸 참고를 해주시고 트위터 연결을 완료해 주신 다음에 이 Text content 부분에

391
00:31:05,089 --> 00:31:09,280
트위터 내용이 들어있는 이 G열을 입력을 해주시면 되겠습니다.

392
00:31:09,780 --> 00:31:15,944
row values 안에 있는 G열을 눌러서 입력을 해주시고 OK를 누르시면 세팅이 끝납니다.

393
00:31:16,971 --> 00:31:19,174
이제 자동 발행을 테스트를 해보겠습니다.

394
00:31:19,420 --> 00:31:23,006
Run Once를 누르고 Way for New Data를 누르신 다음에

395
00:31:23,584 --> 00:31:27,388
구글 시트에서 원하는 글 옆에 발행 체크박스를 누르고

396
00:31:27,726 --> 00:31:31,680
메이크 시나리오를 돌아와 보면 이렇게 실행된 것을 볼 수 있고요.

397
00:31:31,930 --> 00:31:34,630
실제로 링크드인에 들어가서 확인해 보겠습니다.

398
00:31:38,260 --> 00:31:42,560
이렇게 링크드인 글이 잘 포스팅된 것을 확인할 수가 있고요.

399
00:31:43,159 --> 00:31:47,240
트위터도 이렇게 글이 잘 생성된 것을 확인할 수가 있습니다.

400
00:31:47,553 --> 00:31:49,652
이제 이 아래의 스케줄링 부분에

401
00:31:49,772 --> 00:31:56,967
이 구글 시트를 항상 감지하도록 Immediately as Data Arrives를 켜주시면 시스템 세팅이 끝나는데요.

402
00:31:57,566 --> 00:32:03,896
기존 데이터는 삭제해주기 위해서 Delete Old Data, Delete를 눌러주시면 세팅이 완료됩니다.

403
00:32:03,949 --> 00:32:06,052
앞으로는 체크박스 하나만 클릭하면

404
00:32:06,351 --> 00:32:12,820
AI가 알아서 글도 쓰고 발행까지 해주니까 꿈에 그리던 1일 1포스팅도 현실로 만드실 수 있을 겁니다.

405
00:32:13,140 --> 00:32:20,300
참고로 저는 이 시스템으로 제 관심 분야의 최신 뉴스를 자동으로 수집하고 있고, SNS 포스팅까지 하고 있는데요.

406
00:32:20,767 --> 00:32:25,660
특히 여러 SNS를 통해서 셀프 브랜딩을 하려는 분들에게 강력히 추천드립니다.

407
00:32:26,139 --> 00:32:30,665
그리고 AI가 쓴 글이 괜찮을까 이렇게 걱정하시는 분들도 있을 것 같은데요.

408
00:32:30,880 --> 00:32:37,140
이 시스템은 모든 글이 일단 구글 시트에 저장되기 때문에 발행 전에 검토하고 수정을 할 수 있습니다.

409
00:32:37,500 --> 00:32:40,532
결과물을 보면서 프롬프트를 조금씩 개선해 나가고

410
00:32:40,764 --> 00:32:45,880
이 생성된 글 퀄리티가 충분히 마음에 들면 이 발행 단계도 자동화할 수 있는데요.

411
00:32:46,185 --> 00:32:47,380
방법은 간단합니다.

412
00:32:47,558 --> 00:32:55,720
이 메이크 시나리오에서 이 발행 부분 링크드인과 X 모듈을 이 업데이트 모듈 하위에 이렇게 붙여주시면 됩니다.

413
00:32:56,333 --> 00:33:03,320
그러면은 뉴스 선택만 하면 글 작성부터 발행까지 한 번에 처리되는 원스텝 자동화로 업그레이드 하실 수 있습니다.

414
00:33:03,761 --> 00:33:08,316
그리고 여기까지 따라와 주신 분들을 위해서 이 시스템을 당장 활용할 수 있도록

415
00:33:08,661 --> 00:33:13,080
make.com 시나리오 템플릿과 프롬프트 예시를 모두 무료로 드리고 있습니다.

416
00:33:13,455 --> 00:33:22,912
필요하신 분들은 고정 댓글을 통해서 제 단톡방 커뮤니케이션, 제 뉴스레터를 구독해주시면 바로 다운받을 수 있으니까 참고해주세요.

417
00:33:23,530 --> 00:33:27,868
단톡방에서 다양한 AI 활용 팁에 대한 질문 답변도 나누실 수 있으니까

418
00:33:28,255 --> 00:33:33,560
이런 자동화 시스템 구축에 어려움을 느끼시는 분들도 부담없이 참여해주시면 좋겠습니다.

419
00:33:33,940 --> 00:33:40,580
오늘은 이렇게 메이크닷컴을 활용해서 SNS 포스팅을 자동화하는 시스템을 구축하는 방법을 설명드렸는데요.

420
00:33:40,880 --> 00:33:45,580
더 많은 AI 활용 팁이 궁금하시다면 구독과 알림설정 부탁드립니다.

421
00:33:45,935 --> 00:33:49,633
다음 영상에서 더 유익한 정보와 함께 찾아뵙겠습니다.

422
00:33:49,693 --> 00:33:51,220
시청해주셔서 감사합니다.

