1
00:00:05,930 --> 00:00:08,990
이것이 바로 지능이 만들어지는 방식입니다.

2
00:00:11,610 --> 00:00:13,290
새로운 종류의 공장입니다.

3
00:00:15,150 --> 00:00:16,250
토큰 생성기.

4
00:00:18,130 --> 00:00:19,890
AI의 구성 요소입니다.

5
00:00:22,110 --> 00:00:23,990
토큰이 새로운 시대를 열었습니다.

6
00:00:24,710 --> 00:00:26,830
특별한 세계로 나아가는 첫걸음입니다.

7
00:00:27,150 --> 00:00:29,430
무한한 가능성이 탄생하는 곳입니다.

8
00:00:34,710 --> 00:00:37,190
토큰은 단어를 지식으로 변화시키고,

9
00:00:37,590 --> 00:00:39,450
이미지에 생명을 불어넣습니다.

10
00:00:42,570 --> 00:00:44,550
아이디어를 비디오로 만들고,

11
00:00:47,230 --> 00:00:49,750
어떤 환경에서도 안전하게 탐색할 수 있게 도와줍니다.

12
00:00:52,470 --> 00:00:55,290
토큰은 로봇에게 장인처럼 움직이는 법을 가르칩니다.

13
00:01:00,370 --> 00:01:02,270
새로운 축하 방법을 알려주고,

14
00:01:02,430 --> 00:01:03,510
승리를 축하하게 합니다.

15
00:01:03,550 --> 00:01:04,750
마티니 한 잔 주세요.

16
00:01:05,050 --> 00:01:06,050
곧 준비됩니다.

17
00:01:07,410 --> 00:01:08,410
고마워요, 아담.

18
00:01:10,230 --> 00:01:12,990
그리고 가장 필요할 때 마음의 평화를 줍니다.

19
00:01:13,790 --> 00:01:14,790
안녕하세요, 마루카.

20
00:01:15,230 --> 00:01:16,010
안녕하세요, 안나.

21
00:01:16,230 --> 00:01:17,730
다시 만나서 반가워요.

22
00:01:18,490 --> 00:01:19,110
안녕하세요, 엠마.

23
00:01:19,250 --> 00:01:21,210
오늘 혈액 샘플을 채취할 거예요, 괜찮죠?

24
00:01:21,450 --> 00:01:22,110
걱정하지 마세요.

25
00:01:22,370 --> 00:01:24,090
제가 항상 여기 있을 거예요.

26
00:01:27,030 --> 00:01:28,630
숫자에 의미를 부여하고,

27
00:01:30,670 --> 00:01:32,330
더 나은 이해를 돕습니다.

28
00:01:32,430 --> 00:01:33,430
우리 주변의 세상을요.

29
00:01:41,580 --> 00:01:43,780
우리 주변의 위험을 예측하고,

30
00:01:51,940 --> 00:01:54,560
우리 안의 위협에 대한 치료법을 찾습니다.

31
00:02:01,900 --> 00:02:03,920
토큰은 우리의 비전을 현실로 만들고,

32
00:02:10,870 --> 00:02:12,590
우리가 잃어버린 것을 되찾아 줍니다.

33
00:02:16,890 --> 00:02:17,890
재커리.

34
00:02:18,070 --> 00:02:19,970
내 목소리를 되찾았어, 친구.

35
00:02:23,310 --> 00:02:25,010
그들은 우리가 앞으로 나아갈 수 있게 돕고,

36
00:02:26,950 --> 00:02:28,970
한 걸음씩 나아가게 합니다.

37
00:02:35,520 --> 00:02:36,800
그리고 거대한 도약을 합니다.

38
00:02:38,780 --> 00:02:39,780
함께.

39
00:02:53,850 --> 00:02:54,850
그리고 이곳에서,

40
00:02:57,370 --> 00:02:58,930
모든 것이 시작됩니다.

41
00:03:06,880 --> 00:03:08,220
무대로 모시겠습니다.

42
00:03:08,440 --> 00:03:11,220
엔비디아의 창립자이자 CEO, 젠슨 황입니다.

43
00:03:20,940 --> 00:03:22,420
CES에 오신 것을 환영합니다.

44
00:03:25,040 --> 00:03:27,120
라스베이거스에 오신 기분이 어떠신가요?

45
00:03:28,220 --> 00:03:30,100
제 재킷이 마음에 드시나요?

46
00:03:32,480 --> 00:03:35,940
게리 샤피로와는 반대로 가려고 생각했습니다.

47
00:03:37,900 --> 00:03:39,600
결국 저는 라스베이거스에 있으니까요.

48
00:03:39,720 --> 00:03:46,800
만약 이게 잘 안되면, 여러분 모두가 반대한다면, 음, 그냥 익숙해지세요.

49
00:03:46,801 --> 00:03:49,900
여러분은 이 상황을 받아들여야 한다고 생각합니다.

50
00:03:51,340 --> 00:03:54,080
한 시간 정도 지나면 기분이 좋아질 거예요.

51
00:03:58,470 --> 00:04:01,770
자, 엔비디아에 오신 것을 환영합니다.

52
00:04:01,910 --> 00:04:04,550
사실, 여러분은 엔비디아의 디지털 트윈 내부에 있습니다.

53
00:04:05,850 --> 00:04:08,930
이제 엔비디아로 여러분을 모셔가겠습니다.

54
00:04:09,510 --> 00:04:11,110
여러분, 엔비디아에 오신 것을 환영합니다.

55
00:04:14,750 --> 00:04:17,710
여러분은 저희 디지털 트윈 내부에 있습니다.

56
00:04:21,000 --> 00:04:23,580
여기 있는 모든 것은 AI로 생성되었습니다.

57
00:04:26,750 --> 00:04:29,930
정말 특별한 여정이었고, 특별한 한 해였습니다.

58
00:04:30,910 --> 00:04:34,130
그리고 그 시작은 1993년이었습니다.

59
00:04:34,630 --> 00:04:34,850
준비됐나요?

60
00:04:34,930 --> 00:04:35,930
시작!

61
00:04:36,270 --> 00:04:40,654
NV1으로 우리는 일반 컴퓨터가 할 수 없는 일을 할 수 있는

62
00:04:40,655 --> 00:04:44,110
컴퓨터를 만들고 싶었습니다.

63
00:04:44,690 --> 00:04:49,370
그리고 NV1은 PC에서 게임 콘솔을 사용할 수 있게 했습니다.

64
00:04:50,450 --> 00:04:53,850
저희 프로그래밍 아키텍처는 UDA라고 불렀습니다.

65
00:04:54,510 --> 00:04:57,530
약간 뒤늦게 C라는 글자가 추가되었죠.

66
00:04:57,690 --> 00:05:00,770
하지만 UDA는 통합 장치 아키텍처였습니다.

67
00:05:01,230 --> 00:05:05,567
그리고 UDA의 첫 번째 개발자이자 첫 번째 응용 프로그램은

68
00:05:05,568 --> 00:05:10,410
세가의 버추어 파이터였습니다.

69
00:05:11,450 --> 00:05:17,850
6년 후, 1999년에 저희는 프로그래밍 가능한 GPU를 발명했습니다.

70
00:05:18,690 --> 00:05:24,967
그리고 이는 20년이 넘는 기간 동안 놀라운

71
00:05:24,968 --> 00:05:28,910
진보를 이룬 GPU라는 놀라운 프로세서의 시작이었습니다.

72
00:05:29,390 --> 00:05:32,410
이것은 현대 컴퓨터 그래픽을 가능하게 했습니다.

73
00:05:33,770 --> 00:05:40,430
그리고 지금으로부터 30년 후, 세가의 버추어 파이터는 완전히 영화 같아졌습니다.

74
00:05:42,530 --> 00:05:46,110
이것이 곧 출시될 새로운 버추어 파이터 프로젝트입니다.

75
00:05:46,250 --> 00:05:47,250
정말 기대됩니다.

76
00:05:47,990 --> 00:05:49,090
정말 놀랍습니다.

77
00:05:49,970 --> 00:05:56,070
그 후 6년, 1999년 이후 6년 후에 저희는 CUDA를 발명했습니다.

78
00:05:56,630 --> 00:06:03,170
저희는 GPU의 프로그래밍 가능성을 설명하거나 표현하여

79
00:06:03,171 --> 00:06:06,291
이를 통해 이점을 얻을 수 있는 풍부한 알고리즘 세트를 만들 수 있었습니다.

80
00:06:06,690 --> 00:06:10,410
CUDA는 처음에 설명하기 어려웠습니다.

81
00:06:10,810 --> 00:06:12,510
사실, 몇 년이 걸렸습니다.

82
00:06:12,770 --> 00:06:15,470
대략 6년 정도 걸렸습니다.

83
00:06:16,230 --> 00:06:16,910
어떻게든.

84
00:06:16,911 --> 00:06:18,350
6년 후.

85
00:06:19,030 --> 00:06:20,770
6년쯤 후에.

86
00:06:23,130 --> 00:06:24,130
2012년.

87
00:06:26,030 --> 00:06:31,490
알렉스 크르제프스키, 일리야 수츠케버, 제프 힌튼이 CUDA를 발견했습니다.

88
00:06:31,830 --> 00:06:35,330
그것을 사용해서 AlexNet을 처리했습니다.

89
00:06:35,490 --> 00:06:37,790
그리고 나머지는 역사입니다.

90
00:06:38,230 --> 00:06:41,610
그 이후로 AI는 놀라운 속도로 발전해 왔습니다.

91
00:06:41,930 --> 00:06:44,110
지각 AI에서 시작하여,

92
00:06:44,111 --> 00:06:47,650
이제 이미지, 단어, 소리를 이해할 수 있습니다.

93
00:06:48,610 --> 00:06:49,850
생성 AI로.

94
00:06:50,250 --> 00:06:52,850
이미지, 텍스트, 소리를 생성할 수 있습니다.

95
00:06:53,690 --> 00:06:56,530
이제는 에이전트 AI입니다.

96
00:06:57,290 --> 00:07:01,830
인식하고, 추론하고, 계획하고, 행동할 수 있는 AI입니다.

97
00:07:02,470 --> 00:07:06,670
그리고 다음 단계는, 오늘 밤에 이야기할 것 중 일부는, 물리적 AI입니다.

98
00:07:07,350 --> 00:07:08,350
2012년.

99
00:07:08,430 --> 00:07:11,910
이제 마법처럼 2018년.

100
00:07:11,911 --> 00:07:15,170
정말 놀라운 일이 일어났습니다.

101
00:07:16,870 --> 00:07:20,310
구글의 트랜스포머가 버트(Bert)로 출시되었습니다.

102
00:07:20,590 --> 00:07:25,170
그리고 AI의 세계가 정말로 도약했습니다.

103
00:07:26,230 --> 00:07:28,934
아시다시피 트랜스포머는 인공 지능의

104
00:07:28,935 --> 00:07:31,130
판도를 완전히 바꿔 놓았습니다.

105
00:07:31,510 --> 00:07:35,610
사실, 컴퓨팅 전체의 판도를 완전히 바꿔 놓았습니다.

106
00:07:36,270 --> 00:07:41,710
저희는 AI가 단순히 새로운 응용 프로그램이 아니라는 것을 제대로 인식했습니다.

107
00:07:41,711 --> 00:07:44,730
새로운 사업 기회와 더불어 말입니다.

108
00:07:44,970 --> 00:07:50,330
하지만 AI, 더 중요하게는 트랜스포머에 의해 가능해진 머신 러닝은,

109
00:07:50,410 --> 00:07:53,990
컴퓨팅 작동 방식을 근본적으로 변화시킬 것입니다.

110
00:07:54,630 --> 00:08:01,450
오늘날 컴퓨팅은 모든 계층에서 혁신을 이루었습니다.

111
00:08:01,750 --> 00:08:05,177
CPU에서 실행되는 코딩 지침을 통해

112
00:08:05,178 --> 00:08:08,850
사람들이 사용하는 소프트웨어 도구를 만드는 것에서,

113
00:08:09,170 --> 00:08:11,130
이제 머신 러닝을 사용합니다.

114
00:08:11,131 --> 00:08:14,350
이는 신경망을 생성하고 최적화합니다.

115
00:08:14,570 --> 00:08:16,950
GPU에서 처리하고,

116
00:08:17,070 --> 00:08:18,830
인공 지능을 생성합니다.

117
00:08:19,550 --> 00:08:24,570
기술 스택의 모든 계층이 완전히 바뀌었습니다.

118
00:08:25,090 --> 00:08:29,170
단 12년 만에 일어난 놀라운 변화입니다.

119
00:08:29,870 --> 00:08:35,870
이제 우리는 거의 모든 형태의 정보를 이해할 수 있습니다.

120
00:08:36,130 --> 00:08:40,190
물론 여러분은 텍스트, 이미지, 소리 등을 보셨을 겁니다.

121
00:08:40,191 --> 00:08:44,810
하지만 그것들을 이해할 수 있을 뿐만 아니라 아미노산도 이해할 수 있습니다.

122
00:08:44,990 --> 00:08:46,030
물리학도 이해할 수 있습니다.

123
00:08:46,450 --> 00:08:47,810
우리는 그것들을 이해합니다.

124
00:08:47,890 --> 00:08:50,510
우리는 그것들을 번역하고 생성할 수 있습니다.

125
00:08:50,830 --> 00:08:53,750
응용 프로그램은 정말 끝이 없습니다.

126
00:08:54,110 --> 00:08:58,245
사실, 여러분이 보는 거의 모든 AI 응용 프로그램에서

127
00:08:58,246 --> 00:09:01,151
어떤 양식의 입력으로 학습되었습니까?

128
00:09:01,810 --> 00:09:04,650
어떤 양식의 정보로 변환되었습니까?

129
00:09:04,910 --> 00:09:07,590
그리고 어떤 양식의 정보를 생성하고 있습니까?

130
00:09:07,591 --> 00:09:10,069
이 세 가지 기본적인 질문을 하면, 거의 모든

131
00:09:10,070 --> 00:09:13,870
응용 프로그램을 추론할 수 있습니다.

132
00:09:13,990 --> 00:09:18,490
AI 기반 응용 프로그램이 계속 등장하는 것을 볼 때,

133
00:09:18,710 --> 00:09:23,810
AI 네이티브, 그 핵심에는 이러한 기본 개념이 있습니다.

134
00:09:24,010 --> 00:09:28,590
머신 러닝은 모든 응용 프로그램이 구축되는 방식,

135
00:09:28,710 --> 00:09:32,350
컴퓨팅이 수행되는 방식, 그리고 그 너머의 가능성을 변화시켰습니다.

136
00:09:32,890 --> 00:09:35,950
글쎄요, GPU는...

137
00:09:37,270 --> 00:09:43,990
GeForce는 많은 면에서 AI를 포함한 이 모든 것의 근간입니다.

138
00:09:44,850 --> 00:09:48,050
GeForce는 AI가 대중에게 다가갈 수 있도록 했습니다.

139
00:09:48,450 --> 00:09:52,050
이제 AI가 GeForce로 돌아오고 있습니다.

140
00:09:52,830 --> 00:09:56,830
AI 없이는 할 수 없는 일들이 너무나 많습니다.

141
00:09:57,010 --> 00:10:00,210
지금부터 그 중 몇 가지를 보여드리겠습니다.

142
00:11:34,780 --> 00:11:38,020
이것은 실시간 컴퓨터 그래픽이었습니다.

143
00:11:44,960 --> 00:11:50,660
어떤 컴퓨터 그래픽 연구원이나 컴퓨터 과학자도 여러분에게

144
00:11:50,661 --> 00:11:55,960
이 시점에서 모든 픽셀을 레이 트레이싱하는 것이 가능하다고 말하지 않았을 겁니다.

145
00:11:56,640 --> 00:11:58,820
레이 트레이싱은 빛의 시뮬레이션입니다.

146
00:11:59,000 --> 00:12:02,120
여러분들이 보셨던 기하학적 형태의 양은 정말 터무니없었습니다.

147
00:12:02,440 --> 00:12:05,660
인공 지능 없이는 불가능했을 것입니다.

148
00:12:06,220 --> 00:12:08,380
저희가 한 두 가지 기본적인 일이 있습니다.

149
00:12:09,160 --> 00:12:13,700
물론 프로그래밍 가능한 셰이딩과 레이 트레이싱 가속을 사용했습니다.

150
00:12:13,701 --> 00:12:16,456
저희는 레이 트레이싱 가속을 사용하여 매우 아름다운 픽셀을 생성했습니다.

151
00:12:16,480 --> 00:12:23,760
하지만 그런 다음 인공 지능이 그 픽셀에 의해 조건화되고 제어되어

152
00:12:23,761 --> 00:12:27,240
다른 많은 픽셀을 생성하도록 했습니다.

153
00:12:27,500 --> 00:12:31,139
색상이 어떻게 되어야 하는지 알고 있기 때문에 공간적으로 다른 픽셀을 생성할 수 있을 뿐만 아니라,

154
00:12:31,140 --> 00:12:33,900
색상이 어떻게 되어야 하는지 알고 있기 때문에 공간적으로 다른 픽셀을 생성할 수 있을 뿐만 아니라,

155
00:12:34,280 --> 00:12:37,760
엔비디아의 슈퍼컴퓨터에서 훈련을 받았습니다.

156
00:12:37,880 --> 00:12:41,060
그리고 GPU에서 실행되는 신경망은...

157
00:12:41,061 --> 00:12:45,680
저희가 렌더링하지 않은 픽셀을 추론하고 예측할 수 있습니다.

158
00:12:46,320 --> 00:12:49,540
저희는 그것을 할 수 있을 뿐만 아니라 DLSS라고 부릅니다.

159
00:12:49,880 --> 00:12:54,520
최신 세대의 DLSS는 프레임을 넘어 생성합니다.

160
00:12:54,860 --> 00:12:56,460
미래를 예측할 수 있습니다.

161
00:12:57,120 --> 00:13:00,940
저희가 계산하는 모든 프레임에 대해 세 개의 추가 프레임을 생성합니다.

162
00:13:01,560 --> 00:13:05,540
만약 제가 여러분이 보신 4개의 프레임만 계산한다고 말한다면...

163
00:13:06,000 --> 00:13:08,400
왜냐하면 저희는 한 프레임을 렌더링하고 세 개를 생성할 것이기 때문입니다.

164
00:13:08,401 --> 00:13:14,900
만약 제가 풀 HD, 4K에서 4개의 프레임이라고 말한다면, 약 3천 3백만 픽셀입니다.

165
00:13:15,260 --> 00:13:22,040
그 3천 3백만 픽셀 중에서, 저희는 2백만 픽셀만 계산했습니다.

166
00:13:24,260 --> 00:13:28,843
프로그래밍 가능한 셰이더와 레이 트레이싱 엔진을 사용하여

167
00:13:28,844 --> 00:13:33,440
계산적으로 할 수 있다는 것은 정말 기적입니다.

168
00:13:33,441 --> 00:13:38,380
2백만 픽셀을 계산하고 AI가 다른 모든 프레임을 예측하게 할 수 있습니다.

169
00:13:38,400 --> 00:13:39,400
33개.

170
00:13:39,900 --> 00:13:44,720
결과적으로, 엄청나게 높은 성능으로 렌더링할 수 있습니다.

171
00:13:45,100 --> 00:13:47,560
AI가 훨씬 적은 계산을 하기 때문입니다.

172
00:13:48,400 --> 00:13:52,180
물론 그것을 생성하기 위해서는 엄청난 양의 훈련이 필요합니다.

173
00:13:52,440 --> 00:13:56,360
하지만 일단 훈련이 되면, 생성은 매우 효율적입니다.

174
00:13:57,020 --> 00:14:00,620
이것이 인공 지능의 놀라운 기능 중 하나입니다.

175
00:14:00,900 --> 00:14:04,320
그래서 많은 놀라운 일들이 일어나고 있는 것입니다.

176
00:14:04,560 --> 00:14:08,380
저희는 GeForce를 사용하여 인공 지능을 가능하게 했고,

177
00:14:08,381 --> 00:14:11,800
이제 인공 지능이 GeForce를 혁신하고 있습니다.

178
00:14:12,360 --> 00:14:16,340
여러분, 오늘 저희는 차세대 제품을 발표합니다.

179
00:14:17,040 --> 00:14:19,900
RTX 블랙웰 제품군입니다.

180
00:14:20,280 --> 00:14:21,280
한번 보시죠.

181
00:15:19,250 --> 00:15:20,250
여기 있습니다.

182
00:15:21,070 --> 00:15:29,050
저희의 새로운 GeForce RTX 50 시리즈 블랙웰 아키텍처입니다.

183
00:15:29,590 --> 00:15:31,970
GPU는 정말 강력합니다.

184
00:15:32,790 --> 00:15:34,930
920억 개의 트랜지스터.

185
00:15:36,210 --> 00:15:38,010
4,000 TOPS.

186
00:15:38,510 --> 00:15:40,890
4페타플롭의 AI.

187
00:15:41,350 --> 00:15:44,370
지난 세대인 Ada보다 3배 더 높습니다.

188
00:15:44,550 --> 00:15:47,570
그리고 제가 보여드린 픽셀들을 생성하려면 그 모든 것이 필요합니다.

189
00:15:48,970 --> 00:15:51,810
380 레이 트레이싱 테라플롭스.

190
00:15:52,130 --> 00:15:54,910
저희가 계산해야 하는 픽셀들을 위해,

191
00:15:54,911 --> 00:15:57,630
가능한 가장 아름다운 이미지를 계산할 수 있게 합니다.

192
00:15:58,300 --> 00:16:01,610
물론, 125 셰이더 테라플롭스도 있습니다.

193
00:16:01,611 --> 00:16:04,510
실제로는 동시 셰이더 테라플롭스가 있으며,

194
00:16:04,511 --> 00:16:07,450
동일한 성능의 정수 유닛도 있습니다.

195
00:16:07,570 --> 00:16:09,690
즉, 듀얼 셰이더 두 개입니다.

196
00:16:09,890 --> 00:16:11,430
하나는 부동 소수점용이고,

197
00:16:11,590 --> 00:16:12,590
하나는 정수용입니다.

198
00:16:13,210 --> 00:16:15,810
마이크론의 G7 메모리.

199
00:16:15,950 --> 00:16:18,390
초당 1.8테라바이트입니다.

200
00:16:18,470 --> 00:16:20,310
저희의 이전 세대보다 두 배의 성능입니다.

201
00:16:20,630 --> 00:16:24,870
이제 AI 워크로드와 컴퓨터 그래픽 워크로드를

202
00:16:24,871 --> 00:16:26,770
혼합할 수 있습니다.

203
00:16:27,150 --> 00:16:29,610
그리고 이 세대의 놀라운 점 중 하나는,

204
00:16:29,611 --> 00:16:35,490
프로그래밍 가능한 셰이더가 이제 신경망을 처리할 수 있게 되었다는 것입니다.

205
00:16:35,750 --> 00:16:39,030
따라서 셰이더가 이러한 신경망을 수행할 수 있습니다.

206
00:16:39,230 --> 00:16:43,310
결과적으로, 저희는 신경 텍스처 압축을 발명했고,

207
00:16:43,311 --> 00:16:45,630
신경 재료 셰이딩도 발명했습니다.

208
00:16:45,910 --> 00:16:49,530
그 결과, AI를 사용하여 텍스처를 배우고, 압축 알고리즘을 배우고,

209
00:16:49,531 --> 00:16:52,470
그 결과로만 가능한 놀랍도록 아름다운 이미지를 얻게 되었습니다.

210
00:16:52,471 --> 00:16:56,090
텍스처를 배우고, 압축 알고리즘을 배우고

211
00:16:56,091 --> 00:16:58,030
그 결과로 놀라운 결과를 얻게 되었습니다.

212
00:16:58,031 --> 00:17:02,570
자, 이것이 바로 새로운...

213
00:17:05,790 --> 00:17:07,730
RTX 블랙웰 59입니다.

214
00:17:12,270 --> 00:17:16,470
이제 기계 설계조차도 기적입니다.

215
00:17:16,810 --> 00:17:18,310
이것 보세요, 팬이 두 개 있습니다.

216
00:17:19,330 --> 00:17:22,430
이 전체 그래픽 카드는 거대한 팬 하나입니다.

217
00:17:23,210 --> 00:17:25,490
질문은, 그래픽 카드가 어디 있느냐는 것입니다.

218
00:17:25,590 --> 00:17:26,590
정말로 이만큼 큰가요?

219
00:17:27,870 --> 00:17:30,710
전압 조정기 설계는 최첨단입니다.

220
00:17:31,830 --> 00:17:32,830
놀라운 디자인입니다.

221
00:17:33,050 --> 00:17:34,870
엔지니어링 팀이 정말 잘했습니다.

222
00:17:35,250 --> 00:17:36,150
자, 여기 있습니다.

223
00:17:36,270 --> 00:17:37,270
감사합니다.

224
00:17:42,860 --> 00:17:45,100
자, 이것이 속도와 피드입니다.

225
00:17:45,240 --> 00:17:46,240
그렇다면 어떻게 비교될까요?

226
00:17:49,020 --> 00:17:52,300
자, 이것은 RTX 4090입니다.

227
00:17:54,000 --> 00:17:56,240
네, 여러분 중 많은 분들이 가지고 계시겠죠.

228
00:17:58,560 --> 00:17:59,560
알고 있습니다.

229
00:17:59,820 --> 00:18:01,800
보세요, 가격이 1,599달러입니다.

230
00:18:01,801 --> 00:18:05,500
이것은 여러분이 할 수 있는 최고의 투자 중 하나입니다.

231
00:18:07,780 --> 00:18:17,460
1,599달러에 여러분의 10,000달러짜리 PC 엔터테인먼트 사령부로 가져가세요.

232
00:18:17,700 --> 00:18:18,700
그렇지 않나요?

233
00:18:19,420 --> 00:18:21,020
그렇지 않다고 말하지 마세요.

234
00:18:21,280 --> 00:18:22,280
부끄러워하지 마세요.

235
00:18:23,940 --> 00:18:25,320
수냉식입니다.

236
00:18:26,680 --> 00:18:28,280
전체에 화려한 조명이 있습니다.

237
00:18:29,880 --> 00:18:31,300
떠날 때 잠가두세요.

238
00:18:33,780 --> 00:18:35,900
이것이 현대의 홈시어터입니다.

239
00:18:36,100 --> 00:18:37,300
완벽한 이치에 맞습니다.

240
00:18:37,740 --> 00:18:41,597
그리고 이제 1,599달러로 업그레이드할 수 있게 되었고

241
00:18:41,598 --> 00:18:44,760
엄청난 성능 향상을 이룰 수 있습니다.

242
00:18:44,840 --> 00:18:48,280
자, 이제 블랙웰 제품군, RTX 5070입니다.

243
00:18:49,320 --> 00:18:52,860
4090 성능을 549달러에 제공합니다.

244
00:19:01,800 --> 00:19:04,100
인공 지능 없이는 불가능합니다.

245
00:19:04,480 --> 00:19:07,620
4 TOPS 없이는 불가능합니다.

246
00:19:07,621 --> 00:19:11,620
4테라옵스의 AI 텐서 코어 없이는 불가능합니다.

247
00:19:11,860 --> 00:19:14,220
G7 메모리 없이는 불가능합니다.

248
00:19:14,860 --> 00:19:19,040
자, 5070, 4090 성능을 549달러에 제공합니다.

249
00:19:19,520 --> 00:19:20,640
그리고 여기 전체 제품군이 있습니다.

250
00:19:20,740 --> 00:19:23,960
5070부터 5090까지 모두 있습니다.

251
00:19:24,340 --> 00:19:27,060
5090은 4090보다 두 배의 성능을 제공합니다.

252
00:19:30,180 --> 00:19:31,180
출시...

253
00:19:31,620 --> 00:19:35,960
물론 1월부터 대량으로 생산하여 공급할 예정입니다.

254
00:19:35,961 --> 00:19:41,694
정말 놀랍지만, 저희는 이러한 거대한 성능의 GPU를

255
00:19:41,695 --> 00:19:46,420
노트북에 넣는 데 성공했습니다.

256
00:19:46,720 --> 00:19:49,140
이것은 5070 노트북입니다.

257
00:19:49,780 --> 00:19:55,800
1,299달러에 이 5070 노트북은 4090 성능을 제공합니다.

258
00:19:56,220 --> 00:19:58,000
어딘가에 하나 있을 것 같습니다.

259
00:19:59,940 --> 00:20:01,320
이것을 보여드리죠.

260
00:20:03,040 --> 00:20:05,760
이것은... 이거 한번 보세요.

261
00:20:06,220 --> 00:20:08,121
여기, 제가... 여기요.

262
00:20:08,880 --> 00:20:10,080
주머니가 몇 개 없네요.

263
00:20:11,920 --> 00:20:13,620
여러분, 자닌 폴입니다.

264
00:20:17,930 --> 00:20:18,990
상상해 보시겠어요?

265
00:20:19,150 --> 00:20:21,810
여기 이 놀라운 그래픽 카드, 블랙웰이 있습니다.

266
00:20:21,950 --> 00:20:23,970
저희는 이걸 축소해서 저 안에 넣을 것입니다.

267
00:20:24,190 --> 00:20:25,450
이해가 되시나요?

268
00:20:27,450 --> 00:20:30,230
인공 지능 없이는 그렇게 할 수 없습니다.

269
00:20:30,390 --> 00:20:33,702
그 이유는 저희가 텐서 코어를 사용하여

270
00:20:33,703 --> 00:20:35,790
대부분의 픽셀을 생성하기 때문입니다.

271
00:20:35,791 --> 00:20:40,790
따라서 필요한 픽셀만 레이 트레이싱하고, 인공 지능을 사용하여

272
00:20:40,791 --> 00:20:42,810
나머지 모든 픽셀을 생성합니다.

273
00:20:43,110 --> 00:20:46,750
결과적으로 에너지 효율이 엄청나게 높습니다.

274
00:20:47,430 --> 00:20:51,153
컴퓨터 그래픽의 미래는 신경 렌더링, 즉

275
00:20:51,154 --> 00:20:53,711
인공 지능과 컴퓨터 그래픽의 융합입니다.

276
00:20:54,110 --> 00:20:59,450
그리고 정말 놀라운 점은... 아, 여기 있네요.

277
00:20:59,670 --> 00:21:00,670
감사합니다.

278
00:21:01,510 --> 00:21:03,890
놀라울 정도로 활기찬 기조연설이네요.

279
00:21:05,710 --> 00:21:09,410
그리고 정말 놀라운 점은 여기에 넣을 GPU 제품군입니다.

280
00:21:09,750 --> 00:21:15,770
따라서 5090이 얇은 노트북에도 들어갈 것입니다.

281
00:21:15,930 --> 00:21:18,950
마지막 노트북은 14.9밀리미터였습니다.

282
00:21:19,290 --> 00:21:22,310
5080, 5070 Ti, 5070이 있습니다.

283
00:21:22,970 --> 00:21:23,530
아시겠죠?

284
00:21:23,590 --> 00:21:28,730
자, 여러분, RTX 블랙웰 제품군입니다.

285
00:21:37,840 --> 00:21:38,840
글쎄요, GeForce는...

286
00:21:39,100 --> 00:21:42,000
AI를 세상에 가져왔습니다.

287
00:21:42,620 --> 00:21:43,620
AI를 대중화했습니다.

288
00:21:44,080 --> 00:21:48,180
이제 AI가 돌아와서 GeForce를 혁신했습니다.

289
00:21:48,440 --> 00:21:51,000
인공 지능에 대해 이야기해 보겠습니다.

290
00:21:51,320 --> 00:21:53,100
엔비디아의 다른 곳으로 가보시죠.

291
00:21:58,160 --> 00:21:59,880
이곳은 문자 그대로 저희 사무실입니다.

292
00:22:00,040 --> 00:22:01,640
여기는 문자 그대로 엔비디아 본사입니다.

293
00:22:04,180 --> 00:22:06,620
자, AI에 대해 이야기해 보겠습니다.

294
00:22:07,120 --> 00:22:15,080
업계는 인공 지능을 확장하기 위해 경쟁하고 있습니다.

295
00:22:17,140 --> 00:22:20,960
그리고 스케일링 법칙은 강력한 모델입니다.

296
00:22:21,020 --> 00:22:24,240
여러 세대에 걸쳐 연구자들과 업계에서 관찰되고

297
00:22:24,241 --> 00:22:28,860
입증된 경험적 법칙입니다.

298
00:22:29,600 --> 00:22:35,540
스케일링 법칙에 따르면 데이터가 많을수록,

299
00:22:35,541 --> 00:22:39,120
가지고 있는 학습 데이터가 많을수록, 모델이 클수록,

300
00:22:39,121 --> 00:22:42,100
그리고 더 많은 컴퓨팅을 적용할수록, 따라서

301
00:22:42,101 --> 00:22:47,580
모델의 효과가 더 커지거나 성능이 더 좋아집니다.

302
00:22:48,220 --> 00:22:50,560
스케일링 법칙은 계속됩니다.

303
00:22:51,340 --> 00:22:54,100
정말 놀라운 점은 이제 우리가 향하고 있다는 것입니다.

304
00:22:54,840 --> 00:22:59,360
물론 인터넷은 매년 작년보다 약 두 배 더 많은 데이터를 생성하고 있습니다.

305
00:22:59,361 --> 00:23:01,220
매년 작년보다 두 배나 더 많은 양입니다.

306
00:23:01,420 --> 00:23:04,040
제 생각에 앞으로 몇 년 안에 우리는

307
00:23:04,041 --> 00:23:08,720
인류가 시작된 이래로 인류가 생산한 모든 데이터보다 더 많은 데이터를 생산할 것입니다.

308
00:23:08,721 --> 00:23:09,980
시작 이후로 말이죠.

309
00:23:10,180 --> 00:23:13,980
그래서 우리는 여전히 엄청난 양의 데이터를 생성하고 있습니다.

310
00:23:14,160 --> 00:23:16,260
그리고 그것은 다중 모드가 되어가고 있습니다.

311
00:23:16,280 --> 00:23:18,440
비디오, 이미지, 소리입니다.

312
00:23:18,620 --> 00:23:23,120
이 모든 데이터를 사용하여 AI의 기본 지식을 학습할 수 있습니다.

313
00:23:23,480 --> 00:23:25,340
AI의 기초 지식을 말이죠.

314
00:23:25,620 --> 00:23:31,260
하지만 사실, 두 가지 다른 스케일링 법칙이 등장했습니다.

315
00:23:31,500 --> 00:23:33,220
약간 직관적입니다.

316
00:23:33,660 --> 00:23:37,740
두 번째 스케일링 법칙은 사후 학습 스케일링 법칙입니다.

317
00:23:37,940 --> 00:23:41,360
사후 학습 스케일링 법칙은 기술적 기법을 사용합니다.

318
00:23:41,361 --> 00:23:43,100
강화 학습, 인간 피드백과 같은 것입니다.

319
00:23:44,240 --> 00:23:50,980
기본적으로 AI는 인간의 질문에 따라 답변을 생성하고 생성합니다.

320
00:23:51,260 --> 00:23:53,500
그러면 인간은 당연히 피드백을 제공합니다.

321
00:23:54,140 --> 00:23:55,920
그것보다 훨씬 더 복잡합니다.

322
00:23:55,980 --> 00:23:57,620
하지만 그 강화 학습 시스템은,

323
00:23:58,060 --> 00:24:01,140
상당히 많은 양의 매우 고품질 프롬프트를 가지고

324
00:24:01,141 --> 00:24:05,060
AI가 자신의 기술을 개선하도록 합니다.

325
00:24:05,520 --> 00:24:08,660
특정 분야에 대한 기술을 미세 조정할 수 있습니다.

326
00:24:09,020 --> 00:24:10,740
수학 문제를 더 잘 풀 수 있습니다.

327
00:24:11,360 --> 00:24:12,160
추론에 더 능숙해집니다.

328
00:24:12,320 --> 00:24:13,320
등등 말이죠.

329
00:24:13,380 --> 00:24:17,280
기본적으로 멘토가 있거나 학교를 마친 후에

330
00:24:17,281 --> 00:24:21,740
코치가 피드백을 주는 것과 같습니다.

331
00:24:22,200 --> 00:24:23,640
그래서 테스트를 받습니다.

332
00:24:23,860 --> 00:24:24,440
피드백을 받습니다.

333
00:24:24,580 --> 00:24:25,580
자신을 개선합니다.

334
00:24:25,760 --> 00:24:28,540
또한 강화 학습 AI 피드백도 있습니다.

335
00:24:29,000 --> 00:24:31,080
그리고 합성 데이터 생성도 있습니다.

336
00:24:32,140 --> 00:24:34,020
이러한 기술은 다소...

337
00:24:36,020 --> 00:24:38,900
비유하자면 자기 연습과 같습니다.

338
00:24:39,260 --> 00:24:42,080
여러분은 특정 문제에 대한 답을 알고 있습니다.

339
00:24:42,500 --> 00:24:45,220
그리고 정답을 얻을 때까지 계속 시도합니다.

340
00:24:45,580 --> 00:24:47,380
그래서 AI에 제시할 수 있습니다.

341
00:24:47,740 --> 00:24:53,420
매우 복잡하고 어려운 문제, 기능적으로 검증 가능한 문제를 제시할 수 있습니다.

342
00:24:53,520 --> 00:24:55,840
그리고 우리가 이해할 수 있는 답을 가지고 있습니다.

343
00:24:56,080 --> 00:24:57,080
아마도 정리를 증명하는 것일 수 있습니다.

344
00:24:57,240 --> 00:25:00,420
아마도 기하학 문제를 푸는 것일 수 있습니다.

345
00:25:00,760 --> 00:25:05,140
그래서 이러한 문제들은 AI가 답을 생성하도록 할 것입니다.

346
00:25:05,340 --> 00:25:09,260
그리고 강화 학습을 사용하여 스스로 개선하는 방법을 배우게 됩니다.

347
00:25:09,261 --> 00:25:11,600
그것을 사후 학습이라고 합니다.

348
00:25:11,760 --> 00:25:14,200
사후 학습에는 엄청난 양의 계산이 필요합니다.

349
00:25:14,520 --> 00:25:17,540
하지만 최종 결과는 놀라운 모델을 생성합니다.

350
00:25:18,020 --> 00:25:20,600
이제 세 번째 스케일링 법칙이 있습니다.

351
00:25:20,820 --> 00:25:25,780
그리고 이 세 번째 스케일링 법칙은 테스트 시간 스케일링이라는 것과 관련이 있습니다.

352
00:25:26,140 --> 00:25:29,440
테스트 시간 스케일링은 기본적으로 사용 중일 때입니다.

353
00:25:29,660 --> 00:25:34,340
AI를 사용 중일 때, AI는 이제 다른 리소스 할당을

354
00:25:34,341 --> 00:25:37,340
적용할 수 있는 기능을 가집니다.

355
00:25:37,660 --> 00:25:41,440
매개변수를 개선하는 대신, 이제 AI는

356
00:25:41,441 --> 00:25:46,420
답변을 생성하기 위해 얼마만큼의 계산을 사용할지 결정하는 데 집중합니다.

357
00:25:46,421 --> 00:25:47,580
생성하고 싶어하는 답변을 말이죠.

358
00:25:48,900 --> 00:25:50,660
추론은 이것을 생각하는 한 가지 방법입니다.

359
00:25:50,940 --> 00:25:52,940
장시간 사고는 이것을 생각하는 한 가지 방법입니다.

360
00:25:53,120 --> 00:25:58,620
직접적인 추론이나 원샷 답변 대신에, 그것에 대해 추론할 수 있습니다.

361
00:25:58,740 --> 00:26:00,920
문제를 여러 단계로 나눌 수 있습니다.

362
00:26:01,300 --> 00:26:04,720
여러 아이디어를 생성하고 평가할 수 있습니다.

363
00:26:05,100 --> 00:26:09,200
AI 시스템은 여러분이 생성한 아이디어 중 어떤 아이디어가

364
00:26:09,260 --> 00:26:10,260
가장 좋은 아이디어인지 평가합니다.

365
00:26:10,540 --> 00:26:12,600
아마도 단계별로 문제를 해결할 것입니다.

366
00:26:12,760 --> 00:26:13,760
등등 말이죠.

367
00:26:13,860 --> 00:26:18,320
그래서 이제 테스트 시간 스케일링은 엄청나게 효과적인 것으로 입증되었습니다.

368
00:26:18,960 --> 00:26:22,180
이러한 일련의 기술을 보고 계실 겁니다.

369
00:26:22,181 --> 00:26:27,680
그리고 이러한 모든 스케일링 법칙은 ChatGPT에서 01, 03, 그리고 지금 Gemini Pro에 이르기까지

370
00:26:27,681 --> 00:26:33,280
놀라운 성과를 보면서 등장하고 있습니다.

371
00:26:33,480 --> 00:26:38,120
이 모든 시스템이 사전 학습에서 사후 학습으로, 테스트 시간 스케일링으로,

372
00:26:38,121 --> 00:26:42,120
단계별로 이러한 여정을 거치고 있습니다.

373
00:26:42,580 --> 00:26:46,100
물론 저희에게 필요한 계산량은 엄청납니다.

374
00:26:46,580 --> 00:26:49,900
그리고 우리는, 사실, 우리는, 사실,

375
00:26:49,901 --> 00:26:53,280
사회가 점점 더 새롭고 더 나은 지능을 생성하기 위해

376
00:26:53,281 --> 00:26:57,020
계산량을 확장할 수 있는 능력을 갖기를 바랍니다.

377
00:26:57,660 --> 00:27:00,100
물론 지능은 가장 가치 있는 자산입니다.

378
00:27:00,101 --> 00:27:03,541
그리고 그것은 매우 어려운 많은 문제를 해결하는 데 적용될 수 있습니다.

379
00:27:04,000 --> 00:27:05,980
그래서 스케일링 법칙입니다.

380
00:27:06,340 --> 00:27:08,000
엄청난 수요를 이끌어내고 있습니다.

381
00:27:08,120 --> 00:27:09,420
엔비디아 컴퓨팅에 대한 수요를요.

382
00:27:09,640 --> 00:27:14,881
그것은 우리가 블랙웰이라고 부르는 이 놀라운 칩에 대한 엄청난 수요를 이끌어내고 있습니다.

383
00:27:15,460 --> 00:27:16,860
블랙웰을 한번 살펴보시죠.

384
00:27:17,540 --> 00:27:19,940
자, 블랙웰이 본격적으로 생산되고 있습니다.

385
00:27:22,600 --> 00:27:24,801
정말 놀랍습니다. 어떻게 생겼는지 말이죠.

386
00:27:25,100 --> 00:27:27,520
자, 우선 몇 가지...

387
00:27:27,880 --> 00:27:31,361
모든 클라우드 서비스 제공업체는 현재 시스템을 가동하고 있습니다.

388
00:27:31,680 --> 00:27:33,500
여기 약... 15곳의 회사에서 시스템을 보유하고 있습니다.

389
00:27:34,120 --> 00:27:35,120
15...

390
00:27:36,420 --> 00:27:37,420
15...

391
00:27:38,120 --> 00:27:39,620
15개 컴퓨터 제조업체에서 말입니다.

392
00:27:39,920 --> 00:27:43,420
약 200가지 다른 SKU로 제작되고 있습니다.

393
00:27:43,700 --> 00:27:45,080
200가지 다른 구성입니다.

394
00:27:45,360 --> 00:27:49,620
수냉식, 공냉식, x86... 엔비디아 그레이 CPU 버전이 있습니다.

395
00:27:50,040 --> 00:27:52,160
NVLink 36x2.

396
00:27:52,300 --> 00:27:54,520
NVLink 72x1.

397
00:27:54,720 --> 00:27:58,040
전 세계의 거의 모든 데이터 센터를 수용할 수 있도록 다양한 유형의 시스템이 있습니다.

398
00:27:58,041 --> 00:28:00,020
세상의 모든 데이터 센터를 말이죠.

399
00:28:00,780 --> 00:28:03,669
자, 이러한 시스템은 약 45개의 공장에서

400
00:28:03,670 --> 00:28:06,580
현재 제조되고 있습니다.

401
00:28:06,800 --> 00:28:08,000
그것은 여러분에게 알려줍니다...

402
00:28:08,120 --> 00:28:12,280
인공 지능이 얼마나 널리 퍼져 있는지, 그리고 업계가 얼마나 많이

403
00:28:12,281 --> 00:28:16,040
이 새로운 컴퓨팅 모델에서 인공 지능에 뛰어들고 있는지를 말이죠.

404
00:28:17,240 --> 00:28:22,100
자... 우리가 그렇게 열심히 추진하는 이유는, 저희가 필요한 것은,

405
00:28:22,101 --> 00:28:23,101
더 많은 계산이기 때문입니다.

406
00:28:23,160 --> 00:28:27,361
그리고 그것은 매우 분명합니다. 그것은 매우 분명합니다.

407
00:28:30,780 --> 00:28:31,780
자닌?

408
00:28:38,350 --> 00:28:39,350
있잖아요, 저는...

409
00:28:41,130 --> 00:28:45,550
어두운 곳에 손을 뻗고 싶어하지 않는다는 것을 말하기가 어렵습니다.

410
00:28:45,850 --> 00:28:46,850
어두운 곳에요.

411
00:28:48,090 --> 00:28:49,851
잠시만요... 이거 괜찮은 생각인가요?

412
00:28:51,770 --> 00:28:52,770
알겠습니다.

413
00:29:08,840 --> 00:29:09,840
기다려 보세요.

414
00:29:12,220 --> 00:29:13,220
기다려 보세요.

415
00:29:17,740 --> 00:29:18,940
저는 자격이 있다고 생각했어요.

416
00:29:24,220 --> 00:29:26,020
분명히, 요너는 제가 자격이 없다고 생각했나 봐요.

417
00:29:27,680 --> 00:29:28,680
알겠습니다.

418
00:29:29,560 --> 00:29:30,960
이것은 제 쇼 앤 텔입니다.

419
00:29:31,320 --> 00:29:32,360
이것은 쇼 앤 텔입니다.

420
00:29:32,960 --> 00:29:33,960
자...

421
00:29:34,860 --> 00:29:35,140
MVLink 시스템입니다.

422
00:29:35,560 --> 00:29:36,780
바로 이거요.

423
00:29:36,840 --> 00:29:37,900
이 MVLink 시스템이요.

424
00:29:38,200 --> 00:29:40,460
이것이 GB200입니다.

425
00:29:40,800 --> 00:29:41,800
MVLink 72.

426
00:29:42,460 --> 00:29:44,200
무게는 1.5톤입니다.

427
00:29:45,280 --> 00:29:46,860
부품은 60만 개입니다.

428
00:29:48,720 --> 00:29:50,480
대략 자동차 20대와 같습니다.

429
00:29:54,360 --> 00:29:55,720
120킬로와트입니다.

430
00:29:58,750 --> 00:29:59,890
이것은...

431
00:30:00,610 --> 00:30:03,951
뒤쪽에 있는 척추가 모든 GPU를 함께 연결합니다.

432
00:30:04,970 --> 00:30:06,350
2마일 길이의...

433
00:30:06,610 --> 00:30:07,610
구리 케이블.

434
00:30:10,030 --> 00:30:11,070
5,000개의 케이블.

435
00:30:12,550 --> 00:30:15,750
이것은 전 세계 45개 공장에서 제조되고 있습니다.

436
00:30:16,470 --> 00:30:17,510
저희가 그것들을 만듭니다.

437
00:30:18,010 --> 00:30:19,470
액체 냉각합니다.

438
00:30:19,610 --> 00:30:20,610
테스트합니다.

439
00:30:20,690 --> 00:30:21,990
분해합니다.

440
00:30:22,070 --> 00:30:26,450
1.5톤이기 때문에 부품으로 나누어 데이터 센터로 배송합니다.

441
00:30:27,110 --> 00:30:30,230
데이터 센터 외부에서 재조립하고 설치합니다.

442
00:30:30,630 --> 00:30:32,170
제조 과정이 정말 엄청납니다.

443
00:30:32,171 --> 00:30:36,190
하지만 이 모든 것의 목표는 스케일링 법칙이

444
00:30:36,191 --> 00:30:40,190
컴퓨팅을 너무나도 강력하게 추진하고 있기 때문에 이런 수준의 계산이

445
00:30:40,191 --> 00:30:45,070
블랙웰이 이전 세대에 비해 와트당 성능을

446
00:30:45,071 --> 00:30:46,470
4배 향상시켰기 때문입니다.

447
00:30:47,550 --> 00:30:49,470
와트당 성능이 4배 향상되었습니다.

448
00:30:49,590 --> 00:30:52,550
달러당 성능이 3배 향상되었습니다.

449
00:30:52,870 --> 00:30:56,550
그것은 기본적으로 한 세대 만에

450
00:30:56,551 --> 00:31:01,431
이러한 모델 학습 비용을 3배 줄였다는 것을 의미합니다.

451
00:31:02,170 --> 00:31:04,365
또는 모델 크기를 3배 늘리고 싶다면

452
00:31:04,425 --> 00:31:06,350
비용은 거의 동일합니다.

453
00:31:06,750 --> 00:31:08,330
하지만 중요한 것은 이것입니다.

454
00:31:08,950 --> 00:31:14,870
이것들은 우리가 ChatGPT를 사용하거나 Gemini를 사용하거나 미래에 휴대폰을 사용할 때 우리 모두가 사용하는 토큰을 생성하고 있습니다.

455
00:31:14,871 --> 00:31:16,970
미래에 휴대폰을 사용할 때 말입니다.

456
00:31:17,190 --> 00:31:20,930
거의 모든 응용 프로그램이 이러한 AI 토큰을 소비하게 될 것입니다.

457
00:31:21,270 --> 00:31:24,030
그리고 이러한 AI 토큰은 이러한 시스템에 의해 생성됩니다.

458
00:31:25,030 --> 00:31:28,010
그리고 모든 데이터 센터는 전력에 의해 제한됩니다.

459
00:31:28,011 --> 00:31:35,650
따라서 블랙웰의 와트당 성능이 이전 세대의 4배라면,

460
00:31:35,990 --> 00:31:40,610
데이터 센터에서 창출할 수 있는 수익, 즉 창출할 수 있는 사업량이

461
00:31:40,611 --> 00:31:43,051
4배 증가합니다.

462
00:31:43,270 --> 00:31:47,330
그래서 이러한 AI 공장 시스템은 오늘날 실제로 공장입니다.

463
00:31:47,630 --> 00:31:52,430
이제 이 모든 것의 목표는 하나의 거대한 칩을 만드는 것입니다.

464
00:31:52,770 --> 00:31:55,610
저희에게 필요한 계산량은 정말 엄청납니다.

465
00:31:55,910 --> 00:31:57,990
그리고 이것은 기본적으로 하나의 거대한 칩입니다.

466
00:31:57,991 --> 00:32:05,410
만약 우리가 이것을 하나의 칩으로 만들어야 했다면, 당연히 이것은 웨이퍼 크기였을 것입니다.

467
00:32:05,550 --> 00:32:06,550
멋지네요.

468
00:32:07,210 --> 00:32:08,970
이 안에 디스코 조명이 있네요.

469
00:32:12,470 --> 00:32:16,750
만약 우리가 이것을 하나의 칩으로 만들어야 했다면, 당연히 이것은 웨이퍼 크기였을 것입니다.

470
00:32:16,890 --> 00:32:19,250
하지만 이것에는 수율의 영향이 포함되어 있지 않습니다.

471
00:32:19,450 --> 00:32:21,830
아마도 크기가 세 배나 네 배는 더 커야 할 것입니다.

472
00:32:22,130 --> 00:32:27,470
하지만 우리가 여기에서 기본적으로 가지고 있는 것은 72개의 블랙웰 GPU 또는 144개의 다이입니다.

473
00:32:27,970 --> 00:32:29,470
이 하나의 칩입니다.

474
00:32:29,550 --> 00:32:31,550
이 칩은 1.4 엑사플롭스입니다.

475
00:32:31,750 --> 00:32:35,850
세계 최대의 슈퍼컴퓨터이자 가장 빠른 슈퍼컴퓨터는 불과 최근에

476
00:32:36,170 --> 00:32:41,030
이 전체 방 슈퍼컴퓨터에서 엑사플롭스 이상을 달성했습니다.

477
00:32:41,390 --> 00:32:45,310
이것은 AI 부동 소수점 성능이 1.4 엑사플롭스입니다.

478
00:32:45,770 --> 00:32:49,090
14테라바이트의 메모리가 있지만, 놀라운 것은 이것입니다.

479
00:32:49,270 --> 00:32:52,950
메모리 대역폭은 초당 1.2페타바이트입니다.

480
00:32:53,170 --> 00:32:59,530
이는 기본적으로 현재 발생하고 있는 전체 인터넷 트래픽입니다.

481
00:32:59,531 --> 00:33:00,931
지금 바로 이런 일이 일어나고 있습니다.

482
00:33:01,790 --> 00:33:07,430
전 세계 인터넷 트래픽 전체가 이러한 칩을 통해 처리되고 있습니다.

483
00:33:08,090 --> 00:33:15,113
총 130조 개의 트랜지스터를 가지고 있습니다.

484
00:33:15,114 --> 00:33:19,570
2,592개의 CPU 코어, 그리고 다양한 네트워킹을 갖추고 있습니다.

485
00:33:20,230 --> 00:33:22,630
그래서 저는... 이걸 할 수 있었으면 좋겠어요.

486
00:33:22,750 --> 00:33:23,430
그럴 것 같지는 않네요.

487
00:33:23,431 --> 00:33:24,950
자, 이것들이 블랙웰입니다.

488
00:33:26,650 --> 00:33:31,230
이것들은 저희의 ConnectX 네트워킹 칩입니다.

489
00:33:31,770 --> 00:33:37,150
이것들은 NVLink이고, 저희는 NVLink 척추에 대해 가짜로 꾸미려고 노력하고 있지만,

490
00:33:37,430 --> 00:33:38,750
그것은 불가능합니다.

491
00:33:39,290 --> 00:33:45,550
그리고 이것들은 모두 HBM 메모리, 14테라바이트의 HBM 메모리입니다.

492
00:33:46,030 --> 00:33:50,850
이것이 저희가 하려는 것이고, 이것이 블랙웰 시스템의 기적입니다.

493
00:33:51,210 --> 00:33:52,990
바로 여기 블랙웰 다이입니다.

494
00:33:53,630 --> 00:33:55,970
이것은 세계에서 만들어진 가장 큰 단일 칩입니다.

495
00:33:56,390 --> 00:34:00,450
하지만 기적은 실제로 그 외에도 있습니다.

496
00:34:01,090 --> 00:34:02,870
이것이 그레이스 블랙웰 시스템입니다.

497
00:34:03,410 --> 00:34:07,250
글쎄요, 물론 이 모든 것의 목표는 우리가... 감사합니다.

498
00:34:07,310 --> 00:34:08,310
고마워요.

499
00:34:11,540 --> 00:34:13,640
잠시 앉아 있을 수 있는 의자가 있을까요?

500
00:34:26,440 --> 00:34:28,340
미켈롭 울트라 한 잔 주시겠어요?

501
00:34:40,170 --> 00:34:45,130
어떻게 우리가 미켈롭 울트라 스타디움에 있을 수 있을까요?

502
00:34:47,930 --> 00:34:50,550
엔비디아에 왔는데 여러분에게 GPU가 없는 것과 같습니다.

503
00:34:55,710 --> 00:34:58,408
따라서 우리는 더 크고 더 큰 모델을 훈련하고 싶기 때문에

504
00:34:58,409 --> 00:35:00,711
엄청난 양의 계산이 필요합니다.

505
00:35:01,290 --> 00:35:05,824
그리고 이러한 추론은 한 번의 추론이었지만, 미래에는

506
00:35:05,825 --> 00:35:08,326
AI가 스스로와 대화하게 될 것입니다.

507
00:35:08,350 --> 00:35:09,390
생각할 것입니다.

508
00:35:09,670 --> 00:35:11,790
내부적으로 반영하고 처리할 것입니다.

509
00:35:12,090 --> 00:35:17,230
따라서 오늘 토큰이 여러분에게 생성될 때, 초당 20개 또는 30개 토큰으로 나오는 한,

510
00:35:17,231 --> 00:35:22,550
기본적으로 누구든지 읽을 수 있는 속도입니다.

511
00:35:22,690 --> 00:35:31,030
그러나 미래에는, 그리고 지금 GPT-01, 새로운 Gemini Pro와

512
00:35:31,031 --> 00:35:34,690
새로운 0103 모델은 스스로와 대화하고 있습니다.

513
00:35:34,810 --> 00:35:35,450
반영하고 있습니다.

514
00:35:35,710 --> 00:35:36,710
생각하고 있습니다.

515
00:35:36,830 --> 00:35:39,490
따라서 상상할 수 있듯이, 토큰이 입력될 수 있는 속도는

516
00:35:39,491 --> 00:35:42,530
엄청나게 높습니다.

517
00:35:42,870 --> 00:35:46,990
따라서 토큰 속도, 토큰 생성 속도를 훨씬 높여야 합니다.

518
00:35:47,130 --> 00:35:52,390
또한 서비스 품질이 특별할 수 있도록, 고객 비용이 계속 낮을 수 있도록 동시에 비용을 크게 낮춰야 하며,

519
00:35:52,391 --> 00:35:56,450
AI는 계속 확장될 것입니다.

520
00:35:56,630 --> 00:35:58,710
그리고 그것이 바로 MVLink를 만든 근본적인 목적이자 이유입니다.

521
00:35:58,970 --> 00:36:02,430
그리고 그것이 MVLink를 만든 이유입니다.

522
00:36:02,670 --> 00:36:04,712
기업 세계에서 가장 중요한 일 중 하나는

523
00:36:04,713 --> 00:36:07,790
에이전트 AI입니다.

524
00:36:08,390 --> 00:36:12,130
기본적으로 에이전트 AI는 테스트 시간 스케일링의 완벽한 예입니다.

525
00:36:13,010 --> 00:36:15,110
AI는 모델 시스템입니다.

526
00:36:15,790 --> 00:36:17,690
그 중 일부는 고객과 상호 작용하고, 사용자와 상호 작용합니다.

527
00:36:17,691 --> 00:36:19,750
사용자와 상호 작용하는 것입니다.

528
00:36:19,910 --> 00:36:22,970
일부는 정보를 검색하고, 스토리지에서 정보를 검색하는 것입니다.

529
00:36:22,971 --> 00:36:27,290
RAG와 같은 의미론적 AI 시스템처럼요.

530
00:36:27,630 --> 00:36:29,830
아마도 인터넷에 접속할 것입니다.

531
00:36:30,110 --> 00:36:32,830
아마도 PDF 파일을 연구할 것입니다.

532
00:36:33,030 --> 00:36:34,650
따라서 도구를 사용할 수 있습니다.

533
00:36:34,710 --> 00:36:35,950
계산기를 사용할 수 있습니다.

534
00:36:36,090 --> 00:36:40,470
그리고 차트 등을 생성하기 위해 생성적 AI를 사용할 수 있습니다.

535
00:36:40,710 --> 00:36:44,990
그리고 여러분이 제공한 문제를 가져와서 단계별로 나누고,

536
00:36:45,790 --> 00:36:47,266
이러한 모든 다른 모델을 통합합니다.

537
00:36:47,290 --> 00:36:51,490
미래에 고객에게 응답하기 위해, AI가 응답하기 위해,

538
00:36:51,710 --> 00:36:55,310
질문을 하면 답변이 나오기 시작하는 것이 일반적이었습니다.

539
00:36:55,430 --> 00:36:57,612
미래에는 질문을 하면 많은

540
00:36:57,613 --> 00:36:59,591
모델이 백그라운드에서 작동하게 될 것입니다.

541
00:36:59,650 --> 00:37:05,270
따라서 추론에 사용되는 계산량인 테스트 시간 스케일링은

542
00:37:05,410 --> 00:37:07,050
엄청나게 증가할 것입니다.

543
00:37:07,470 --> 00:37:10,346
더욱더 나은 답변을 원하기 때문에 엄청나게 증가할 것입니다.

544
00:37:10,370 --> 00:37:14,583
업계가 에이전트 AI를 구축하는 데 도움이 되도록, 저희의

545
00:37:14,584 --> 00:37:17,330
시장 진출 전략은 기업 고객에게 직접적으로 하는 것이 아닙니다.

546
00:37:17,570 --> 00:37:23,050
저희의 시장 진출 전략은 IT 생태계의 소프트웨어 개발자와 협력하여 기술을 통합하여

547
00:37:23,051 --> 00:37:25,821
새로운 기능을 가능하게 하는 것입니다.

548
00:37:25,822 --> 00:37:29,011
CUDA 라이브러리로 했던 것처럼 말이죠.

549
00:37:29,050 --> 00:37:32,530
이제 AI 라이브러리로 그렇게 하고 싶습니다.

550
00:37:33,090 --> 00:37:38,870
과거 컴퓨팅 모델에 컴퓨터 그래픽을 수행하거나 선형 대수를 수행하거나 유체 역학을 수행하는 API가 있었던 것처럼,

551
00:37:38,871 --> 00:37:43,270
미래에는 이러한 가속 라이브러리, CUDA 가속 라이브러리 위에

552
00:37:43,271 --> 00:37:46,544
AI 라이브러리가 있을 것입니다.

553
00:37:46,545 --> 00:37:49,570
AI 라이브러리가 있을 것입니다.

554
00:37:49,930 --> 00:37:54,410
저희는 생태계가 에이전트 AI를 구축하는 데 도움이 되도록 세 가지를 만들었습니다.

555
00:37:54,790 --> 00:38:00,410
기본적으로 모두 패키지된 AI 마이크로서비스인 NVIDIA NIMS입니다.

556
00:38:00,530 --> 00:38:06,210
여기에는 이 모든 매우 복잡한 CUDA 소프트웨어, CUDA DNN, Cutlass,

557
00:38:06,250 --> 00:38:12,490
또는 Tensor RTLM 또는 Triton, 또는 이 모든 다양한 매우 복잡한 소프트웨어와

558
00:38:12,491 --> 00:38:16,830
모델 자체를 패키징하고, 최적화하고, 컨테이너에 넣어 어디든 가져갈 수 있습니다.

559
00:38:16,831 --> 00:38:18,970
컨테이너에 넣어 어디든 가져갈 수 있습니다.

560
00:38:19,170 --> 00:38:23,510
따라서 비전, 언어 이해, 음성,

561
00:38:23,710 --> 00:38:27,167
애니메이션, 디지털 생물학 모델이 있으며, 물리적 AI를 위한

562
00:38:27,168 --> 00:38:29,930
몇 가지 새로운 흥미로운 모델이 출시될 예정입니다.

563
00:38:30,170 --> 00:38:34,010
이러한 AI 모델은 모든 클라우드에서 실행됩니다. 왜냐하면

564
00:38:34,011 --> 00:38:36,571
엔비디아의 GPU는 이제 모든 클라우드에서 사용할 수 있기 때문입니다.

565
00:38:36,670 --> 00:38:38,230
모든 OEM에서 사용할 수 있습니다.

566
00:38:38,370 --> 00:38:42,470
따라서 이러한 모델을 가져와서 소프트웨어 패키지에 통합하여,

567
00:38:42,490 --> 00:38:49,270
Cadence에서 실행되는 AI 에이전트를 만들거나 ServiceNow 에이전트,

568
00:38:49,450 --> 00:38:54,170
또는 SAP 에이전트가 될 수 있으며, 고객에게 배포하여

569
00:38:54,171 --> 00:38:56,171
고객이 소프트웨어를 실행하려는 곳에서 실행할 수 있습니다.

570
00:38:56,310 --> 00:38:58,730
다음 계층은 NVIDIA Nemo라고 부르는 것입니다.

571
00:38:59,210 --> 00:39:09,690
Nemo는 기본적으로 디지털 직원 온보딩 및 교육 평가 시스템입니다.

572
00:39:10,770 --> 00:39:16,490
미래에는 이러한 AI 에이전트가 기본적으로 여러분의 직원과 함께 일하고 여러분을 대신하여 작업을 수행하는 디지털 인력이 될 것입니다.

573
00:39:16,491 --> 00:39:21,290
여러분을 대신하여 작업을 수행하는 디지털 인력입니다.

574
00:39:21,590 --> 00:39:27,470
따라서 이러한 특수 에이전트, 이 특수 에이전트를 여러분의 회사로 데려오는 방법은 직원을 온보딩하는 것과 같습니다.

575
00:39:27,590 --> 00:39:31,890
직원을 온보딩하는 것과 똑같습니다.

576
00:39:32,470 --> 00:39:37,970
따라서 이러한 AI 에이전트가 여러분 회사의 언어 유형에 대해 훈련되도록 돕는 다양한 라이브러리가 있습니다. 아마도 어휘가 여러분 회사에 고유할 수 있고,

577
00:39:37,971 --> 00:39:43,090
여러분의 회사에 고유할 수 있고, 비즈니스 프로세스가 다르고, 일하는 방식이 다를 수 있습니다.

578
00:39:43,091 --> 00:39:46,310
비즈니스 프로세스가 다르고, 여러분이 일하는 방식이 다를 수 있습니다.

579
00:39:46,450 --> 00:39:50,030
따라서 작업 결과물이 어떻게 보여야 하는지에 대한 예시를 제공하고,

580
00:39:50,090 --> 00:39:52,650
그들이 생성하려고 하면 피드백을 제공할 것입니다.

581
00:39:52,830 --> 00:39:55,530
그런 다음 그들을 평가할 것이고, 등등 말이죠.

582
00:39:55,750 --> 00:39:58,210
그리고 그들을 보호할 것입니다.

583
00:39:58,310 --> 00:40:00,126
이것은 여러분이 할 수 없는 일들이라고 말하세요.

584
00:40:00,150 --> 00:40:01,990
이것은 여러분이 말할 수 없는 것들이라고 말하세요.

585
00:40:02,170 --> 00:40:05,090
심지어 특정 정보에 대한 액세스 권한도 부여합니다.

586
00:40:05,910 --> 00:40:11,650
따라서 전체 파이프라인, 디지털 직원 파이프라인, 마지막 라인은 Nemo라고 합니다.

587
00:40:11,830 --> 00:40:16,134
많은 면에서, 모든 회사의 IT 부서는

588
00:40:16,135 --> 00:40:19,610
미래에 AI 에이전트의 HR 부서가 될 것입니다.

589
00:40:20,610 --> 00:40:26,130
오늘날 그들은 IT 산업의 다양한 소프트웨어를 관리하고 유지보수합니다.

590
00:40:26,350 --> 00:40:31,990
미래에는 수많은 디지털 에이전트를 유지 관리, 육성, 온보딩 및 개선하고

591
00:40:31,991 --> 00:40:35,290
회사에서 사용할 수 있도록 제공할 것입니다.

592
00:40:35,291 --> 00:40:40,570
따라서 IT 부서는 일종의 AI 에이전트 HR과 같이 될 것입니다.

593
00:40:41,390 --> 00:40:44,437
그리고 그 위에, 저희는 생태계가 활용할 수 있는

594
00:40:44,438 --> 00:40:48,370
많은 청사진을 제공합니다.

595
00:40:48,470 --> 00:40:51,428
이 모든 것은 완전히 오픈 소스이므로,

596
00:40:51,429 --> 00:40:53,770
청사진을 가져와 수정할 수 있습니다.

597
00:40:53,830 --> 00:40:56,270
저희는 다양한 유형의 에이전트에 대한 청사진을 가지고 있습니다.

598
00:40:56,670 --> 00:40:59,173
오늘 저희는 정말 멋지고, 꽤 영리하다고 생각하는 일을

599
00:40:59,174 --> 00:41:01,531
하고 있다는 것을 발표할 것입니다.

600
00:41:02,030 --> 00:41:04,870
저희는 전체 모델 제품군을 발표합니다.

601
00:41:05,290 --> 00:41:07,090
LAMA를 기반으로 합니다.

602
00:41:07,230 --> 00:41:11,710
NVIDIA LAMA NEMOTRON 언어 기반 모델입니다.

603
00:41:12,230 --> 00:41:16,090
LAMA 3.1은 완전한 현상입니다.

604
00:41:17,150 --> 00:41:22,670
메타에서 LAMA 3.1을 65만 회 다운로드했습니다.

605
00:41:23,010 --> 00:41:24,170
그쯤 됩니다.

606
00:41:24,490 --> 00:41:29,710
그것은 다른 모델로 파생되어 바뀌었습니다.

607
00:41:29,950 --> 00:41:32,630
약 6만 개의 다른 모델로요.

608
00:41:32,850 --> 00:41:35,210
그것이 바로 유일한 이유입니다.

609
00:41:35,290 --> 00:41:37,767
거의 모든 기업과 모든 산업이

610
00:41:37,768 --> 00:41:40,010
AI 작업을 시작하도록 활성화된 이유 말입니다.

611
00:41:40,350 --> 00:41:43,943
저희가 한 일은 LAMA 모델이

612
00:41:43,944 --> 00:41:47,670
기업용으로 더 잘 미세 조정될 수 있다는 것을 깨달은 것입니다.

613
00:41:48,090 --> 00:41:51,490
그래서 저희는 저희의 전문 지식과 역량을 사용하여 그 모델을 미세 조정했습니다.

614
00:41:51,850 --> 00:41:56,770
그리고 그것들을 LAMA NEMOTRON 오픈 모델 제품군으로 만들었습니다.

615
00:41:57,370 --> 00:42:02,470
매우 빠른 응답 시간으로 상호 작용하는 작은 모델이 있습니다.

616
00:42:03,030 --> 00:42:03,670
매우 작습니다.

617
00:42:03,671 --> 00:42:06,630
저희가 슈퍼라고 부르는 모델입니다.

618
00:42:07,210 --> 00:42:08,510
LAMA NEMOTRON 슈퍼입니다.

619
00:42:08,930 --> 00:42:11,750
그것들은 기본적으로 모델의 주류 버전입니다.

620
00:42:11,870 --> 00:42:13,450
또는 울트라 모델입니다.

621
00:42:13,630 --> 00:42:16,518
울트라 모델은 다른 많은 모델의

622
00:42:16,519 --> 00:42:18,830
교사 모델로 사용될 수 있습니다.

623
00:42:19,010 --> 00:42:20,570
보상 모델이 될 수 있습니다.

624
00:42:20,910 --> 00:42:21,450
평가자요.

625
00:42:21,850 --> 00:42:24,637
다른 모델이 답변을 만들고, 그것이

626
00:42:24,638 --> 00:42:27,450
좋은 답변인지 아닌지를 결정하는 심판관입니다.

627
00:42:27,830 --> 00:42:29,830
기본적으로 다른 모델에 피드백을 제공합니다.

628
00:42:30,050 --> 00:42:31,786
많은 다른 방식으로 증류될 수 있습니다.

629
00:42:31,810 --> 00:42:33,190
기본적으로 교사 모델입니다.

630
00:42:33,191 --> 00:42:36,210
지식 증류 모델입니다.

631
00:42:36,570 --> 00:42:37,550
매우 큽니다.

632
00:42:37,590 --> 00:42:38,170
매우 유능합니다.

633
00:42:38,410 --> 00:42:40,950
그리고 이 모든 것을 이제 온라인에서 사용할 수 있습니다.

634
00:42:41,370 --> 00:42:44,870
글쎄요, 이 모델들은 정말 놀랍습니다.

635
00:42:45,270 --> 00:42:48,030
이 모델은 채팅에서 리더보드 1위입니다.

636
00:42:48,370 --> 00:42:50,590
지침에 대한 리더보드.

637
00:42:51,530 --> 00:42:53,670
검색에 대한 리더보드.

638
00:42:54,170 --> 00:42:57,369
따라서 전 세계의 AI 에이전트에서 사용되는

639
00:42:57,370 --> 00:42:59,490
다양한 유형의 기능들을 가지고 있습니다.

640
00:42:59,670 --> 00:43:01,750
이것은 여러분에게 놀라운 모델이 될 것입니다.

641
00:43:02,950 --> 00:43:05,250
또한 저희는 생태계와 협력하고 있습니다.

642
00:43:06,030 --> 00:43:11,690
저희의 모든 NVIDIA AI 기술은 IT 산업에 통합되어 있습니다.

643
00:43:12,290 --> 00:43:15,890
저희는 ServiceNow, SAP, 산업용 AI를 위한 Siemens에서

644
00:43:16,010 --> 00:43:19,590
훌륭한 파트너십을 맺고 정말 훌륭한 작업을 진행하고 있습니다.

645
00:43:20,610 --> 00:43:22,030
Cadence도 훌륭한 작업을 하고 있습니다.

646
00:43:22,150 --> 00:43:23,310
Synopsys도 훌륭한 작업을 하고 있습니다.

647
00:43:23,370 --> 00:43:25,990
저는 Perplexity와 함께 하는 작업이 정말 자랑스럽습니다.

648
00:43:26,030 --> 00:43:27,730
아시다시피, 그들은 검색에 혁명을 일으켰습니다.

649
00:43:28,070 --> 00:43:29,770
정말 환상적인 것입니다.

650
00:43:30,190 --> 00:43:30,730
Codium.

651
00:43:30,731 --> 00:43:33,490
전 세계의 모든 소프트웨어 엔지니어.

652
00:43:33,550 --> 00:43:37,170
이것은 차세대 거대한 AI 응용 프로그램이 될 것입니다.

653
00:43:37,610 --> 00:43:42,290
차세대 거대한 AI 서비스 시대는 소프트웨어 코딩입니다.

654
00:43:42,670 --> 00:43:45,030
전 세계에 3천만 명의 소프트웨어 엔지니어가 있습니다.

655
00:43:45,370 --> 00:43:49,290
모두가 코딩을 돕는 소프트웨어 보조원을 갖게 될 것입니다.

656
00:43:49,770 --> 00:43:52,928
그렇지 않으면 당연히 생산성이 훨씬 떨어지고

657
00:43:52,929 --> 00:43:56,110
더 낮은 품질의 코드를 만들게 될 것입니다.

658
00:43:56,290 --> 00:43:58,030
따라서 이것은 3천만 명입니다.

659
00:43:58,031 --> 00:44:01,150
전 세계에 10억 명의 지식 근로자가 있습니다.

660
00:44:01,290 --> 00:44:02,530
이것은 매우 분명합니다.

661
00:44:02,850 --> 00:44:06,627
AI 에이전트는 아마도 다음 로봇 산업일 것이고

662
00:44:06,628 --> 00:44:09,591
수조 달러 규모의 기회가 될 가능성이 높습니다.

663
00:44:09,810 --> 00:44:15,250
자, 저희가 만든 청사진과 저희 파트너들이 이러한 AI 에이전트로 작업한 내용 중 일부를 보여드리겠습니다.

664
00:44:15,251 --> 00:44:18,050
보여드리겠습니다.

665
00:44:22,830 --> 00:44:25,690
AI 에이전트는 새로운 디지털 인력입니다.

666
00:44:25,691 --> 00:44:28,170
우리와 함께 일하고, 우리를 위해 일합니다.

667
00:44:28,910 --> 00:44:34,990
AI 에이전트는 임무에 대해 추론하고, 작업을 나누고, 데이터를 검색하거나 도구를 사용하여 양질의 응답을 생성하는 모델 시스템입니다.

668
00:44:34,991 --> 00:44:39,890
데이터를 검색하거나 도구를 사용하여 양질의 응답을 생성하는 모델 시스템입니다.

669
00:44:41,090 --> 00:44:46,710
NVIDIA의 에이전트 AI 빌딩 블록, NIM 사전 학습 모델 및 Nemo 프레임워크를 통해 조직은 AI 에이전트를 쉽게 개발하고 어디든 배포할 수 있습니다.

670
00:44:46,711 --> 00:44:51,570
어디든 배포할 수 있습니다.

671
00:44:51,970 --> 00:44:55,490
저희는 에이전트 인력을 온보딩하고 교육할 것입니다.

672
00:44:55,491 --> 00:44:56,810
회사 방식에 따라 말입니다.

673
00:44:57,050 --> 00:44:58,450
직원에게 하는 것처럼 말입니다.

674
00:44:59,170 --> 00:45:03,050
AI 에이전트는 특정 업무 전문가입니다.

675
00:45:03,490 --> 00:45:05,030
네 가지 예를 보여드리겠습니다.

676
00:45:05,670 --> 00:45:10,630
수십억 명의 지식 근로자와 학생들을 위해, AI 연구 보조 에이전트는

677
00:45:10,631 --> 00:45:15,349
강의, 저널, 재무 결과와 같은 복잡한 문서를 수집하고 쉽게 학습할 수 있도록

678
00:45:15,350 --> 00:45:19,510
대화형 팟캐스트를 생성합니다.

679
00:45:19,750 --> 00:45:24,950
UNET 회귀 모델과 확산 모델을 결합하여 CoreDiff는

680
00:45:24,951 --> 00:45:28,270
전역 날씨 예보를 25km에서 2km로 축소할 수 있습니다.

681
00:45:29,950 --> 00:45:34,970
엔비디아와 같은 개발자들은 소프트웨어 취약점을 지속적으로 검사하는

682
00:45:34,971 --> 00:45:37,430
소프트웨어 보안 AI 에이전트를 관리합니다.

683
00:45:37,970 --> 00:45:40,930
개발자에게 필요한 조치를 알려줍니다.

684
00:45:42,850 --> 00:45:49,010
가상 실험실 AI 에이전트는 연구자들이 수십억 개의 화합물을 설계하고 스크리닝하여

685
00:45:49,011 --> 00:45:51,470
유망한 신약 후보를 그 어느 때보다 빠르게 찾을 수 있도록 돕습니다.

686
00:45:53,050 --> 00:45:58,570
NVIDIA Cosmos Nematron Vision Language Models,

687
00:45:58,571 --> 00:46:02,490
LAMA Nematron LLM, 및 Nemo Retriever를 포함하는 NVIDIA Metropolis 청사진을 기반으로 구축된 NVIDIA 분석 AI 에이전트입니다.

688
00:46:02,491 --> 00:46:05,951
NVIDIA Cosmos Nematron Vision Language Models,

689
00:46:06,270 --> 00:46:11,017
메트로폴리스 에이전트는 매일 10만 페타바이트의 비디오를 생성하는

690
00:46:11,018 --> 00:46:14,310
수십억 대의 카메라에서 콘텐츠를 분석합니다.

691
00:46:14,750 --> 00:46:19,810
대화형 검색, 요약 및 자동 보고가 가능합니다.

692
00:46:19,811 --> 00:46:25,970
그리고 교통 흐름을 모니터링하고 혼잡 또는 위험을 표시하는 데 도움이 됩니다.

693
00:46:27,850 --> 00:46:31,454
산업 시설에서는 프로세스를 모니터링하고

694
00:46:31,455 --> 00:46:34,831
개선 권장 사항 또는 개선 사항을 생성합니다.

695
00:46:35,850 --> 00:46:39,977
메트로폴리스 에이전트는 수백 대의 카메라에서 데이터를 중앙 집중화하고

696
00:46:39,978 --> 00:46:43,710
사건이 발생하면 작업자 또는 로봇의 경로를 재지정할 수 있습니다.

697
00:46:44,410 --> 00:46:46,910
에이전트 AI 시대가 도래했습니다.

698
00:46:47,330 --> 00:46:49,070
모든 조직을 위해 말이죠.

699
00:46:53,030 --> 00:46:54,030
좋아요.

700
00:46:57,400 --> 00:47:00,640
저것은 야구 경기에서 한 첫 번째 투구였습니다.

701
00:47:00,720 --> 00:47:01,760
생성된 것이 아니었습니다.

702
00:47:02,200 --> 00:47:04,320
저는 여러분 중 누구도 감명을 받지 않았다고 느꼈습니다.

703
00:47:06,040 --> 00:47:12,040
좋아요, AI는 클라우드에서 생성되었고 클라우드를 위해 만들어졌습니다.

704
00:47:12,360 --> 00:47:14,180
AI는 클라우드에서 생성되었고 클라우드를 위해 만들어졌습니다.

705
00:47:14,320 --> 00:47:18,740
물론 휴대폰에서 AI를 즐기기에는 완벽합니다.

706
00:47:19,440 --> 00:47:20,520
매우 곧.

707
00:47:21,200 --> 00:47:24,040
지속적으로 여러분과 함께할 AI가 있을 것입니다.

708
00:47:24,200 --> 00:47:28,880
그리고 메타 안경을 사용하면, 물론 뭔가를 가리키고,

709
00:47:28,980 --> 00:47:32,080
무언가를 보고 원하는 정보를 물어볼 수 있을 것입니다.

710
00:47:32,340 --> 00:47:35,300
따라서 AI는 클라우드에서 완벽합니다.

711
00:47:35,360 --> 00:47:37,176
클라우드에서 만들어진 것은 클라우드에서 완벽합니다.

712
00:47:37,200 --> 00:47:40,700
하지만 우리는 그 AI를 모든 곳에서 활용할 수 있기를 바랍니다.

713
00:47:40,900 --> 00:47:43,641
이미 엔비디아 AI를 모든 클라우드로 가져갈 수 있다고 언급했지만,

714
00:47:43,642 --> 00:47:46,140
회사 내부에 넣을 수도 있습니다.

715
00:47:46,340 --> 00:47:49,600
하지만 우리가 무엇보다도 하고 싶은 것은 PC에도 넣는 것입니다.

716
00:47:49,601 --> 00:47:54,940
아시다시피 윈도우 95는 컴퓨터 산업에 혁명을 일으켰습니다.

717
00:47:55,220 --> 00:47:58,650
이것은 새로운 멀티미디어 서비스 제품군을 가능하게 했고,

718
00:47:58,651 --> 00:48:01,440
응용 프로그램이 생성되는 방식을 영원히 바꾸었습니다.

719
00:48:02,400 --> 00:48:08,400
물론, 윈도우 95의 이러한 컴퓨팅 모델은 AI에 완벽하지 않습니다.

720
00:48:08,700 --> 00:48:13,540
따라서 우리가 하고 싶은 것은 미래에 AI가 기본적으로 여러분의 AI 비서가 되도록 하는 것입니다.

721
00:48:13,700 --> 00:48:16,060
여러분의 AI 비서가 되는 것입니다.

722
00:48:16,360 --> 00:48:19,580
단순히 3D 모델 대신에.

723
00:48:19,581 --> 00:48:24,180
3D API와 사운드 API, 비디오 API 대신에, 생성적 API가 있을 것입니다.

724
00:48:24,560 --> 00:48:27,539
3D용 생성적 API, 언어용 생성적 API,

725
00:48:27,540 --> 00:48:29,580
사운드용 생성적 AI 등이 있을 것입니다.

726
00:48:29,820 --> 00:48:34,393
그리고 클라우드에 있는 막대한 투자를 활용하면서

727
00:48:34,394 --> 00:48:37,760
그것을 가능하게 하는 시스템이 필요합니다.

728
00:48:38,140 --> 00:48:40,286
세상이 AI 모델을 프로그래밍하는 또 다른 방법을

729
00:48:40,287 --> 00:48:43,461
만들 수 있는 방법은 없을 것입니다.

730
00:48:43,680 --> 00:48:44,920
그것은 일어나지 않을 것입니다.

731
00:48:45,120 --> 00:48:50,748
따라서 만약 우리가 윈도우 PC를 세계적 수준의 AI PC로 만드는 방법을 알아낼 수 있다면,

732
00:48:50,749 --> 00:48:55,200
정말 멋질 것입니다.

733
00:48:55,400 --> 00:48:57,380
그리고 그 해답은 윈도우입니다.

734
00:48:57,800 --> 00:49:00,280
윈도우 WSL2입니다.

735
00:49:00,500 --> 00:49:02,720
윈도우 WSL2.

736
00:49:02,800 --> 00:49:07,140
윈도우 WSL2는 기본적으로 하나 안에 두 개의 운영 체제입니다.

737
00:49:07,340 --> 00:49:08,580
완벽하게 작동합니다.

738
00:49:09,300 --> 00:49:12,305
개발자를 위해 개발되었으며, 베어 메탈에

739
00:49:12,306 --> 00:49:15,341
액세스할 수 있도록 개발되었습니다.

740
00:49:15,500 --> 00:49:17,640
WSL2는 최적화되었습니다.

741
00:49:18,920 --> 00:49:19,560
최적화되었습니다.

742
00:49:19,580 --> 00:49:21,540
클라우드 네이티브 애플리케이션에 최적화되었습니다.

743
00:49:21,760 --> 00:49:26,140
가장 중요한 것은 CUDA에 최적화되었다는 것입니다.

744
00:49:26,460 --> 00:49:30,480
따라서 WSL2는 CUDA를 완벽하게 지원합니다.

745
00:49:30,580 --> 00:49:39,760
결과적으로, NVIDIA NIMS, NVIDIA Nemo,

746
00:49:40,340 --> 00:49:45,474
AI.nvidia.com에 올라갈 저희가 개발한 청사진은,

747
00:49:45,594 --> 00:49:50,760
컴퓨터에 적합하고 모델에 적합하다면, 비전 모델이든,

748
00:49:50,900 --> 00:49:54,700
언어 모델이든, 음성 모델이든, 이러한 애니메이션 디지털 인간 모델이든,

749
00:49:54,701 --> 00:49:59,520
다양한 유형의 모델이 여러분의 PC에 완벽할 것입니다.

750
00:49:59,680 --> 00:50:03,980
다운로드하면 바로 실행될 것입니다.

751
00:50:04,280 --> 00:50:07,960
그래서 저희의 초점은 윈도우 WSL2, 윈도우 PC를

752
00:50:08,160 --> 00:50:14,337
저희가 지원할 첫 번째 등급의 플랫폼으로 바꾸는 것입니다.

753
00:50:14,338 --> 00:50:18,420
그리고 우리가 살아있는 한 유지보수할 것입니다.

754
00:50:18,421 --> 00:50:20,800
그리고 우리가 살아있는 한 유지보수할 것입니다.

755
00:50:20,940 --> 00:50:25,080
이것은 전 세계의 엔지니어와 개발자에게 놀라운 일입니다.

756
00:50:25,360 --> 00:50:27,440
그것으로 무엇을 할 수 있는지 보여드리죠.

757
00:50:27,580 --> 00:50:30,100
이것은 여러분을 위해 만든 청사진의 예 중 하나입니다.

758
00:50:32,940 --> 00:50:37,440
생성 AI는 간단한 텍스트 프롬프트에서 놀라운 이미지를 합성합니다.

759
00:50:37,840 --> 00:50:41,800
그러나 이미지 구성은 단어만 사용하여 제어하기 어려울 수 있습니다.

760
00:50:42,260 --> 00:50:46,229
NVIDIA NIMS 마이크로서비스를 통해 제작자는

761
00:50:46,230 --> 00:50:49,240
단순한 3D 객체를 사용하여 AI 이미지 생성을 안내할 수 있습니다.

762
00:50:49,660 --> 00:50:54,700
컨셉 아티스트가 이 기술을 사용하여 장면의 모양을 개발하는 방법을 살펴보겠습니다.

763
00:50:55,460 --> 00:51:00,600
먼저 손으로 만들거나 AI로 생성한 3D 자산을 배치합니다.

764
00:51:00,920 --> 00:51:04,618
그런 다음 Flux와 같은 이미지 생성 NIM을 사용하여

765
00:51:04,619 --> 00:51:07,800
3D 장면에 맞는 시각적 효과를 만듭니다.

766
00:51:08,640 --> 00:51:11,600
객체를 추가하거나 이동하여 구성을 개선합니다.

767
00:51:13,860 --> 00:51:17,220
카메라 각도를 변경하여 완벽한 장면을 구성합니다.

768
00:51:18,420 --> 00:51:21,160
또는 새로운 프롬프트로 전체 장면을 재구성합니다.

769
00:51:25,260 --> 00:51:31,041
생성 AI와 NVIDIA NIM의 지원을 받아 아티스트는 자신의 비전을 빠르게 실현할 수 있습니다.

770
00:51:34,170 --> 00:51:35,810
PC용 NVIDIA AI입니다.

771
00:51:38,350 --> 00:51:40,984
전 세계에 수억 대의 PC가

772
00:51:40,985 --> 00:51:44,230
윈도우를 가지고 있으므로, 우리는 그것들을 AI에 대비시킬 수 있습니다.

773
00:51:45,110 --> 00:51:47,651
저희가 협력하는 모든 PC OEM은 기본적으로 전 세계 주요 PC OEM은

774
00:51:47,652 --> 00:51:50,850
PC를 준비할 것입니다.

775
00:51:50,851 --> 00:51:51,851
이 스택을 위해 준비할 것입니다.

776
00:51:52,130 --> 00:51:55,350
따라서 AI PC가 곧 여러분의 집으로 찾아갈 것입니다.

777
00:52:01,940 --> 00:52:02,960
리눅스도 좋습니다.

778
00:52:08,780 --> 00:52:10,640
자, 물리적 AI에 대해 이야기해 보겠습니다.

779
00:52:13,100 --> 00:52:15,440
리눅스에 대해 이야기한 김에, 물리적 AI에 대해 이야기해 보죠.

780
00:52:17,320 --> 00:52:18,880
자, 물리적 AI.

781
00:52:20,680 --> 00:52:21,880
상상해 보세요. 상상해 보세요.

782
00:52:23,300 --> 00:52:29,200
여러분은 여러분의 대규모 언어 모델에 컨텍스트, 즉 프롬프트를 제공합니다.

783
00:52:30,900 --> 00:52:37,840
왼쪽에, 그리고 그것은 출력을 생성하기 위해 한 번에 하나씩 토큰을 생성합니다.

784
00:52:38,860 --> 00:52:40,200
기본적으로 그것이 작동하는 방식입니다.

785
00:52:40,380 --> 00:52:42,868
놀라운 점은 이 중간에 있는 모델이

786
00:52:42,869 --> 00:52:45,761
매우 크고 수십억 개의 매개변수를 가지고 있다는 것입니다.

787
00:52:46,020 --> 00:52:51,320
컨텍스트 길이는 믿을 수 없을 정도로 깁니다. 왜냐하면 여러분은 PDF를 로드하기로 결정할 수 있기 때문입니다.

788
00:52:51,560 --> 00:52:55,420
저의 경우, 질문하기 전에 여러 개의 PDF를 로드할 수 있습니다.

789
00:52:56,200 --> 00:52:57,400
이러한 PDF는 그것을 할 수 있습니다.

790
00:52:57,401 --> 00:53:00,320
따라서 만약 제가 토큰으로 바꾸고 싶다면, 트랜스포머의 기본적인 주의 특성은

791
00:53:00,321 --> 00:53:04,173
모든 토큰이 다른 모든 토큰에 대한 관계와 관련성을 찾도록 합니다.

792
00:53:04,174 --> 00:53:07,440
찾도록 합니다.

793
00:53:08,200 --> 00:53:13,880
따라서 수십만 개의 토큰을 가질 수 있고, 계산 부하는 2차적으로 증가하며, 이것을 수행하며, 모든 매개변수,

794
00:53:13,881 --> 00:53:19,600
모든 입력 시퀀스를 트랜스포머의 모든 계층을 통해 처리하고,

795
00:53:19,601 --> 00:53:22,800
트랜스포머의 모든 계층을 통해 처리합니다.

796
00:53:22,980 --> 00:53:24,560
그리고 하나의 토큰을 생성합니다.

797
00:53:24,900 --> 00:53:26,720
그것이 바로 블랙웰이 필요했던 이유입니다.

798
00:53:26,721 --> 00:53:29,580
그리고 다음 토큰이 생성됩니다.

799
00:53:29,740 --> 00:53:34,240
현재 토큰이 완료되면, 현재 토큰을 입력 시퀀스에 넣고

800
00:53:34,241 --> 00:53:37,840
그 전체를 가져와 다음 토큰을 생성합니다.

801
00:53:37,900 --> 00:53:38,900
한 번에 하나씩 합니다.

802
00:53:39,480 --> 00:53:41,760
이것이 트랜스포머 모델입니다.

803
00:53:41,920 --> 00:53:46,600
그것이 매우 효과적이면서도 계산적으로 수요가 많은 이유입니다.

804
00:53:47,240 --> 00:53:51,220
만약 PDF 대신 여러분을 둘러싼 환경이라면요?

805
00:53:51,260 --> 00:53:55,240
그리고 만약 프롬프트 대신 질문이 아닌 요청이라면요?

806
00:53:55,241 --> 00:53:59,000
저기 가서 저 상자를 집어서 가져오라고 말이죠.

807
00:53:59,300 --> 00:54:05,160
그리고 텍스트로 토큰으로 생성되는 대신, 작업 토큰을 생성한다면요?

808
00:54:06,040 --> 00:54:11,560
글쎄요, 제가 방금 설명한 것은 미래 로봇 공학에 매우 합리적인 것입니다.

809
00:54:12,360 --> 00:54:14,540
그리고 그 기술은 바로 코앞에 있습니다.

810
00:54:14,740 --> 00:54:19,060
하지만 우리가 해야 할 일은 효과적으로, 효율적으로

811
00:54:19,240 --> 00:54:25,900
GPT와 반대로 세계 모델을 만드는 것입니다. GPT는 언어 모델이니까요.

812
00:54:26,120 --> 00:54:29,520
그리고 이 세계 모델은 세계의 언어를 이해해야 합니다.

813
00:54:29,600 --> 00:54:31,620
물리적 역학을 이해해야 합니다.

814
00:54:32,460 --> 00:54:35,640
중력, 마찰, 관성과 같은 것들 말입니다.

815
00:54:36,060 --> 00:54:39,260
기하학적 및 공간적 관계를 이해해야 합니다.

816
00:54:39,740 --> 00:54:41,380
원인과 결과를 이해해야 합니다.

817
00:54:41,620 --> 00:54:43,484
만약 여러분이 무언가를 떨어뜨리면 바닥에 떨어지고,

818
00:54:43,485 --> 00:54:45,961
여러분이 찌르면 쓰러집니다.

819
00:54:46,320 --> 00:54:48,540
사물 영속성을 이해해야 합니다.

820
00:54:49,320 --> 00:54:51,607
만약 여러분이 공을 부엌 카운터 위로 굴리면,

821
00:54:51,647 --> 00:54:54,120
그 반대편으로 떨어지면 공이 사라지지 않습니다.

822
00:54:54,121 --> 00:54:57,140
우리는 여전히 거기에 있는 또 다른 양자 세계로 이동할 것입니다.

823
00:54:57,380 --> 00:55:01,440
따라서 이러한 모든 유형의 이해, 직관적인 이해는

824
00:55:01,441 --> 00:55:05,560
오늘날 대부분의 모델이 매우 어려워하는 것들입니다.

825
00:55:05,780 --> 00:55:10,020
그래서 우리는 세계를 만들고 싶습니다. 즉, 세계 기초 모델이 필요합니다.

826
00:55:10,200 --> 00:55:12,540
오늘 우리는 매우 큰 것을 발표합니다.

827
00:55:12,940 --> 00:55:19,440
우리는 엔비디아 Cosmos, 즉 물리적 세계를 이해하도록 설계된 세계 기초 모델을 발표합니다.

828
00:55:19,660 --> 00:55:22,780
물리적 세계를 이해하도록 만들어진 세계 기초 모델입니다.

829
00:55:22,781 --> 00:55:26,080
그리고 이 모델을 정말로 이해하는 유일한 방법은 보는 것입니다.

830
00:55:26,120 --> 00:55:27,120
보시죠.

831
00:55:33,340 --> 00:55:36,600
AI의 다음 개척지는 물리적 AI입니다.

832
00:55:37,080 --> 00:55:40,940
모델 성능은 데이터 가용성과 직접적인 관련이 있습니다.

833
00:55:41,460 --> 00:55:46,060
하지만 물리적 세계 데이터는 포착, 큐레이팅 및 레이블링하는 데 비용이 많이 듭니다.

834
00:55:47,460 --> 00:55:53,626
NVIDIA Cosmos는 물리적 세계 데이터를 발전시키기 위한 세계 기반 모델 개발 플랫폼입니다.

835
00:55:54,253 --> 00:55:58,740
여기에는 자동 회귀 세계 기반 모델, 확산 기반 세계

836
00:55:58,741 --> 00:56:02,472
기반 모델, 고급 토크나이저 및 NVIDIA CUDA,

837
00:56:02,473 --> 00:56:06,461
AI 가속 데이터 파이프라인이 포함됩니다.

838
00:56:08,360 --> 00:56:12,055
코스모스 모델은 텍스트, 이미지 또는 비디오 프롬프트를 수집하고,

839
00:56:12,056 --> 00:56:14,760
가상 세계 상태를 비디오로 생성합니다.

840
00:56:15,780 --> 00:56:21,180
코스모스 생성은 실제 데이터와 같은 AV 및 로봇 공학 사용 사례의 고유한 요구 사항을 우선시합니다.

841
00:56:21,360 --> 00:56:22,760
실제 데이터와 같은 것들입니다.

842
00:56:22,780 --> 00:56:26,060
환경, 조명 및 사물 영속성을 구축합니다.

843
00:56:27,100 --> 00:56:32,480
개발자는 NVIDIA Omniverse를 사용하여 물리학 기반의 지리 공간적으로 정확한

844
00:56:32,481 --> 00:56:38,400
시나리오를 구축한 다음 Omniverse 렌더링을 코스모스로 출력하여 사진처럼 실감나고

845
00:56:38,520 --> 00:56:40,640
물리적 기반의 합성 데이터를 생성합니다.

846
00:56:51,700 --> 00:56:57,794
다양한 객체, 환경, 날씨와 같은 조건 또는 시간대, 또는 극단적인 시나리오든 말이죠.

847
00:56:57,795 --> 00:57:03,280
날씨와 같은 조건 또는 시간대, 또는 극단적인 시나리오든 말이죠.

848
00:57:05,640 --> 00:57:11,420
개발자는 코스모스를 사용하여 정책 모델을 개선하거나 모델 성능을 테스트하고 검증하기 위한

849
00:57:11,421 --> 00:57:16,460
강화 학습 AI 피드백에 대한 세계를 생성합니다.

850
00:57:18,000 --> 00:57:20,140
다중 센서 뷰에서도 마찬가지입니다.

851
00:57:22,800 --> 00:57:26,361
코스모스는 실시간으로 토큰을 생성하여 AI 모델에

852
00:57:26,362 --> 00:57:30,460
선견지명과 다중 세계 시뮬레이션의 힘을 제공할 수 있습니다.

853
00:57:31,040 --> 00:57:35,240
모델이 올바른 경로를 선택하는 데 도움이 되도록 가능한 모든 미래를 생성합니다.

854
00:57:37,000 --> 00:57:40,465
세계 개발자 생태계와 협력하여 NVIDIA는

855
00:57:40,466 --> 00:57:43,720
다음 물결의 물리적 AI를 발전시키는 데 도움을 주고 있습니다.

856
00:57:49,350 --> 00:57:50,730
NVIDIA Cosmos.

857
00:57:52,610 --> 00:57:54,010
NVIDIA Cosmos.

858
00:57:54,850 --> 00:57:56,110
NVIDIA Cosmos.

859
00:57:56,270 --> 00:57:59,530
세계 최초의 세계 기반 모델입니다.

860
00:57:59,990 --> 00:58:04,550
2천만 시간의 비디오로 학습되었습니다.

861
00:58:05,070 --> 00:58:10,290
2천만 시간의 비디오는 역동적인 물리적 움직임에 초점을 맞추고 있습니다.

862
00:58:10,490 --> 00:58:20,511
역동적인 자연, 자연 테마, 걷는 인간, 움직이는 손, 물건을 조작하는 움직임 등입니다.

863
00:58:20,650 --> 00:58:23,930
즉, 빠른 카메라 움직임과 같은 것들이요.

864
00:58:24,090 --> 00:58:28,450
정말 중요한 것은 창의적인 콘텐츠를 생성하는 것이 아니라 AI가 물리적 세계를 이해하도록 가르치는 것입니다.

865
00:58:28,690 --> 00:58:31,650
AI가 물리적 세계를 이해하도록 가르치는 것입니다.

866
00:58:31,651 --> 00:58:35,121
그리고 이 물리적 AI로부터 결과적으로 할 수 있는 여러 가지 후속적인 일들이 있습니다.

867
00:58:35,122 --> 00:58:39,370
여러 가지 후속적인 일들을 할 수 있습니다.

868
00:58:39,490 --> 00:58:42,850
모델을 훈련하기 위해 합성 데이터를 생성할 수 있습니다.

869
00:58:43,150 --> 00:58:46,328
그것을 증류하여 효과적으로 로봇 모델의

870
00:58:46,329 --> 00:58:48,590
시작, 즉 시작점으로 바꿀 수 있습니다.

871
00:58:48,850 --> 00:58:54,350
복수로 물리적으로 그럴듯한, 물리적으로 기반을 둔 것을 생성할 수 있습니다.

872
00:58:55,350 --> 00:58:56,670
미래 시나리오를 말입니다.

873
00:58:56,790 --> 00:58:58,070
기본적으로 닥터 스트레인지처럼요.

874
00:58:58,830 --> 00:59:02,730
이 모델이 물리적 세계를 이해하기 때문에, 이 모델이

875
00:59:02,830 --> 00:59:06,130
물리적 세계를 이해하기 때문에 당연히 수많은 이미지가 생성되는 것을 보셨듯이,

876
00:59:06,131 --> 00:59:10,090
이 모델은 당연히 캡션도 만들 수 있습니다.

877
00:59:10,150 --> 00:59:16,210
따라서 매우 훌륭하게 비디오 캡션을 만들 수 있으며, 그 캡션과

878
00:59:16,211 --> 00:59:20,730
비디오를 사용하여 대규모 언어 모델을 훈련할 수 있습니다.

879
00:59:21,670 --> 00:59:23,550
다중 모드, 대규모 언어 모델입니다.

880
00:59:24,030 --> 00:59:28,650
따라서 이 기술을 사용하여 이 기초 모델을 사용하여

881
00:59:28,651 --> 00:59:33,730
로봇 공학, 로봇을 훈련할 수 있습니다. 그래서 이것이 NVIDIA Cosmos입니다.

882
00:59:33,910 --> 00:59:38,830
이 플랫폼은 실시간 애플리케이션을 위한 자동 회귀 모델, 매우 높은 품질의 이미지 생성을 위한 확산 모델,

883
00:59:38,831 --> 00:59:43,610
실제 세계 어휘를 배우는 기본 토크나이저, 데이터 파이프라인을 보유하고 있습니다.

884
00:59:43,730 --> 00:59:49,830
만약 여러분이 이 모든 것을 가져와서 여러분의 데이터로 훈련하고 싶다면, 이 데이터

885
00:59:49,831 --> 00:59:53,830
파이프라인은 많은 데이터가 관련되어 있기 때문에,

886
00:59:53,831 --> 00:59:56,045
많은 데이터가 관련되어 있기 때문에,

887
00:59:56,046 --> 00:59:58,310
저희는 모든 것을 엔드 투 엔드로 가속화했습니다.

888
00:59:58,311 --> 01:00:01,859
그래서 이것은 세계 최초의 데이터 처리 파이프라인입니다.

889
01:00:01,860 --> 01:00:04,410
CUDA 가속과 AI 가속 모두를 지원하는 파이프라인입니다.

890
01:00:04,710 --> 01:00:07,330
이 모든 것이 코스모스 플랫폼의 일부입니다.

891
01:00:07,590 --> 01:00:11,330
그리고 오늘 코스모스가 오픈 라이선스라는 것을 발표합니다.

892
01:00:11,630 --> 01:00:13,330
GitHub에서 오픈 소스로 제공됩니다.

893
01:00:20,720 --> 01:00:28,320
저희는 이 순간이 매우 빠른 모델, 주류 모델, 그리고 기본적으로

894
01:00:28,560 --> 01:00:31,760
교사 모델을 위한 작은 모델, 중간 모델, 큰 모델을 만들기를 바랍니다.

895
01:00:31,980 --> 01:00:33,500
지식 전송 모델이 아닙니다.

896
01:00:33,780 --> 01:00:40,800
Cosmos World Foundation 모델을 오픈함으로써, 저희는 LAMA3가 엔터프라이즈 AI에 했던 것과

897
01:00:40,801 --> 01:00:45,060
마찬가지로 로봇 공학 및 산업 AI 분야에도 그렇게 하기를 바랍니다.

898
01:00:45,660 --> 01:00:51,020
코스모스를 옴니버스와 연결하면 마법이 일어납니다.

899
01:00:51,240 --> 01:00:52,920
그리고 그 이유는 근본적으로 이것입니다.

900
01:00:53,880 --> 01:00:57,920
옴니버스는 물리학에 기반을 둡니다.

901
01:00:58,040 --> 01:01:01,100
물리적으로 기반을 두는 것이 아니라, 물리학에 기반을 둡니다.

902
01:01:01,101 --> 01:01:06,020
알고리즘적 물리학, 원칙적인 물리학 시뮬레이션 기반 시스템입니다.

903
01:01:06,360 --> 01:01:07,360
시뮬레이터입니다.

904
01:01:07,760 --> 01:01:14,060
그것을 코스모스에 연결하면, 코스모스 생성을 제어하고 조건화할 수 있는

905
01:01:14,061 --> 01:01:18,500
기반, 즉 근거가 제공됩니다.

906
01:01:19,100 --> 01:01:22,120
결과적으로 코스모스에서 나오는 것은 진실에 기반을 둡니다.

907
01:01:22,380 --> 01:01:27,160
이것은 대규모 언어 모델을 RAG(검색 증강 생성) 시스템에 연결하는 것과 정확히 동일한 아이디어입니다.

908
01:01:27,161 --> 01:01:30,220
RAG, 즉 검색 증강 생성 시스템에 연결하는 것과 같습니다.

909
01:01:30,221 --> 01:01:34,140
AI 생성이 사실에 기반을 두기를 원합니다.

910
01:01:34,340 --> 01:01:38,766
따라서 이 둘의 조합은 여러분에게 물리적으로 시뮬레이션된,

911
01:01:38,767 --> 01:01:44,020
물리적으로 기반을 둔 다중 세계 생성기를 제공합니다.

912
01:01:44,760 --> 01:01:48,040
그리고 응용 프로그램, 사용 사례는 정말 흥미롭습니다.

913
01:01:48,360 --> 01:01:54,220
그리고 물론 로봇 공학, 산업 응용 분야에 있어서는 매우 분명합니다.

914
01:01:54,560 --> 01:01:59,680
이 코스모스, 플러스 옴니버스, 플러스 코스모스는

915
01:01:59,681 --> 01:02:04,100
로봇 시스템을 구축하는 데 필요한 세 번째 컴퓨터를 나타냅니다.

916
01:02:04,980 --> 01:02:08,780
모든 로봇 회사는 궁극적으로 세 대의 컴퓨터를 구축해야 할 것입니다.

917
01:02:09,020 --> 01:02:12,860
로봇 시스템은 공장일 수도 있고, 로봇 시스템은 자동차일 수도 있습니다.

918
01:02:13,000 --> 01:02:13,680
로봇일 수도 있습니다.

919
01:02:13,900 --> 01:02:16,140
세 가지 기본적인 컴퓨터가 필요합니다.

920
01:02:16,380 --> 01:02:18,520
물론 첫 번째 컴퓨터는 AI를 훈련하는 것입니다.

921
01:02:18,900 --> 01:02:21,960
저희는 그것을 AI를 훈련하는 DGX 컴퓨터라고 부릅니다.

922
01:02:22,260 --> 01:02:26,020
또 다른 컴퓨터는 물론 완료되면 AI를 배포하는 것입니다.

923
01:02:26,160 --> 01:02:27,720
저희는 그것을 AGX라고 부릅니다.

924
01:02:27,721 --> 01:02:33,300
자동차, 로봇, AMR, 스타디움 등 어디에나 있습니다.

925
01:02:33,440 --> 01:02:34,300
어디든지 말이죠.

926
01:02:34,420 --> 01:02:37,960
이 컴퓨터는 에지에 있으며 자율적입니다.

927
01:02:38,500 --> 01:02:41,280
하지만 이 둘을 연결하려면 디지털 트윈이 필요합니다.

928
01:02:41,580 --> 01:02:43,720
그리고 이것이 여러분이 보았던 모든 시뮬레이션입니다.

929
01:02:43,940 --> 01:02:49,460
디지털 트윈은 훈련된 AI가 연습하러 가는 곳입니다.

930
01:02:49,760 --> 01:02:50,900
미세 조정하기 위해서요.

931
01:02:51,220 --> 01:02:53,140
합성 데이터 생성을 하기 위해서요.

932
01:02:53,820 --> 01:02:55,420
강화 학습 AI 피드백 말입니다.

933
01:02:55,680 --> 01:02:56,380
등등.

934
01:02:56,381 --> 01:02:58,800
그래서 그것은 AI의 디지털 트윈입니다.

935
01:02:59,140 --> 01:03:01,900
이 세 대의 컴퓨터는 상호 작용 방식으로 작동할 것입니다.

936
01:03:02,160 --> 01:03:06,740
산업 세계에 대한 엔비디아의 전략은, 저희가 얼마 동안 이야기해 왔던 것은

937
01:03:06,741 --> 01:03:09,320
이 세 대의 컴퓨터 시스템입니다.

938
01:03:10,320 --> 01:03:14,400
세 개의 물체 문제 대신에 세 개의 컴퓨터 솔루션이 있습니다.

939
01:03:15,040 --> 01:03:17,460
그것이 로봇 공학의 NVIDIA입니다.

940
01:03:23,860 --> 01:03:25,700
세 가지 예를 보여드리겠습니다.

941
01:03:26,240 --> 01:03:28,660
자, 첫 번째 예는...

942
01:03:29,860 --> 01:03:34,700
산업 디지털화에 이 모든 것을 적용하는 방법입니다.

943
01:03:35,100 --> 01:03:39,380
수백만 개의 공장과 수십만 개의 창고가 있습니다.

944
01:03:39,460 --> 01:03:44,840
그것은 기본적으로 50조 달러 규모의 제조 산업의 근간입니다.

945
01:03:45,240 --> 01:03:47,380
그 모든 것이 소프트웨어 정의가 되어야 합니다.

946
01:03:47,720 --> 01:03:51,120
그 모든 것이 미래에 자동화를 가져야 합니다.

947
01:03:51,300 --> 01:03:53,400
그리고 그 모든 것이 로봇 공학으로 주입될 것입니다.

948
01:03:53,880 --> 01:03:58,820
글쎄요, 저희는 세계 최고의 창고 자동화 솔루션 제공업체인 Kion과,

949
01:03:58,821 --> 01:04:03,157
그리고 세계 최대의 전문 서비스 제공업체인 Accenture와 파트너십을 맺고 있습니다.

950
01:04:03,158 --> 01:04:05,760
세계 최대의 전문 서비스 제공업체인 Accenture와 파트너십을 맺고 있습니다.

951
01:04:06,040 --> 01:04:09,280
그리고 그들은 디지털 제조에 큰 중점을 두고 있습니다.

952
01:04:09,660 --> 01:04:13,600
그리고 우리는 특별한 무언가를 만들기 위해 함께 노력하고 있습니다.

953
01:04:13,720 --> 01:04:14,916
잠시 후에 보여드리겠습니다.

954
01:04:14,940 --> 01:04:19,380
하지만 저희의 시장 진출 전략은 기본적으로 다른 모든 소프트웨어

955
01:04:19,381 --> 01:04:22,200
플랫폼 및 모든 기술 플랫폼과 동일합니다.

956
01:04:22,320 --> 01:04:31,000
개발자와 에코시스템 파트너를 통해 옴니버스에 연결하는 에코시스템 파트너 수가 계속 증가하고 있습니다.

957
01:04:31,001 --> 01:04:33,380
옴니버스에 연결하는 에코시스템 파트너 수가 계속 증가하고 있습니다.

958
01:04:33,620 --> 01:04:35,180
그리고 그 이유는 매우 분명합니다.

959
01:04:35,380 --> 01:04:38,140
모두가 미래 산업을 디지털화하기를 원합니다.

960
01:04:38,480 --> 01:04:41,843
세계 GDP 50조 달러에서 너무 많은 낭비가 있고,

961
01:04:41,844 --> 01:04:44,920
자동화의 기회가 너무 많습니다.

962
01:04:45,360 --> 01:04:50,360
자, Kion과 Accenture와 함께 진행하고 있는 한 가지 예를 살펴보겠습니다.

963
01:04:53,280 --> 01:04:53,880
Kion.

964
01:04:53,881 --> 01:04:56,220
공급망 솔루션 회사.

965
01:04:56,680 --> 01:04:57,560
Accenture.

966
01:04:57,680 --> 01:04:59,960
전문 서비스 분야의 글로벌 리더.

967
01:05:00,280 --> 01:05:01,280
그리고 엔비디아가

968
01:05:01,420 --> 01:05:08,201
1조 달러 규모의 창고 및 유통 센터 시장에 물리적 AI를 도입하고 있습니다.

969
01:05:08,400 --> 01:05:13,280
고성능 창고 물류 관리는 끊임없이 변화하는 변수에 영향을 받는 복잡한 의사 결정 웹을 탐색하는 것을 포함합니다.

970
01:05:13,281 --> 01:05:17,060
복잡한 의사 결정 웹을 탐색하는 것을 포함합니다.

971
01:05:17,440 --> 01:05:22,980
여기에는 일일 및 계절별 수요 변화, 공간 제약, 인력 가용성,

972
01:05:22,981 --> 01:05:28,100
다양한 로봇 및 자동화 시스템 통합 등이 포함됩니다.

973
01:05:28,360 --> 01:05:34,740
그리고 물리적 창고의 운영 KPI를 예측하는 것은 오늘날 거의 불가능합니다.

974
01:05:35,160 --> 01:05:40,560
이러한 문제를 해결하기 위해 Kion은 로봇 공학 함대를 테스트하고 최적화하기 위한 산업 디지털 트윈을 구축하기 위해 NVIDIA Omniverse 청사진인 Mega를 채택하고 있습니다.

975
01:05:40,561 --> 01:05:46,080
산업 디지털 트윈을 구축하기 위해 NVIDIA Omniverse 청사진인 Mega를 채택하고 있습니다.

976
01:05:46,380 --> 01:05:51,920
첫째, Kion의 창고 관리 솔루션은 로봇에 작업을 할당합니다.

977
01:05:51,921 --> 01:05:55,375
예를 들어, 완충 위치에서 셔틀 저장 솔루션으로

978
01:05:55,376 --> 01:05:58,380
로드를 이동하는 것과 같은 디지털 트윈의 산업 AI 브레인에 말입니다.

979
01:05:59,120 --> 01:06:04,620
로봇의 두뇌는 CAD, 비디오 및 이미지를 3D로, LIDAR를 포인트 클라우드로, AI 생성 데이터를 수집하기 위해 OpenUSD 커넥터를 사용하여 Omniverse로 디지털화된 실제 창고의 시뮬레이션에 있습니다.

980
01:06:04,621 --> 01:06:11,180
Omniverse로 디지털화된 실제 창고의 시뮬레이션에 있습니다.

981
01:06:11,420 --> 01:06:15,360
LIDAR를 포인트 클라우드로, AI 생성 데이터를 수집하기 위해 OpenUSD 커넥터를 사용하여 Omniverse로 디지털화된 실제 창고의 시뮬레이션에 있습니다.

982
01:06:15,580 --> 01:06:21,260
로봇 함대는 Omniverse 디지털 트윈 환경을 인식하고 추론하고 다음 동작을 계획하고 행동함으로써 작업을 수행합니다.

983
01:06:21,261 --> 01:06:25,660
Omniverse 디지털 트윈 환경을 인식하고 추론하고 다음 동작을 계획하고 행동함으로써 작업을 수행합니다.

984
01:06:26,280 --> 01:06:29,729
로봇 두뇌는 센서 시뮬레이션을 통해 결과 상태를 보고

985
01:06:29,730 --> 01:06:32,360
다음 행동을 결정할 수 있습니다.

986
01:06:32,600 --> 01:06:36,138
Mega는 디지털 트윈의 모든 것의 상태를 정확하게 추적하는 동안

987
01:06:36,139 --> 01:06:38,840
루프는 계속됩니다.

988
01:06:39,220 --> 01:06:46,120
이제 Kion은 물리적 창고에 변경 사항을 배포하기 전에 처리량, 효율성 및 활용률과 같은 운영 KPI를 측정하면서

989
01:06:46,300 --> 01:06:50,396
무한한 시나리오를 대규모로 시뮬레이션할 수 있습니다.

990
01:06:50,397 --> 01:06:53,120
무한한 시나리오를 대규모로 시뮬레이션할 수 있습니다.

991
01:06:54,160 --> 01:06:59,780
NVIDIA와 함께 Kion과 Accenture는 산업 자율성을 재창조하고 있습니다.

992
01:07:02,760 --> 01:07:03,780
정말 놀랍습니다.

993
01:07:03,960 --> 01:07:05,080
모든 것이 시뮬레이션에 있습니다.

994
01:07:05,940 --> 01:07:12,280
미래에는, 미래에는 모든 공장이 디지털 트윈을 갖게 될 것입니다.

995
01:07:12,460 --> 01:07:15,980
그리고 그 디지털 트윈은 실제 공장과 정확히 똑같이 작동합니다.

996
01:07:16,180 --> 01:07:19,748
그리고 사실, 여러분은 Omniverse를 Cosmos와 함께 사용하여

997
01:07:19,749 --> 01:07:22,720
많은 미래 시나리오를 생성할 수 있습니다.

998
01:07:22,960 --> 01:07:25,670
그리고 그런 다음 AI가 어떤 시나리오가

999
01:07:25,671 --> 01:07:28,760
어떤 KPI에 가장 최적인지 결정합니다.

1000
01:07:28,920 --> 01:07:32,740
그리고 그것이 실제 공장에 배치될 AI의 프로그램, 구속 조건이 됩니다.

1001
01:07:32,860 --> 01:07:35,920
그것이 실제 공장에 배치될 AI의 프로그램, 구속 조건이 됩니다.

1002
01:07:36,120 --> 01:07:37,960
다음 예는 자율주행차입니다.

1003
01:07:38,260 --> 01:07:40,560
AV 혁명이 도래했습니다.

1004
01:07:41,220 --> 01:07:46,760
여러 해가 지난 후 Waymo의 성공과 Tesla의 성공으로, 자율 주행차가

1005
01:07:46,820 --> 01:07:49,760
드디어 도착했다는 것이 매우 분명합니다.

1006
01:07:50,120 --> 01:07:53,900
이 산업에 대한 저희의 제안은 세 대의 컴퓨터입니다.

1007
01:07:54,080 --> 01:07:59,360
AI를 훈련하는 교육 시스템, 시뮬레이션 시스템, 합성 데이터 생성 시스템인 옴니버스와 이제 코스모스,

1008
01:07:59,361 --> 01:08:02,450
시뮬레이션 시스템, 합성 데이터 생성 시스템인 옴니버스와 이제 코스모스,

1009
01:08:02,451 --> 01:08:05,221
그리고 자동차 내부에 있는 컴퓨터입니다.

1010
01:08:05,720 --> 01:08:08,694
각 자동차 회사는 서로 다른 방식으로 저희와 협력할 수 있습니다.

1011
01:08:08,695 --> 01:08:10,700
하나, 둘 또는 세 대의 컴퓨터를 사용할 수 있습니다.

1012
01:08:10,900 --> 01:08:14,640
저희는 전 세계 거의 모든 주요 자동차 회사와 협력하고 있습니다.

1013
01:08:14,800 --> 01:08:18,240
Waymo와 Zoom, Zooks와 Tesla, 그리고 당연히 그들의 데이터 센터.

1014
01:08:18,500 --> 01:08:21,400
세계 최대의 EV 회사인 BYD.

1015
01:08:21,500 --> 01:08:23,380
JLR은 정말 멋진 차를 출시할 예정입니다.

1016
01:08:23,560 --> 01:08:26,331
메르세데스는 올해부터 생산을 시작하는

1017
01:08:26,332 --> 01:08:28,580
NVIDIA와 함께 자동차를 출시할 예정입니다.

1018
01:08:28,840 --> 01:08:34,940
그리고 오늘, 도요타와 엔비디아가 차세대 AV를 만들기 위해

1019
01:08:34,941 --> 01:08:37,460
협력할 것이라고 발표하게 되어 매우 기쁩니다.

1020
01:08:44,770 --> 01:08:46,970
정말 많은 멋진 회사들이 있습니다.

1021
01:08:47,510 --> 01:08:53,330
Lucid와 Rivian, Xiaomi, 그리고 물론 Volvo까지 정말 많은 다양한 회사들이 있습니다.

1022
01:08:53,530 --> 01:08:56,010
Wabi는 자율 주행 트럭을 만들고 있습니다.

1023
01:08:56,290 --> 01:08:58,968
Aurora도 이번 주에 발표했는데, Aurora는

1024
01:08:58,969 --> 01:09:01,451
자율 주행 트럭을 만드는 데 NVIDIA를 사용할 것입니다.

1025
01:09:02,330 --> 01:09:08,550
자율 주행, 매년 1억 대의 자동차가 생산되고, 전 세계 도로에서 10억 대의 자동차가 운행되며, 매년 1조 마일이 운전됩니다.

1026
01:09:08,551 --> 01:09:12,230
자동차, 세계 도로에서 10억 대가 운행되며, 매년 1조 마일이 운전됩니다.

1027
01:09:13,270 --> 01:09:16,301
이 모든 것이 앞으로 고도로 자율적이거나

1028
01:09:16,302 --> 01:09:18,930
완전히 자율적이 될 것입니다.

1029
01:09:19,070 --> 01:09:21,530
그래서 이것은 매우 크고, 매우 큰 산업이 될 것입니다.

1030
01:09:21,710 --> 01:09:27,190
저는 이것이 아마도 최초의 수조 달러 규모의 로봇 산업이 될 것이라고 예측합니다.

1031
01:09:27,450 --> 01:09:34,850
저희 사업은 이미 시장에 진출하기 시작한 이러한 자동차 중 일부에서만으로도 40억 달러 규모이며, 올해는

1032
01:09:34,851 --> 01:09:38,950
매출이 40억 달러에 달하고, 올해는 아마도 약 50억 달러의 매출을 기록할 것입니다.

1033
01:09:39,070 --> 01:09:41,130
매출은 50억 달러에 달할 것입니다.

1034
01:09:41,290 --> 01:09:43,030
이미 매우 중요한 사업입니다.

1035
01:09:43,170 --> 01:09:44,266
매우 큰 규모가 될 것입니다.

1036
01:09:44,290 --> 01:09:48,850
자, 오늘 저희는 차세대 자동차용 프로세서,

1037
01:09:48,851 --> 01:09:51,990
차세대 자동차용 컴퓨터를 발표할 예정입니다. 이름은 Thor입니다.

1038
01:09:52,250 --> 01:09:53,330
여기 하나 있습니다.

1039
01:09:53,410 --> 01:09:54,410
잠시만요.

1040
01:09:56,920 --> 01:09:58,100
자, 이것이 Thor입니다.

1041
01:09:59,360 --> 01:10:00,360
이것이 Thor입니다.

1042
01:10:01,880 --> 01:10:05,420
이것은, 이것은 로봇 공학 컴퓨터입니다.

1043
01:10:06,600 --> 01:10:08,200
이것은 로봇 공학 컴퓨터입니다.

1044
01:10:08,340 --> 01:10:14,480
수많은 센서 정보를 가져와서 처리합니다.

1045
01:10:16,640 --> 01:10:22,920
수많은 카메라, 고해상도, 레이더, 라이다가 모두 이 칩으로 들어옵니다.

1046
01:10:23,040 --> 01:10:27,060
그리고 이 칩은 모든 센서를 처리하고 토큰으로 바꾸고,

1047
01:10:27,300 --> 01:10:31,120
트랜스포머에 넣어 다음 경로를 예측해야 합니다.

1048
01:10:31,620 --> 01:10:35,540
그리고 이 AV 컴퓨터는 이제 본격적으로 생산되고 있습니다.

1049
01:10:35,840 --> 01:10:42,140
Thor는 이전 세대인 Orin보다 20배나 높은 처리 능력을 가지고 있으며, 그것은 현재 자율 주행차의 표준입니다.

1050
01:10:42,141 --> 01:10:44,520
현재 자율 주행차의 표준입니다.

1051
01:10:44,780 --> 01:10:47,540
정말 놀라운 성능입니다.

1052
01:10:47,740 --> 01:10:48,980
Thor는 본격적으로 생산 중입니다.

1053
01:10:48,981 --> 01:10:52,520
이 로봇 프로세서는 또한 전체 로봇에도 들어갑니다.

1054
01:10:52,720 --> 01:10:57,500
AMR일 수도 있고, 인간 또는 로봇일 수도 있고, 브레인일 수도 있고,

1055
01:10:57,640 --> 01:10:59,140
매니퓰레이터일 수도 있습니다.

1056
01:10:59,420 --> 01:11:03,940
이 프로세서는 기본적으로 범용 로봇 공학 컴퓨터입니다.

1057
01:11:05,380 --> 01:11:08,324
제가 매우 자랑스러워하는 Drive 시스템의 두 번째 부분은

1058
01:11:08,325 --> 01:11:12,001
안전에 대한 헌신입니다.

1059
01:11:12,640 --> 01:11:18,420
Drive OS는 이제 ASIL-D까지 인증된 최초의 소프트웨어 정의 프로그래밍 가능 AI 컴퓨터라고 발표하게 되어 기쁩니다.

1060
01:11:19,120 --> 01:11:25,620
Drive OS는 이제 ASIL-D까지 인증된 최초의 소프트웨어 정의 프로그래밍 가능 AI 컴퓨터라고 발표하게 되어 기쁩니다.

1061
01:11:25,621 --> 01:11:30,160
이것은 자동차 기능 안전에 대한 최고 기준입니다.

1062
01:11:30,400 --> 01:11:32,120
유일하고 가장 높은 기준입니다.

1063
01:11:32,380 --> 01:11:34,200
그래서 저는 정말, 정말 자랑스럽습니다.

1064
01:11:34,360 --> 01:11:36,840
ASIL-D, ISO 26262입니다.

1065
01:11:37,220 --> 01:11:41,560
약 15,000 엔지니어링 년의 노력입니다.

1066
01:11:42,180 --> 01:11:44,160
정말 놀라운 작업입니다.

1067
01:11:44,320 --> 01:11:49,000
결과적으로 CUDA는 이제 기능적으로 안전한 컴퓨터입니다.

1068
01:11:50,120 --> 01:11:53,200
따라서 로봇을 만들고 있다면, NVIDIA CUDA가 있습니다.

1069
01:11:58,150 --> 01:12:02,810
자, 이제 여러분에게 제가 옴니버스와 코스모스를 사용하여 자율 주행차의 맥락에서 무엇을 할 것인지 보여드리겠다고 했습니다.

1070
01:12:02,811 --> 01:12:08,650
사용하여 자율 주행차의 맥락에서 무엇을 할 것인지 보여드리겠다고 했습니다.

1071
01:12:09,330 --> 01:12:14,470
그리고 오늘날, 여러분에게 도로에서 주행하는 자동차의 많은 비디오를 보여주는 대신에, 그것도 좀 보여드리겠지만,

1072
01:12:14,471 --> 01:12:16,910
그것도 좀 보여드리겠지만,

1073
01:12:17,530 --> 01:12:23,670
AI를 사용하여 자동차가 디지털 트윈을 자동으로 재구성하고 그 기능을 사용하여 미래 AI 모델을 훈련하는 방법을 보여드리고 싶습니다.

1074
01:12:23,671 --> 01:12:29,670
재구성하고 그 기능을 사용하여 미래 AI 모델을 훈련하는 방법을 보여드리고 싶습니다.

1075
01:12:29,910 --> 01:12:30,910
자, 보시죠.

1076
01:12:34,480 --> 01:12:37,480
자율 주행차 혁명이 여기에 있습니다.

1077
01:12:38,060 --> 01:12:43,700
모든 로봇과 마찬가지로 자율 주행차를 구축하려면 세 대의 컴퓨터가 필요합니다.

1078
01:12:44,080 --> 01:12:47,000
AI 모델을 훈련하는 NVIDIA DGX.

1079
01:12:47,320 --> 01:12:50,620
테스트 주행과 합성 데이터를 생성하는 Omniverse.

1080
01:12:50,760 --> 01:12:54,700
그리고 자동차의 슈퍼컴퓨터인 Drive AGX.

1081
01:12:55,380 --> 01:12:59,620
안전한 자율 주행차를 구축하려면 엣지 시나리오를 해결해야 합니다.

1082
01:13:00,370 --> 01:13:06,641
하지만 실제 데이터는 제한적이므로 훈련을 위해서는 합성 데이터가 필수적입니다.

1083
01:13:07,390 --> 01:13:12,780
NVIDIA Omniverse, AI 모델,

1084
01:13:12,980 --> 01:13:16,981
및 Cosmos로 구동되는 자율 주행차 데이터 공장은

1085
01:13:16,982 --> 01:13:19,980
훈련 데이터를 수량 수준으로 향상시키는 합성 주행 시나리오를 생성합니다.

1086
01:13:19,981 --> 01:13:29,281
첫째, 옴니맵은 지도 및 지리 공간 데이터를 융합하여 주행 가능한 3D 환경을 구축합니다.

1087
01:13:31,830 --> 01:13:35,587
주행 시나리오 변형은 재현된 주행 로그 또는 AI 트래픽 생성기에서

1088
01:13:35,588 --> 01:13:38,711
생성할 수 있습니다.

1089
01:13:39,790 --> 01:13:44,830
다음으로, 신경 재구성 엔진은 자율 주행차 센서 로그를 사용하여

1090
01:13:44,831 --> 01:13:49,790
고화질 4D 시뮬레이션 환경을 생성합니다.

1091
01:13:49,791 --> 01:13:53,990
이전 주행을 3D로 재생하고 훈련 데이터를 증폭하기 위해

1092
01:13:53,991 --> 01:13:57,591
시나리오 변형을 생성합니다.

1093
01:13:58,450 --> 01:14:05,810
마지막으로, Edify 3DS는 기존 자산 라이브러리를 자동으로 검색하거나 새로운 자산을 생성하여 시뮬레이션 준비 장면을 만듭니다.

1094
01:14:05,811 --> 01:14:09,370
새로운 자산을 생성하여 시뮬레이션 준비 장면을 만듭니다.

1095
01:14:12,490 --> 01:14:17,870
옴니버스 시나리오는 코스모스를 조건화하여 시뮬레이션-현실 간 격차를 줄이고

1096
01:14:17,871 --> 01:14:24,110
대규모의 사진처럼 사실적인 데이터를 생성하는 데 사용되며, 텍스트 프롬프트를 사용하여

1097
01:14:24,111 --> 01:14:29,390
거의 무한한 주행 시나리오 변형을 생성합니다.

1098
01:14:30,830 --> 01:14:36,610
Cosmos Nemotron Video Search를 통해 대규모 합성 데이터 세트는 기록된 드라이브와 결합하여 모델을 훈련하기 위해 큐레이팅할 수 있습니다.

1099
01:14:36,890 --> 01:14:41,430
기록된 드라이브와 결합하여 모델을 훈련하기 위해 큐레이팅할 수 있습니다.

1100
01:14:44,190 --> 01:14:49,770
NVIDIA의 AI 데이터 공장은 수백 개의 드라이브를 수십억 개의 효과로 확장합니다.

1101
01:14:49,790 --> 01:14:51,886
그런 다음 데이터는 가장 효과적인 마일을 추적하는 데 사용되어

1102
01:14:51,887 --> 01:14:55,090
안전하고 발전된 자율 주행의 표준을 설정합니다.

1103
01:14:59,200 --> 01:15:00,200
정말 놀랍지 않나요?

1104
01:15:00,840 --> 01:15:01,840
저희는...

1105
01:15:04,300 --> 01:15:05,300
수천 개의...

1106
01:15:05,600 --> 01:15:10,380
수천 개의 드라이브를 가져와서 수십억 마일로 바꿉니다.

1107
01:15:10,660 --> 01:15:15,480
저희는 자율 주행차를 위한 엄청난 양의 학습 데이터를 가지게 될 것입니다.

1108
01:15:15,720 --> 01:15:18,440
물론, 여전히 실제 도로 위의 자동차가 필요합니다.

1109
01:15:18,580 --> 01:15:24,520
물론, 실제 데이터를 계속 수집할 것이지만, 이러한 다중 세계를 사용하여 합성 데이터 생성을

1110
01:15:24,521 --> 01:15:30,240
사용하여 물리적으로 기반을 두고 정확하거나, 그럴듯한 AI 훈련 데이터를 생성하여,

1111
01:15:30,480 --> 01:15:36,140
수많은 데이터를 가지고 훈련할 수 있게 할 것입니다.

1112
01:15:36,280 --> 01:15:40,200
수많은 데이터를 가지고 훈련할 수 있게 할 것입니다.

1113
01:15:40,400 --> 01:15:41,920
AV 산업이 여기에 있습니다.

1114
01:15:42,220 --> 01:15:44,640
정말 놀라운 시간입니다.

1115
01:15:44,800 --> 01:15:48,360
앞으로 몇 년이 정말, 정말 기대됩니다.

1116
01:15:48,480 --> 01:15:52,170
저는 컴퓨터 그래픽이 믿을 수 없는 속도로 혁명을 이루었던 것처럼,

1117
01:15:52,171 --> 01:15:55,815
AV 개발 속도가 앞으로 몇 년 동안 엄청나게 증가하는 것을 보게 될 것이라고 생각합니다.

1118
01:15:55,816 --> 01:15:58,830
AV 개발 속도가 앞으로 몇 년 동안 엄청나게 증가하는 것을 보게 될 것이라고 생각합니다.

1119
01:16:09,510 --> 01:16:11,711
저는... 저는...

1120
01:16:13,730 --> 01:16:17,431
다음 부분은... 로봇 공학이라고 생각합니다.

1121
01:16:18,730 --> 01:16:19,730
자...

1122
01:16:26,840 --> 01:16:27,840
휴머노이드 로봇입니다.

1123
01:16:31,740 --> 01:16:32,740
여러분.

1124
01:16:38,870 --> 01:16:43,750
일반 로봇 공학을 위한 chat GPT의 순간이 바로 눈앞에 있습니다.

1125
01:16:43,770 --> 01:16:47,650
사실, 제가 지금까지 이야기해 온 모든 가능 기술들이

1126
01:16:47,651 --> 01:16:54,450
우리가 앞으로 몇 년 안에 일반 로봇 공학에서 매우 빠르고 놀라운 돌파구를 볼 수 있도록 만들 것입니다.

1127
01:16:54,451 --> 01:16:57,650
놀라운 돌파구를 볼 수 있도록 만들 것입니다.

1128
01:16:57,950 --> 01:17:02,850
이제 일반 로봇 공학이 매우 중요한 이유는 트랙과 바퀴가 달린 로봇은 특별한 환경을 수용해야 하는 반면, 우리가 만들 수 있는 세 개의 로봇은,

1129
01:17:02,851 --> 01:17:08,870
특별한 환경을 수용해야 하는 반면, 우리가 만들 수 있는 세 개의 로봇은

1130
01:17:09,970 --> 01:17:13,750
로봇이 필요한 세 곳이 있습니다.

1131
01:17:13,751 --> 01:17:14,930
그린 필드는 없습니다.

1132
01:17:16,410 --> 01:17:18,330
브라운필드 적응이 완벽합니다.

1133
01:17:18,810 --> 01:17:24,150
만약 우리가 이러한 놀라운 로봇을 만들 수 있다면, 우리가 스스로 만든 세상에 정확히 배치할 수 있습니다.

1134
01:17:24,151 --> 01:17:25,831
스스로 만든 세상에 정확히 배치할 수 있습니다.

1135
01:17:26,190 --> 01:17:32,570
이 세 가지 로봇은 첫째, 에이전트 로봇과 에이전트 AI입니다.

1136
01:17:32,750 --> 01:17:36,350
그 이유는 정보 노동자이고, 우리의 사무실에 있는 컴퓨터를 수용할 수 있는 한,

1137
01:17:36,351 --> 01:17:38,831
정말 좋을 것이기 때문입니다.

1138
01:17:39,130 --> 01:17:41,570
두 번째는 자율 주행차입니다.

1139
01:17:41,810 --> 01:17:45,990
그 이유는 우리가 100년 넘게 도로와 도시를 건설하는 데 보냈기 때문입니다.

1140
01:17:46,330 --> 01:17:48,650
그리고 세 번째는 휴머노이드 로봇입니다.

1141
01:17:48,930 --> 01:17:52,866
만약 우리가 이 세 가지를 해결할 기술을 가지고 있다면, 이것은

1142
01:17:52,867 --> 01:17:56,210
세상이 본 적이 없는 가장 큰 기술 산업이 될 것입니다.

1143
01:17:56,890 --> 01:18:02,170
그래서 저희는 로봇 공학 시대가 바로 코앞에 있다고 생각합니다.

1144
01:18:02,370 --> 01:18:06,190
가장 중요한 능력은 이러한 로봇을 훈련하는 방법입니다.

1145
01:18:06,710 --> 01:18:13,290
휴머노이드 로봇의 경우, 모방 정보는 수집하기가 다소 어렵습니다.

1146
01:18:13,650 --> 01:18:17,170
그 이유는 자동차의 경우, 그냥 운전하면 됩니다.

1147
01:18:17,230 --> 01:18:18,486
우리는 항상 자동차를 운전하고 있습니다.

1148
01:18:18,510 --> 01:18:21,930
이러한 휴머노이드 로봇의 경우, 모방

1149
01:18:21,931 --> 01:18:25,470
정보, 인간 시연은 하기가 다소 어렵습니다.

1150
01:18:25,710 --> 01:18:30,790
따라서 수백 개의 시연, 수천 개의 인간 시연을 가져와서 인공 지능과

1151
01:18:31,170 --> 01:18:36,310
옴니버스를 사용하여 수백만 개의 합성 움직임을 생성하는 영리한 방법을 고안해야 합니다.

1152
01:18:36,311 --> 01:18:48,370
수백만 개의 합성 움직임을 생성하는 영리한 방법을 고안해야 합니다.

1153
01:18:48,710 --> 01:18:53,570
그리고 그러한 움직임에서 AI는 작업을 수행하는 방법을 배울 수 있습니다.

1154
01:18:53,790 --> 01:18:55,090
그 방법이 어떻게 이루어지는지 보여드리겠습니다.

1155
01:19:06,660 --> 01:19:09,363
전 세계 개발자들이 차세대 물리적 AI 기반 로봇, 즉

1156
01:19:09,364 --> 01:19:12,920
휴머노이드를 구축하고 있습니다.

1157
01:19:14,180 --> 01:19:18,820
범용 로봇 모델을 개발하려면 막대한 양의 실제 데이터가 필요하며, 이는 포착하고 큐레이팅하는 데 비용이 많이 듭니다.

1158
01:19:18,821 --> 01:19:21,880
비용이 많이 듭니다.

1159
01:19:22,760 --> 01:19:26,092
NVIDIA Isaac Groot는 휴머노이드 로봇 개발자에게 네 가지 사항을 제공함으로써 이러한 문제를 해결하는 데 도움을 줍니다.

1160
01:19:26,093 --> 01:19:29,200
네 가지 사항을 제공함으로써 이러한 문제를 해결하는 데 도움을 줍니다.

1161
01:19:29,440 --> 01:19:35,379
로봇 기반 모델, 데이터 파이프라인, 시뮬레이션 프레임워크,

1162
01:19:35,380 --> 01:19:39,961
그리고 Thor 로봇 공학 컴퓨터입니다.

1163
01:19:41,220 --> 01:19:46,260
합성 모션 생성을 위한 NVIDIA Isaac Groot 청사진은 모방 학습을 위한 시뮬레이션 워크플로이며,

1164
01:19:46,261 --> 01:19:51,060
개발자가 소수의 인간 시연에서 기하급수적으로 큰 데이터 세트를 생성할 수 있도록 합니다.

1165
01:19:51,061 --> 01:19:55,460
소수의 인간 시연에서 기하급수적으로 큰 데이터 세트를 생성할 수 있도록 합니다.

1166
01:19:56,320 --> 01:20:01,480
첫째, Groot Teleop을 통해 숙련된 인간 작업자는 Apple Vision Pro를 사용하여

1167
01:20:01,481 --> 01:20:05,200
로봇의 디지털 트윈으로 이동할 수 있습니다.

1168
01:20:06,360 --> 01:20:11,300
즉, 작업자는 실제 로봇 없이도 데이터를 포착할 수 있으며, 물리적 손상이나 마모의 가능성을 제거하여

1169
01:20:11,301 --> 01:20:14,697
위험 부담이 없는 환경에서 로봇을 작동시킬 수 있습니다.

1170
01:20:14,698 --> 01:20:17,080
위험 부담이 없는 환경에서 로봇을 작동시킬 수 있습니다.

1171
01:20:18,960 --> 01:20:23,440
로봇에게 단일 작업을 가르치기 위해 작업자는 소수의 원격 조작 시연을 통해 모션 궤적을 캡처합니다.

1172
01:20:23,980 --> 01:20:26,100
모션 궤적을 캡처합니다.

1173
01:20:26,740 --> 01:20:32,460
그런 다음 Groot Mimic을 사용하여 이러한 궤적을 훨씬 더 큰 데이터 세트로 늘립니다.

1174
01:20:34,220 --> 01:20:39,260
다음으로, Omniverse와 Cosmos를 기반으로 구축된 Groot Gen을 사용하여 영역 랜덤화 및 3D에서 실제 스케일 업을 위해 훨씬 크고 기하급수적으로 큰 데이터 세트를 생성합니다.

1175
01:20:39,261 --> 01:20:43,392
기하급수적으로 큰 데이터 세트를 생성합니다.

1176
01:20:43,393 --> 01:20:46,820
데이터 세트를 생성합니다.

1177
01:20:49,060 --> 01:20:53,147
Omniverse와 Cosmos 다중 세계 시뮬레이션 엔진은 로봇 정책을 훈련하기 위한

1178
01:20:53,148 --> 01:20:56,860
대규모 데이터 세트를 제공합니다.

1179
01:20:58,080 --> 01:21:03,760
정책이 훈련되면 개발자는 실제 로봇에 배포하기 전에 Isaac Sim에서 소프트웨어 루프 테스트와 유효성 검사를 수행할 수 있습니다.

1180
01:21:03,761 --> 01:21:07,600
Isaac Sim에서 소프트웨어 루프 테스트와 유효성 검사를 수행할 수 있습니다.

1181
01:21:09,280 --> 01:21:11,880
일반 로봇 공학 시대가 다가오고 있습니다.

1182
01:21:12,300 --> 01:21:14,240
NVIDIA Isaac Groot로 구동됩니다.

1183
01:21:18,840 --> 01:21:21,900
우리는 로봇을 훈련할 많은 데이터를 가지게 될 것입니다.

1184
01:21:24,880 --> 01:21:26,560
NVIDIA Isaac Groot.

1185
01:21:26,900 --> 01:21:28,220
NVIDIA Isaac Groot.

1186
01:21:28,320 --> 01:21:34,500
이것은 로봇 공학 산업이 일반 로봇 공학 개발을 가속화하기 위해 기술 요소를 제공하는 플랫폼입니다.

1187
01:21:34,501 --> 01:21:36,420
일반 로봇 공학 개발을 가속화하는 플랫폼입니다.

1188
01:21:37,080 --> 01:21:41,020
자, 여러분에게 보여드리고 싶은 것이 하나 더 있습니다.

1189
01:21:41,400 --> 01:21:45,290
이 모든 것은 약 10년 전에 시작한 이 놀라운 프로젝트가 없었다면 불가능했을 것입니다.

1190
01:21:45,291 --> 01:21:49,940
이 놀라운 프로젝트가 없었다면 불가능했을 것입니다.

1191
01:21:50,220 --> 01:21:53,740
회사 내부에서는 Project Digits라고 불렸습니다.

1192
01:21:54,140 --> 01:21:59,060
딥 러닝 GPU 인텔리전스 트레이닝 시스템입니다.

1193
01:22:00,060 --> 01:22:01,060
Digits.

1194
01:22:01,920 --> 01:22:06,680
자, 출시하기 전에 저는 그것을 DGX로 줄였습니다.

1195
01:22:07,420 --> 01:22:11,980
그리고 RTX, AGX, OVX, 그리고 회사에 있는

1196
01:22:11,981 --> 01:22:15,501
다른 모든 X와 조화를 이루기 위해서였습니다.

1197
01:22:15,680 --> 01:22:20,520
그리고... 그리고 그것은 정말 혁명을 일으켰습니다...

1198
01:22:21,200 --> 01:22:24,380
DGX1은 정말로 혁명을 일으켰습니다... DGX1은 어디 있을까요?

1199
01:22:26,360 --> 01:22:28,660
DGX1은 인공 지능에 혁명을 일으켰습니다.

1200
01:22:28,960 --> 01:22:34,580
저희가 그것을 만든 이유는 연구자들과 스타트업이 바로 사용할 수 있는 AI 슈퍼컴퓨터를

1201
01:22:34,581 --> 01:22:37,600
가질 수 있도록 만들기 위해서였습니다.

1202
01:22:38,200 --> 01:22:40,360
과거에 슈퍼컴퓨터가 구축되었던 방식을 상상해 보세요.

1203
01:22:40,620 --> 01:22:43,301
여러분은 실제로 자신의 시설을 만들고

1204
01:22:43,302 --> 01:22:45,020
자신의 인프라를 구축해야 합니다.

1205
01:22:45,021 --> 01:22:47,580
그리고 실제로 존재하도록 설계해야 합니다.

1206
01:22:47,900 --> 01:22:51,584
그래서 우리는 연구자와 스타트업이 상자에서 꺼내서 사용할 수 있는

1207
01:22:51,585 --> 01:22:55,360
AI 개발을 위한 슈퍼컴퓨터를 만들었습니다.

1208
01:22:55,520 --> 01:23:00,020
저는 2016년에 첫 번째 제품을 OpenAI라는 스타트업 회사에 전달했습니다.

1209
01:23:00,360 --> 01:23:01,600
그리고 엘론이 거기에 있었습니다.

1210
01:23:01,700 --> 01:23:03,280
그리고 일리야 수츠케버도 거기에 있었습니다.

1211
01:23:03,380 --> 01:23:05,440
그리고 많은 NVIDIA 엔지니어가 거기에 있었습니다.

1212
01:23:05,600 --> 01:23:09,240
그리고 우리는 DGX1의 도착을 축하했습니다.

1213
01:23:09,360 --> 01:23:15,000
그리고 분명히 그것은 인공 지능과 컴퓨팅에 혁명을 일으켰습니다.

1214
01:23:15,780 --> 01:23:18,200
하지만 이제 인공 지능은 모든 곳에 있습니다.

1215
01:23:18,400 --> 01:23:21,140
단순히 연구원이나 스타트업 연구실에만 있는 것이 아닙니다.

1216
01:23:21,740 --> 01:23:24,860
저희는 인공 지능을 원합니다. 제가 강연 초반에 말씀드렸듯이요.

1217
01:23:25,120 --> 01:23:27,520
이것이 이제 컴퓨팅을 하는 새로운 방식입니다.

1218
01:23:27,660 --> 01:23:29,180
이것이 소프트웨어를 만드는 새로운 방식입니다.

1219
01:23:29,220 --> 01:23:34,660
모든 소프트웨어 엔지니어, 모든 엔지니어, 모든 창의적인 예술가, 오늘날 컴퓨터를 도구로 사용하는 모든 사람은 AI 슈퍼컴퓨터가 필요합니다.

1220
01:23:34,661 --> 01:23:39,420
AI 슈퍼컴퓨터가 필요할 것입니다.

1221
01:23:40,200 --> 01:23:45,120
그래서 저는 DGX1이 더 작았으면 좋겠다고 생각했습니다.

1222
01:23:45,620 --> 01:23:56,690
그래서 여러분, 상상해 보세요.

1223
01:24:05,530 --> 01:24:09,210
이것이 엔비디아의 최신 AI 슈퍼컴퓨터입니다.

1224
01:24:13,730 --> 01:24:18,450
그리고 그것은 마침내 지금 프로젝트 Digits라고 불립니다.

1225
01:24:18,830 --> 01:24:21,510
이름이 좋으면 저희에게 연락해 주세요.

1226
01:24:24,170 --> 01:24:25,590
자, 여기 놀라운 것이 있습니다.

1227
01:24:25,610 --> 01:24:26,730
이것은 AI 슈퍼컴퓨터입니다.

1228
01:24:27,030 --> 01:24:29,970
전체 NVIDIA AI 스택을 실행합니다.

1229
01:24:31,410 --> 01:24:33,450
모든 NVIDIA 소프트웨어가 여기에서 실행됩니다.

1230
01:24:34,070 --> 01:24:35,850
DGX Cloud가 여기에서 실행됩니다.

1231
01:24:37,110 --> 01:24:40,494
이것은, 음, 어딘가에 앉아있고 여러분의 컴퓨터에 무선으로 연결되어 있습니다.

1232
01:24:40,495 --> 01:24:42,930
또는 연결되어 있습니다.

1233
01:24:43,110 --> 01:24:44,970
원한다면 워크스테이션으로도 사용할 수 있습니다.

1234
01:24:45,170 --> 01:24:47,230
그리고 여러분은 그것에 접근할 수 있습니다.

1235
01:24:47,330 --> 01:24:51,170
클라우드 슈퍼컴퓨터처럼 접근할 수 있습니다.

1236
01:24:51,570 --> 01:24:53,650
NVIDIA의 AI가 그 위에서 작동합니다.

1237
01:24:53,651 --> 01:25:00,050
그리고 그것은 저희가 GB110이라고 부르는 매우 비밀스러운 칩을 기반으로 만들어졌습니다.

1238
01:25:00,430 --> 01:25:03,470
저희가 만드는 가장 작은 Grace Blackwell입니다.

1239
01:25:04,030 --> 01:25:05,930
그리고 저는... 글쎄요, 아시겠죠?

1240
01:25:05,970 --> 01:25:07,210
모두에게 내부를 보여주세요.

1241
01:25:34,480 --> 01:25:37,640
이게 그냥, 그냥 귀엽지 않나요?

1242
01:25:37,860 --> 01:25:39,380
이것이 내부에 있는 칩입니다.

1243
01:25:41,220 --> 01:25:42,860
현재 생산 중입니다.

1244
01:25:44,040 --> 01:25:48,960
이 일급 비밀 칩은 MediaTek과 협력하여 NVIDIA용으로 제작된 CPU인 Grace CPU와

1245
01:25:49,240 --> 01:25:54,420
협력하여 만들었으며, 세계 최고의 SOC 회사입니다.

1246
01:25:55,000 --> 01:25:57,140
그들은 세계 최고의 SOC 회사입니다.

1247
01:25:57,380 --> 01:26:01,470
그리고 그들은 저희와 협력하여 이 CPU, 이 CPU SOC를 구축하고,

1248
01:26:01,471 --> 01:26:05,640
칩 대 칩 NVLink로 블랙웰 GPU에 연결했습니다.

1249
01:26:06,240 --> 01:26:10,760
그리고 이 작은, 이 작은 것이 본격적으로 생산되고 있습니다.

1250
01:26:11,200 --> 01:26:16,660
저희는 이 컴퓨터가 5월쯤에 출시될 것으로 예상하고 있습니다.

1251
01:26:16,661 --> 01:26:18,940
그래서 여러분에게 다가오고 있습니다.

1252
01:26:19,320 --> 01:26:21,260
정말 놀라운 것을 할 수 있습니다.

1253
01:26:21,400 --> 01:26:26,690
저는 여러분이 정말, 저는 제가 더 많은 손이나 더 많은 주머니가 필요한지 알아보려고 노력하고 있었습니다.

1254
01:26:26,691 --> 01:26:30,141
더 많은 손이나 더 많은 주머니가 필요한지 알아보려고 노력하고 있었습니다.

1255
01:26:31,220 --> 01:26:34,960
좋아요, 자, 상상해 보세요. 이렇게 생겼습니다.

1256
01:26:36,420 --> 01:26:38,140
누가 저런 걸 가지고 싶어 하지 않겠어요?

1257
01:26:39,180 --> 01:26:44,440
그리고 여러분이 PC, 맥, 모든 것을 사용한다면,

1258
01:26:45,440 --> 01:26:48,500
왜냐하면 이것은 클라우드 플랫폼이기 때문입니다.

1259
01:26:48,660 --> 01:26:50,820
데스크에 앉아 있는 클라우드 컴퓨팅 플랫폼입니다.

1260
01:26:50,920 --> 01:26:53,740
원한다면 Linux 워크스테이션으로도 사용할 수 있습니다.

1261
01:26:54,220 --> 01:26:59,780
만약 여러분이 두 자릿수 규모를 원한다면, 이것이 어떤 모습인지 보시죠.

1262
01:26:59,880 --> 01:27:06,220
그리고 여러분은 ConnectX로 그것들을 연결하고, Nickel,

1263
01:27:07,640 --> 01:27:11,000
GPU Direct, 이 모든 것을 바로 사용할 수 있습니다.

1264
01:27:11,140 --> 01:27:12,180
슈퍼컴퓨터와 같습니다.

1265
01:27:12,320 --> 01:27:14,980
저희의 전체 슈퍼컴퓨팅 스택을 사용할 수 있습니다.

1266
01:27:15,540 --> 01:27:18,800
자, NVIDIA Project Digits.

1267
01:27:27,490 --> 01:27:28,490
좋아요.

1268
01:27:29,090 --> 01:27:31,910
자, 제가 여러분에게 말씀드린 내용을 말씀드리겠습니다.

1269
01:27:32,110 --> 01:27:38,510
저는 세 가지 새로운 블랙웰을 생산하고 있다고 말씀드렸습니다.

1270
01:27:38,670 --> 01:27:43,590
Grace Blackwell 슈퍼컴퓨터, NVLink 72가 전 세계적으로 생산되고 있을 뿐만 아니라,

1271
01:27:43,591 --> 01:27:48,650
이제 세 가지 새로운 블랙웰 시스템이 생산되고 있습니다.

1272
01:27:49,070 --> 01:27:53,797
한 가지 놀라운 AI 기반, 세계 기반 모델,

1273
01:27:53,798 --> 01:27:57,110
세계 최초의 물리적 AI 기반 모델입니다.

1274
01:27:57,270 --> 01:28:02,310
그것은 로봇 공학 등 세계 산업을 활성화하기 위해 개방되어 제공됩니다.

1275
01:28:02,510 --> 01:28:09,550
그리고 세 가지, 에이전트 AI, 휴머노이드 로봇, 자율 주행 자동차에서 작동하는 세 가지 로봇입니다.

1276
01:28:10,550 --> 01:28:12,470
휴머노이드 로봇과 자율 주행 자동차를 이야기했습니다.

1277
01:28:14,130 --> 01:28:15,670
놀라운 한 해였습니다.

1278
01:28:15,850 --> 01:28:17,730
여러분 모두의 파트너십에 감사드립니다.

1279
01:28:17,890 --> 01:28:19,230
와주셔서 감사합니다.

1280
01:28:19,390 --> 01:28:21,690
작년을 되돌아보고 싶어 짧은 비디오를 만들었습니다.

1281
01:28:21,691 --> 01:28:23,170
그리고 내년을 기대하고 있습니다.

1282
01:28:23,250 --> 01:28:24,250
시작해 주세요.

1283
01:31:14,640 --> 01:31:16,500
모두 즐거운 CES 되세요!

1284
01:31:18,260 --> 01:31:19,280
새해 복 많이 받으세요!

1285
01:31:20,420 --> 01:31:21,420
감사합니다!

